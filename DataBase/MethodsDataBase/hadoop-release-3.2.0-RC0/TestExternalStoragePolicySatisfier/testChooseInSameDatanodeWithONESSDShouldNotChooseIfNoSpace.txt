/** 
 * Tests that movements should not be assigned when there is no space in target DN.
 */
@Test(timeout=300000) public void testChooseInSameDatanodeWithONESSDShouldNotChooseIfNoSpace() throws Exception {
  StorageType[][] diskTypes=new StorageType[][]{{StorageType.DISK,StorageType.DISK},{StorageType.DISK,StorageType.SSD},{StorageType.DISK,StorageType.DISK}};
  config.setLong("dfs.block.size",2 * DEFAULT_BLOCK_SIZE);
  long dnCapacity=1024 * DEFAULT_BLOCK_SIZE + (2 * DEFAULT_BLOCK_SIZE - 1);
  try {
    hdfsCluster=startCluster(config,diskTypes,NUM_OF_DATANODES,STORAGES_PER_DATANODE,dnCapacity);
    dfs=hdfsCluster.getFileSystem();
    writeContent(FILE);
    dfs.setStoragePolicy(new Path(FILE),ONE_SSD);
    Path filePath=new Path("/testChooseInSameDatanode");
    final FSDataOutputStream out=dfs.create(filePath,false,100,(short)1,2 * DEFAULT_BLOCK_SIZE);
    try {
      dfs.setStoragePolicy(filePath,ONE_SSD);
      long remaining=dfs.getStatus().getRemaining() / (3 * 2);
      for (int i=0; i < remaining; i++) {
        out.write(i);
      }
    }
  finally {
      out.close();
    }
    hdfsCluster.triggerHeartbeats();
    ArrayList<DataNode> dataNodes=hdfsCluster.getDataNodes();
    for (    DataNode dataNode : dataNodes) {
      DataNodeTestUtils.setHeartbeatsDisabledForTests(dataNode,true);
    }
    dfs.satisfyStoragePolicy(new Path(FILE));
    waitForAttemptedItems(1,30000);
    for (    DataNode dataNode : dataNodes) {
      DataNodeTestUtils.setHeartbeatsDisabledForTests(dataNode,false);
    }
    hdfsCluster.triggerHeartbeats();
    DFSTestUtil.waitExpectedStorageType(FILE,StorageType.DISK,3,30000,dfs);
    DFSTestUtil.waitExpectedStorageType(FILE,StorageType.SSD,0,30000,dfs);
  }
  finally {
    shutdownCluster();
  }
}
