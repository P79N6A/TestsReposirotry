/** 
 * Tests to verify that for the given path, only few of the blocks or block src locations(src nodes) under the given path will be scheduled for block movement. For example, there are two block for a file: File1 => two blocks and default storage policy(HOT). blk_1[locations=A(DISK),B(DISK),C(DISK),D(DISK),E(DISK)], blk_2[locations=A(DISK),B(DISK),C(DISK),D(DISK),E(DISK)]. Now, set storage policy to COLD. Only two Dns are available with expected storage type ARCHIVE, say A, E. SPS will schedule block movement to the coordinator node with the details, blk_1[move A(DISK) -> A(ARCHIVE), move E(DISK) -> E(ARCHIVE)], blk_2[move A(DISK) -> A(ARCHIVE), move E(DISK) -> E(ARCHIVE)].
 */
@Test(timeout=300000) public void testWhenOnlyFewSourceNodesHaveMatchingTargetNodes() throws Exception {
  try {
    int numOfDns=5;
    config.setLong("dfs.block.size",1024);
    allDiskTypes=new StorageType[][]{{StorageType.DISK,StorageType.ARCHIVE},{StorageType.DISK,StorageType.DISK},{StorageType.DISK,StorageType.DISK},{StorageType.DISK,StorageType.DISK},{StorageType.DISK,StorageType.ARCHIVE}};
    hdfsCluster=startCluster(config,allDiskTypes,numOfDns,STORAGES_PER_DATANODE,CAPACITY);
    dfs=hdfsCluster.getFileSystem();
    writeContent(FILE,(short)5);
    dfs.setStoragePolicy(new Path(FILE),COLD);
    dfs.satisfyStoragePolicy(new Path(FILE));
    hdfsCluster.triggerHeartbeats();
    DFSTestUtil.waitExpectedStorageType(FILE,StorageType.ARCHIVE,2,30000,dfs);
    DFSTestUtil.waitExpectedStorageType(FILE,StorageType.DISK,3,30000,dfs);
    waitForBlocksMovementAttemptReport(1,30000);
  }
  finally {
    shutdownCluster();
  }
}
