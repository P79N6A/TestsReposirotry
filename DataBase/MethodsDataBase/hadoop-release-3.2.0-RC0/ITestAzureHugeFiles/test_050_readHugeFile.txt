@Test public void test_050_readHugeFile() throws Throwable {
  assumeHugeFileExists();
  describe("Reading %s",hugefile);
  NativeAzureFileSystem fs=getFileSystem();
  FileStatus status=fs.getFileStatus(hugefile);
  long filesize=status.getLen();
  long blocks=filesize / UPLOAD_BLOCKSIZE;
  byte[] data=new byte[UPLOAD_BLOCKSIZE];
  ContractTestUtils.NanoTimer timer=new ContractTestUtils.NanoTimer();
  try (FSDataInputStream in=openDataFile()){
    for (long block=0; block < blocks; block++) {
      in.readFully(data);
    }
    LOG.info("Final stream state: {}",in);
  }
   long mb=Math.max(filesize / S_1M,1);
  timer.end("time to read file of %d MB ",mb);
  LOG.info("Time per MB to read = {} nS",toHuman(timer.nanosPerOperation(mb)));
  bandwidth(timer,filesize);
  logFSState();
}
