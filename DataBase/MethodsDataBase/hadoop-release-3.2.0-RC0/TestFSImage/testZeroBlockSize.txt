/** 
 * In this test case, I have created an image with a file having preferredblockSize = 0. We are trying to read this image (since file with preferredblockSize = 0 was allowed pre 2.1.0-beta version. The namenode  after 2.6 version will not be able to read this particular file. See HDFS-7788 for more information.
 * @throws Exception
 */
@Test public void testZeroBlockSize() throws Exception {
  final Configuration conf=new HdfsConfiguration();
  String tarFile=System.getProperty("test.cache.data","build/test/cache") + "/" + HADOOP_2_7_ZER0_BLOCK_SIZE_TGZ;
  String testDir=PathUtils.getTestDirName(getClass());
  File dfsDir=new File(testDir,"image-with-zero-block-size");
  if (dfsDir.exists() && !FileUtil.fullyDelete(dfsDir)) {
    throw new IOException("Could not delete dfs directory '" + dfsDir + "'");
  }
  FileUtil.unTar(new File(tarFile),new File(testDir));
  File nameDir=new File(dfsDir,"name");
  GenericTestUtils.assertExists(nameDir);
  conf.set(DFSConfigKeys.DFS_NAMENODE_NAME_DIR_KEY,nameDir.getAbsolutePath());
  MiniDFSCluster cluster=new MiniDFSCluster.Builder(conf).numDataNodes(1).format(false).manageDataDfsDirs(false).manageNameDfsDirs(false).waitSafeMode(false).startupOption(StartupOption.UPGRADE).build();
  try {
    FileSystem fs=cluster.getFileSystem();
    Path testPath=new Path("/tmp/zeroBlockFile");
    assertTrue("File /tmp/zeroBlockFile doesn't exist ",fs.exists(testPath));
    assertTrue("Name node didn't come up",cluster.isNameNodeUp(0));
  }
  finally {
    cluster.shutdown();
    FileUtil.fullyDelete(dfsDir);
  }
}
