@Test public void testDNShouldNotDeleteBlockONTooManyOpenFiles() throws Exception {
  Configuration conf=new HdfsConfiguration();
  conf.setLong(DFSConfigKeys.DFS_HEARTBEAT_INTERVAL_KEY,1L);
  conf.setLong(HdfsClientConfigKeys.Retry.WINDOW_BASE_KEY,1);
  DataNodeFaultInjector oldInjector=DataNodeFaultInjector.get();
  MiniDFSCluster cluster=new MiniDFSCluster.Builder(conf).numDataNodes(1).build();
  final DataNodeFaultInjector injector=Mockito.mock(DataNodeFaultInjector.class);
  try {
    cluster.waitActive();
    DistributedFileSystem fs=cluster.getFileSystem();
    Path p=new Path("/testShouldThrowTMP");
    DFSTestUtil.writeFile(fs,p,new String("testdata"));
    verifyBlockLocations(fs,p,1);
    Mockito.doThrow(new FileNotFoundException("Too many open files")).when(injector).throwTooManyOpenFiles();
    DataNodeFaultInjector.set(injector);
    ExtendedBlock b=fs.getClient().getLocatedBlocks(p.toString(),0).get(0).getBlock();
    try {
      new BlockSender(b,0,-1,false,true,true,cluster.getDataNodes().get(0),null,CachingStrategy.newDefaultStrategy());
      fail("Must throw FileNotFoundException");
    }
 catch (    FileNotFoundException fe) {
      assertTrue("Should throw too many open files",fe.getMessage().contains("Too many open files"));
    }
    cluster.triggerHeartbeats();
    assertTrue(cluster.getDataNodes().get(0).getFSDataset().isValidBlock(b));
    verifyBlockLocations(fs,p,1);
  }
  finally {
    if (cluster != null) {
      cluster.shutdown();
    }
    DataNodeFaultInjector.set(oldInjector);
  }
}
