@Test public void testPipelineRecoveryOnRemoteDatanodeUpgrade() throws Exception {
  Configuration conf=new HdfsConfiguration();
  conf.setBoolean(BlockWrite.ReplaceDatanodeOnFailure.BEST_EFFORT_KEY,true);
  MiniDFSCluster cluster=null;
  DFSClientFaultInjector old=DFSClientFaultInjector.get();
  try {
    cluster=new MiniDFSCluster.Builder(conf).numDataNodes(3).build();
    cluster.waitActive();
    FileSystem fileSys=cluster.getFileSystem();
    Path file=new Path("/testPipelineRecoveryOnDatanodeUpgrade");
    DFSTestUtil.createFile(fileSys,file,10240L,(short)3,0L);
    DFSClientFaultInjector.set(new DFSClientFaultInjector(){
      public boolean skipRollingRestartWait(){
        return true;
      }
    }
);
    final DFSOutputStream out=(DFSOutputStream)fileSys.append(file).getWrappedStream();
    final AtomicBoolean running=new AtomicBoolean(true);
    final AtomicBoolean failed=new AtomicBoolean(false);
    Thread t=new Thread(){
      public void run(){
        while (running.get()) {
          try {
            out.write("test".getBytes());
            out.hflush();
            Thread.sleep(1000);
          }
 catch (          IOException|InterruptedException e) {
            LOG.error("Exception during write",e);
            failed.set(true);
            break;
          }
        }
        running.set(false);
      }
    }
;
    t.start();
    Thread.sleep(1000);
    DatanodeInfo[] pipeline=out.getPipeline();
    for (    DatanodeInfo node : pipeline) {
      assertFalse("Write should be going on",failed.get());
      ArrayList<DataNode> dataNodes=cluster.getDataNodes();
      int indexToShutdown=0;
      for (int i=0; i < dataNodes.size(); i++) {
        if (dataNodes.get(i).getIpcPort() == node.getIpcPort()) {
          indexToShutdown=i;
          break;
        }
      }
      final long oldGs=out.getBlock().getGenerationStamp();
      MiniDFSCluster.DataNodeProperties dnProps=cluster.stopDataNodeForUpgrade(indexToShutdown);
      GenericTestUtils.waitForThreadTermination("Async datanode shutdown thread",100,10000);
      cluster.restartDataNode(dnProps,true);
      cluster.waitActive();
      GenericTestUtils.waitFor(new Supplier<Boolean>(){
        @Override public Boolean get(){
          return out.getBlock().getGenerationStamp() > oldGs;
        }
      }
,100,10000);
      Assert.assertEquals("The pipeline recovery count shouldn't increase",0,out.getStreamer().getPipelineRecoveryCount());
    }
    assertFalse("Write should be going on",failed.get());
    running.set(false);
    t.join();
    out.write("testagain".getBytes());
    assertTrue("There should be atleast 2 nodes in pipeline still",out.getPipeline().length >= 2);
    out.close();
  }
  finally {
    DFSClientFaultInjector.set(old);
    if (cluster != null) {
      cluster.shutdown();
    }
  }
}
