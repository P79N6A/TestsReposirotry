/** 
 * There was this problem where some steps and in particular parallel CSV input parsing that paniced would hang the import entirely.
 */
@Test public void shouldExitAndThrowExceptionOnPanic() throws Exception {
  try (JobScheduler jobScheduler=new ThreadPoolJobScheduler()){
    BatchImporter importer=new ParallelBatchImporter(directory.databaseLayout(),fs,null,Configuration.DEFAULT,NullLogService.getInstance(),ExecutionMonitors.invisible(),AdditionalInitialIds.EMPTY,Config.defaults(),StandardV3_0.RECORD_FORMATS,NO_MONITOR,jobScheduler);
    Iterable<DataFactory> nodeData=datas(data(NO_DECORATOR,fileAsCharReadable(nodeCsvFileWithBrokenEntries())));
    Input brokenCsvInput=new CsvInput(nodeData,defaultFormatNodeFileHeader(),datas(),defaultFormatRelationshipFileHeader(),IdType.ACTUAL,csvConfigurationWithLowBufferSize(),new BadCollector(NullOutputStream.NULL_OUTPUT_STREAM,0,0));
    importer.doImport(brokenCsvInput);
    fail("Should have failed properly");
  }
 catch (  InputException e) {
    assertTrue(e.getCause() instanceof DataAfterQuoteException);
  }
}
