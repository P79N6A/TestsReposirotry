@Test public void testHypercubeMapReduceRunSequentially() throws Exception {
  Configuration configuration=getConfiguration();
  configure(configuration);
  configuration.set(DefaultOptionCreator.METHOD_OPTION,DefaultOptionCreator.SEQUENTIAL_METHOD);
  Path inputPath=new Path("testInput");
  Path outputPath=new Path("testOutput");
  StreamingKMeansUtilsMR.writeVectorsToSequenceFile(syntheticData.getFirst(),inputPath,configuration);
  StreamingKMeansDriver.run(configuration,inputPath,outputPath);
  testReducerResults(syntheticData.getFirst().size(),Lists.newArrayList(Iterables.transform(new SequenceFileIterable<IntWritable,CentroidWritable>(outputPath,configuration),new Function<Pair<IntWritable,CentroidWritable>,org.apache.hadoop.mrunit.types.Pair<IntWritable,CentroidWritable>>(){
    @Override public org.apache.hadoop.mrunit.types.Pair<IntWritable,CentroidWritable> apply(    org.apache.mahout.common.Pair<IntWritable,CentroidWritable> input){
      return new org.apache.hadoop.mrunit.types.Pair<>(input.getFirst(),input.getSecond());
    }
  }
)));
}
