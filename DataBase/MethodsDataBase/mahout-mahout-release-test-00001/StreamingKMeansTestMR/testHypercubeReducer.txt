@Test public void testHypercubeReducer() throws IOException {
  ReduceDriver<IntWritable,CentroidWritable,IntWritable,CentroidWritable> reduceDriver=ReduceDriver.newReduceDriver(new StreamingKMeansReducer());
  Configuration configuration=reduceDriver.getConfiguration();
  configure(configuration);
  System.out.printf("%s reducer test\n",configuration.get(StreamingKMeansDriver.SEARCHER_CLASS_OPTION));
  StreamingKMeans clusterer=new StreamingKMeans(StreamingKMeansUtilsMR.searcherFromConfiguration(configuration),(1 << NUM_DIMENSIONS) * (int)Math.log(NUM_DATA_POINTS),DISTANCE_CUTOFF);
  long start=System.currentTimeMillis();
  clusterer.cluster(syntheticData.getFirst());
  long end=System.currentTimeMillis();
  System.out.printf("%f [s]\n",(end - start) / 1000.0);
  List<CentroidWritable> reducerInputs=Lists.newArrayList();
  int postMapperTotalWeight=0;
  for (  Centroid intermediateCentroid : clusterer) {
    reducerInputs.add(new CentroidWritable(intermediateCentroid));
    postMapperTotalWeight+=intermediateCentroid.getWeight();
  }
  reduceDriver.addInput(new IntWritable(0),reducerInputs);
  List<org.apache.hadoop.mrunit.types.Pair<IntWritable,CentroidWritable>> results=reduceDriver.run();
  testReducerResults(postMapperTotalWeight,results);
}
