/** 
 * Story: User can remove outliers while clustering points using sequential execution 
 */
@Test public void testClusteringEuclideanWithOutlierRemovalSeq() throws Exception {
  List<VectorWritable> points=getPointsWritable();
  Configuration config=getConfiguration();
  ClusteringTestUtils.writePointsToFile(points,getTestTempFilePath("testdata/file1"),fs,config);
  Path output=getTestTempDirPath("output");
  String[] args={optKey(DefaultOptionCreator.INPUT_OPTION),getTestTempDirPath("testdata").toString(),optKey(DefaultOptionCreator.OUTPUT_OPTION),output.toString(),optKey(DefaultOptionCreator.DISTANCE_MEASURE_OPTION),EuclideanDistanceMeasure.class.getName(),optKey(DefaultOptionCreator.T1_OPTION),"3.1",optKey(DefaultOptionCreator.T2_OPTION),"2.1",optKey(DefaultOptionCreator.OUTLIER_THRESHOLD),"0.5",optKey(DefaultOptionCreator.CLUSTERING_OPTION),optKey(DefaultOptionCreator.OVERWRITE_OPTION),optKey(DefaultOptionCreator.METHOD_OPTION),DefaultOptionCreator.SEQUENTIAL_METHOD};
  ToolRunner.run(config,new CanopyDriver(),args);
  Path path=new Path(output,"clusters-0-final/part-r-00000");
  int ix=0;
  for (  ClusterWritable clusterWritable : new SequenceFileValueIterable<ClusterWritable>(path,true,config)) {
    assertEquals("Center [" + ix + ']',euclideanCentroids.get(ix),clusterWritable.getValue().getCenter());
    ix++;
  }
  path=new Path(output,"clusteredPoints/part-m-0");
  long count=HadoopUtil.countRecords(path,config);
  int expectedPointsHavingPDFGreaterThanThreshold=6;
  assertEquals("number of points",expectedPointsHavingPDFGreaterThanThreshold,count);
}
