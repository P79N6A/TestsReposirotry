/** 
 * Test that tags survive through a bulk load that needs to split hfiles. This test depends on the "hbase.client.rpc.codec" = KeyValueCodecWithTags so that the client can get tags in the responses.
 */
@Test public void testTagsSurviveBulkLoadSplit() throws Exception {
  Path dir=util.getDataTestDirOnTestFS(tn.getMethodName());
  FileSystem fs=util.getTestFileSystem();
  dir=dir.makeQualified(fs.getUri(),fs.getWorkingDirectory());
  Path familyDir=new Path(dir,Bytes.toString(FAMILY));
  byte[][] tableSplitKeys=new byte[][]{Bytes.toBytes("aaa"),Bytes.toBytes("fff"),Bytes.toBytes("jjj"),Bytes.toBytes("ppp"),Bytes.toBytes("uuu"),Bytes.toBytes("zzz")};
  byte[] from=Bytes.toBytes("ddd");
  byte[] to=Bytes.toBytes("ooo");
  HFileTestUtil.createHFileWithTags(util.getConfiguration(),fs,new Path(familyDir,tn.getMethodName() + "_hfile"),FAMILY,QUALIFIER,from,to,1000);
  int expectedRows=1000;
  TableName tableName=TableName.valueOf(tn.getMethodName());
  TableDescriptor htd=buildHTD(tableName,BloomType.NONE);
  util.getAdmin().createTable(htd,tableSplitKeys);
  LoadIncrementalHFiles loader=new LoadIncrementalHFiles(util.getConfiguration());
  String[] args={dir.toString(),tableName.toString()};
  loader.run(args);
  Table table=util.getConnection().getTable(tableName);
  try {
    assertEquals(expectedRows,util.countRows(table));
    HFileTestUtil.verifyTags(table);
  }
  finally {
    table.close();
  }
  util.deleteTable(tableName);
}
