/** 
 * Tests that a task waiting on an async producer/consumer that is stuck in a blocking buffer request can be properly cancelled. <p>This is currently required for the Flink Kafka sources, which spawn a separate Thread consuming from Kafka and producing the intermediate streams in the spawned Thread instead of the main task Thread.
 */
@Test public void testCancelAsyncProducerAndConsumer() throws Exception {
  Deadline deadline=Deadline.now().plus(Duration.ofMinutes(2));
  Configuration config=new Configuration();
  config.setInteger(RestOptions.PORT,0);
  config.setString(TaskManagerOptions.MEMORY_SEGMENT_SIZE,"4096");
  config.setInteger(TaskManagerOptions.NETWORK_NUM_BUFFERS,9);
  MiniClusterConfiguration miniClusterConfiguration=new MiniClusterConfiguration.Builder().setConfiguration(config).setNumTaskManagers(1).setNumSlotsPerTaskManager(1).build();
  try (MiniCluster flink=new MiniCluster(miniClusterConfiguration)){
    flink.start();
    JobVertex producer=new JobVertex("AsyncProducer");
    producer.setParallelism(1);
    producer.setInvokableClass(AsyncProducer.class);
    JobVertex consumer=new JobVertex("AsyncConsumer");
    consumer.setParallelism(1);
    consumer.setInvokableClass(AsyncConsumer.class);
    consumer.connectNewDataSetAsInput(producer,DistributionPattern.POINTWISE,ResultPartitionType.PIPELINED);
    SlotSharingGroup slot=new SlotSharingGroup(producer.getID(),consumer.getID());
    producer.setSlotSharingGroup(slot);
    consumer.setSlotSharingGroup(slot);
    JobGraph jobGraph=new JobGraph(producer,consumer);
    flink.runDetached(jobGraph);
    FutureUtils.retrySuccesfulWithDelay(() -> flink.getJobStatus(jobGraph.getJobID()),Time.milliseconds(10),deadline,status -> status == JobStatus.RUNNING,TestingUtils.defaultScheduledExecutor()).get(deadline.timeLeft().toMillis(),TimeUnit.MILLISECONDS);
    boolean producerBlocked=false;
    for (int i=0; i < 50; i++) {
      Thread thread=ASYNC_PRODUCER_THREAD;
      if (thread != null && thread.isAlive()) {
        StackTraceElement[] stackTrace=thread.getStackTrace();
        producerBlocked=isInBlockingBufferRequest(stackTrace);
      }
      if (producerBlocked) {
        break;
      }
 else {
        Thread.sleep(500L);
      }
    }
    assertTrue("Producer thread is not blocked: " + Arrays.toString(ASYNC_PRODUCER_THREAD.getStackTrace()),producerBlocked);
    boolean consumerWaiting=false;
    for (int i=0; i < 50; i++) {
      Thread thread=ASYNC_CONSUMER_THREAD;
      if (thread != null && thread.isAlive()) {
        consumerWaiting=thread.getState() == Thread.State.WAITING;
      }
      if (consumerWaiting) {
        break;
      }
 else {
        Thread.sleep(500L);
      }
    }
    assertTrue("Consumer thread is not blocked.",consumerWaiting);
    flink.cancelJob(jobGraph.getJobID()).get(deadline.timeLeft().toMillis(),TimeUnit.MILLISECONDS);
    FutureUtils.retrySuccesfulWithDelay(() -> flink.getJobStatus(jobGraph.getJobID()),Time.milliseconds(10),deadline,status -> status == JobStatus.CANCELED,TestingUtils.defaultScheduledExecutor()).get(deadline.timeLeft().toMillis(),TimeUnit.MILLISECONDS);
    assertNotNull(ASYNC_PRODUCER_EXCEPTION);
    assertEquals(IllegalStateException.class,ASYNC_PRODUCER_EXCEPTION.getClass());
    assertNotNull(ASYNC_CONSUMER_EXCEPTION);
    assertEquals(IllegalStateException.class,ASYNC_CONSUMER_EXCEPTION.getClass());
  }
 }
