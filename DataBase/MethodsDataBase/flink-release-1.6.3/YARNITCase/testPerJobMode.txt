@Ignore("The cluster cannot be stopped yet.") @Test public void testPerJobMode() throws Exception {
  Configuration configuration=new Configuration();
  configuration.setString(AkkaOptions.ASK_TIMEOUT,"30 s");
  final YarnClient yarnClient=getYarnClient();
  try (final YarnClusterDescriptor yarnClusterDescriptor=new YarnClusterDescriptor(configuration,getYarnConfiguration(),System.getenv(ConfigConstants.ENV_FLINK_CONF_DIR),yarnClient,true)){
    yarnClusterDescriptor.setLocalJarPath(new Path(flinkUberjar.getAbsolutePath()));
    yarnClusterDescriptor.addShipFiles(Arrays.asList(flinkLibFolder.listFiles()));
    final ClusterSpecification clusterSpecification=new ClusterSpecification.ClusterSpecificationBuilder().setMasterMemoryMB(768).setTaskManagerMemoryMB(1024).setSlotsPerTaskManager(1).setNumberTaskManagers(1).createClusterSpecification();
    StreamExecutionEnvironment env=StreamExecutionEnvironment.getExecutionEnvironment();
    env.setParallelism(2);
    env.addSource(new InfiniteSource()).shuffle().addSink(new DiscardingSink<Integer>());
    final JobGraph jobGraph=env.getStreamGraph().getJobGraph();
    File testingJar=YarnTestBase.findFile("..",new TestingYarnClusterDescriptor.TestJarFinder("flink-yarn-tests"));
    jobGraph.addJar(new org.apache.flink.core.fs.Path(testingJar.toURI()));
    ClusterClient<ApplicationId> clusterClient=yarnClusterDescriptor.deployJobCluster(clusterSpecification,jobGraph,true);
    clusterClient.shutdown();
  }
 }
