/** 
 * Similar tests as  {@link #testValueState()} but before submitting thejob, we already issue one request which fails.
 */
@Test public void testQueryNonStartedJobState() throws Exception {
  final Deadline deadline=Deadline.now().plus(TEST_TIMEOUT);
  final long numElements=1024L;
  StreamExecutionEnvironment env=StreamExecutionEnvironment.getExecutionEnvironment();
  env.setStateBackend(stateBackend);
  env.setParallelism(maxParallelism);
  env.setRestartStrategy(RestartStrategies.fixedDelayRestart(Integer.MAX_VALUE,1000L));
  DataStream<Tuple2<Integer,Long>> source=env.addSource(new TestAscendingValueSource(numElements));
  ValueStateDescriptor<Tuple2<Integer,Long>> valueState=new ValueStateDescriptor<>("any",source.getType(),null);
  QueryableStateStream<Integer,Tuple2<Integer,Long>> queryableState=source.keyBy(new KeySelector<Tuple2<Integer,Long>,Integer>(){
    private static final long serialVersionUID=7480503339992214681L;
    @Override public Integer getKey(    Tuple2<Integer,Long> value){
      return value.f0;
    }
  }
).asQueryableState("hakuna",valueState);
  try (AutoCancellableJob autoCancellableJob=new AutoCancellableJob(deadline,clusterClient,env)){
    final JobID jobId=autoCancellableJob.getJobId();
    final JobGraph jobGraph=autoCancellableJob.getJobGraph();
    long expected=numElements;
    client.getKvState(autoCancellableJob.getJobId(),queryableState.getQueryableStateName(),0,BasicTypeInfo.INT_TYPE_INFO,valueState);
    clusterClient.setDetached(true);
    clusterClient.submitJob(jobGraph,AbstractQueryableStateTestBase.class.getClassLoader());
    executeValueQuery(deadline,client,jobId,"hakuna",valueState,expected);
  }
 }
