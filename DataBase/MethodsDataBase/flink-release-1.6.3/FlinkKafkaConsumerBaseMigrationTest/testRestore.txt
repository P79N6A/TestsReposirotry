/** 
 * Test restoring from a non-empty state taken using a previous Flink version, when some partitions could be found for topics.
 */
@Test public void testRestore() throws Exception {
  final List<KafkaTopicPartition> partitions=new ArrayList<>(PARTITION_STATE.keySet());
  final DummyFlinkKafkaConsumer<String> consumerFunction=new DummyFlinkKafkaConsumer<>(partitions,FlinkKafkaConsumerBase.PARTITION_DISCOVERY_DISABLED);
  StreamSource<String,DummyFlinkKafkaConsumer<String>> consumerOperator=new StreamSource<>(consumerFunction);
  final AbstractStreamOperatorTestHarness<String> testHarness=new AbstractStreamOperatorTestHarness<>(consumerOperator,1,1,0);
  testHarness.setTimeCharacteristic(TimeCharacteristic.ProcessingTime);
  testHarness.setup();
  MigrationTestUtil.restoreFromSnapshot(testHarness,OperatorSnapshotUtil.getResourceFilename("kafka-consumer-migration-test-flink" + testMigrateVersion + "-snapshot"),testMigrateVersion);
  testHarness.open();
  assertTrue(consumerFunction.getSubscribedPartitionsToStartOffsets() != null);
  assertTrue(!consumerFunction.getSubscribedPartitionsToStartOffsets().isEmpty());
  assertEquals(PARTITION_STATE,consumerFunction.getSubscribedPartitionsToStartOffsets());
  assertTrue(consumerFunction.getRestoredState() != null);
  assertEquals(PARTITION_STATE,consumerFunction.getRestoredState());
  consumerOperator.close();
  consumerOperator.cancel();
}
