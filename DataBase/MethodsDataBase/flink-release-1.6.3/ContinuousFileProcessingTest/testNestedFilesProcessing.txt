@Test public void testNestedFilesProcessing() throws Exception {
  String testBasePath=hdfsURI + "/" + UUID.randomUUID()+ "/";
  final Set<org.apache.hadoop.fs.Path> filesCreated=new HashSet<>();
  final Set<String> filesToBeRead=new TreeSet<>();
  org.apache.hadoop.fs.Path firstLevelDir=new org.apache.hadoop.fs.Path(testBasePath + "/" + "firstLevelDir");
  org.apache.hadoop.fs.Path secondLevelDir=new org.apache.hadoop.fs.Path(testBasePath + "/" + "firstLevelDir"+ "/"+ "secondLevelDir");
  Assert.assertFalse(hdfs.exists(firstLevelDir));
  hdfs.mkdirs(firstLevelDir);
  hdfs.mkdirs(secondLevelDir);
  for (int i=0; i < NO_OF_FILES; i++) {
    Tuple2<org.apache.hadoop.fs.Path,String> file=createFileAndFillWithData(testBasePath,"firstLevelFile",i,"This is test line.");
    filesCreated.add(file.f0);
    filesToBeRead.add(file.f0.getName());
  }
  for (int i=0; i < NO_OF_FILES; i++) {
    Tuple2<org.apache.hadoop.fs.Path,String> file=createFileAndFillWithData(firstLevelDir.toString(),"secondLevelFile",i,"This is test line.");
    filesCreated.add(file.f0);
    filesToBeRead.add(file.f0.getName());
  }
  for (int i=0; i < NO_OF_FILES; i++) {
    Tuple2<org.apache.hadoop.fs.Path,String> file=createFileAndFillWithData(secondLevelDir.toString(),"thirdLevelFile",i,"This is test line.");
    filesCreated.add(file.f0);
    filesToBeRead.add(file.f0.getName());
  }
  TextInputFormat format=new TextInputFormat(new Path(testBasePath));
  format.setFilesFilter(FilePathFilter.createDefaultFilter());
  format.setNestedFileEnumeration(true);
  ContinuousFileMonitoringFunction<String> monitoringFunction=createTestContinuousFileMonitoringFunction(format,FileProcessingMode.PROCESS_ONCE);
  final FileVerifyingSourceContext context=new FileVerifyingSourceContext(new OneShotLatch(),monitoringFunction);
  monitoringFunction.open(new Configuration());
  monitoringFunction.run(context);
  Assert.assertArrayEquals(filesToBeRead.toArray(),context.getSeenFiles().toArray());
  for (  org.apache.hadoop.fs.Path file : filesCreated) {
    hdfs.delete(file,false);
  }
  hdfs.delete(secondLevelDir,false);
  hdfs.delete(firstLevelDir,false);
}
