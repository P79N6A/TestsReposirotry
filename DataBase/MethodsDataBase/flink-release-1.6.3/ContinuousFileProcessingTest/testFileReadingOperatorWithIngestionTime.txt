@Test public void testFileReadingOperatorWithIngestionTime() throws Exception {
  String testBasePath=hdfsURI + "/" + UUID.randomUUID()+ "/";
  Set<org.apache.hadoop.fs.Path> filesCreated=new HashSet<>();
  Map<Integer,String> expectedFileContents=new HashMap<>();
  Map<String,Long> modTimes=new HashMap<>();
  for (int i=0; i < NO_OF_FILES; i++) {
    Tuple2<org.apache.hadoop.fs.Path,String> file=createFileAndFillWithData(testBasePath,"file",i,"This is test line.");
    filesCreated.add(file.f0);
    modTimes.put(file.f0.getName(),hdfs.getFileStatus(file.f0).getModificationTime());
    expectedFileContents.put(i,file.f1);
  }
  TextInputFormat format=new TextInputFormat(new Path(testBasePath));
  TypeInformation<String> typeInfo=TypeExtractor.getInputFormatTypes(format);
  final long watermarkInterval=10;
  ContinuousFileReaderOperator<String> reader=new ContinuousFileReaderOperator<>(format);
  final OneInputStreamOperatorTestHarness<TimestampedFileInputSplit,String> tester=new OneInputStreamOperatorTestHarness<>(reader);
  tester.getExecutionConfig().setAutoWatermarkInterval(watermarkInterval);
  tester.setTimeCharacteristic(TimeCharacteristic.IngestionTime);
  reader.setOutputType(typeInfo,tester.getExecutionConfig());
  tester.open();
  Assert.assertEquals(TimeCharacteristic.IngestionTime,tester.getTimeCharacteristic());
  ConcurrentLinkedQueue<Object> output=tester.getOutput();
  tester.setProcessingTime(201);
  Assert.assertTrue(output.peek() instanceof Watermark);
  Assert.assertEquals(200,((Watermark)output.poll()).getTimestamp());
  tester.setProcessingTime(301);
  Assert.assertTrue(output.peek() instanceof Watermark);
  Assert.assertEquals(300,((Watermark)output.poll()).getTimestamp());
  tester.setProcessingTime(401);
  Assert.assertTrue(output.peek() instanceof Watermark);
  Assert.assertEquals(400,((Watermark)output.poll()).getTimestamp());
  tester.setProcessingTime(501);
  Assert.assertTrue(output.peek() instanceof Watermark);
  Assert.assertEquals(500,((Watermark)output.poll()).getTimestamp());
  Assert.assertTrue(output.isEmpty());
  FileInputSplit[] splits=format.createInputSplits(reader.getRuntimeContext().getNumberOfParallelSubtasks());
  Map<Integer,List<String>> actualFileContents=new HashMap<>();
  long lastSeenWatermark=Long.MIN_VALUE;
  int lineCounter=0;
  int watermarkCounter=0;
  for (  FileInputSplit split : splits) {
    long nextTimestamp=tester.getProcessingTime() + watermarkInterval;
    tester.setProcessingTime(nextTimestamp);
    tester.processElement(new StreamRecord<>(new TimestampedFileInputSplit(modTimes.get(split.getPath().getName()),split.getSplitNumber(),split.getPath(),split.getStart(),split.getLength(),split.getHostnames())));
    while (tester.getOutput().isEmpty() || tester.getOutput().size() != (LINES_PER_FILE + 1)) {
      Thread.sleep(10);
    }
    for (    Object line : tester.getOutput()) {
      if (line instanceof StreamRecord) {
        @SuppressWarnings("unchecked") StreamRecord<String> element=(StreamRecord<String>)line;
        lineCounter++;
        Assert.assertEquals(nextTimestamp,element.getTimestamp());
        int fileIdx=Character.getNumericValue(element.getValue().charAt(0));
        List<String> content=actualFileContents.get(fileIdx);
        if (content == null) {
          content=new ArrayList<>();
          actualFileContents.put(fileIdx,content);
        }
        content.add(element.getValue() + "\n");
      }
 else       if (line instanceof Watermark) {
        long watermark=((Watermark)line).getTimestamp();
        Assert.assertEquals(nextTimestamp - (nextTimestamp % watermarkInterval),watermark);
        Assert.assertTrue(watermark > lastSeenWatermark);
        watermarkCounter++;
        lastSeenWatermark=watermark;
      }
 else {
        Assert.fail("Unknown element in the list.");
      }
    }
    tester.getOutput().clear();
  }
  Assert.assertEquals(NO_OF_FILES * LINES_PER_FILE,lineCounter);
  Assert.assertEquals(splits.length,watermarkCounter);
synchronized (tester.getCheckpointLock()) {
    tester.close();
  }
  for (  org.apache.hadoop.fs.Path file : filesCreated) {
    hdfs.delete(file,false);
  }
  Assert.assertEquals(1,tester.getOutput().size());
  Assert.assertTrue(tester.getOutput().peek() instanceof Watermark);
  Assert.assertEquals(Long.MAX_VALUE,((Watermark)tester.getOutput().poll()).getTimestamp());
  Assert.assertEquals(expectedFileContents.size(),actualFileContents.size());
  for (  Integer fileIdx : expectedFileContents.keySet()) {
    Assert.assertTrue("file" + fileIdx + " not found",actualFileContents.keySet().contains(fileIdx));
    List<String> cntnt=actualFileContents.get(fileIdx);
    Collections.sort(cntnt,new Comparator<String>(){
      @Override public int compare(      String o1,      String o2){
        return getLineNo(o1) - getLineNo(o2);
      }
    }
);
    StringBuilder cntntStr=new StringBuilder();
    for (    String line : cntnt) {
      cntntStr.append(line);
    }
    Assert.assertEquals(expectedFileContents.get(fileIdx),cntntStr.toString());
  }
}
