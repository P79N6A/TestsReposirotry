@Test public void testOutputWorkspace(){
  String wsName="ExternalTestWorkspace";
  WorkspaceConfiguration conf=WorkspaceConfiguration.builder().initialSize(0).overallocationLimit(0.02).policyLearning(LearningPolicy.OVER_TIME).cyclesBeforeInitialization(1).policyReset(ResetPolicy.BLOCK_LEFT).policySpill(SpillPolicy.REALLOCATE).policyAllocation(AllocationPolicy.OVERALLOCATE).build();
  MemoryWorkspace workspace=Nd4j.getWorkspaceManager().getWorkspaceForCurrentThread(conf,wsName);
  MultiLayerConfiguration netConf=new NeuralNetConfiguration.Builder().seed(12345).weightInit(WeightInit.XAVIER).list().layer(new DenseLayer.Builder().nIn(4).nOut(3).activation(Activation.TANH).build()).layer(new OutputLayer.Builder().nIn(3).nOut(3).activation(Activation.SOFTMAX).lossFunction(LossFunctions.LossFunction.MCXENT).build()).build();
  MultiLayerNetwork net=new MultiLayerNetwork(netConf);
  net.init();
  INDArray in=Nd4j.rand(3,4);
  for (int i=0; i < 3; i++) {
    try (MemoryWorkspace ws=workspace.notifyScopeEntered()){
      System.out.println("MLN - " + i);
      INDArray out=net.output(in,false,ws);
      assertTrue(out.isAttached());
      assertEquals(wsName,out.data().getParentWorkspace().getId());
    }
 catch (    Throwable t) {
      fail();
      throw new RuntimeException(t);
    }
    System.out.println("MLN SCOPE ACTIVE: " + i + " - "+ workspace.isScopeActive());
    assertFalse(workspace.isScopeActive());
  }
  ComputationGraph cg=net.toComputationGraph();
  for (int i=0; i < 3; i++) {
    try (MemoryWorkspace ws=workspace.notifyScopeEntered()){
      System.out.println("CG - " + i);
      INDArray out=cg.output(false,ws,in)[0];
      assertTrue(out.isAttached());
      assertEquals(wsName,out.data().getParentWorkspace().getId());
    }
 catch (    Throwable t) {
      throw new RuntimeException(t);
    }
    System.out.println("CG SCOPE ACTIVE: " + i + " - "+ workspace.isScopeActive());
    assertFalse(workspace.isScopeActive());
  }
  Nd4j.getWorkspaceManager().printAllocationStatisticsForCurrentThread();
}
