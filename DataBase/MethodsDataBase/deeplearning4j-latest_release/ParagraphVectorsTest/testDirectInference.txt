@Test public void testDirectInference() throws Exception {
  ClassPathResource resource_sentences=new ClassPathResource("/big/raw_sentences.txt");
  ClassPathResource resource_mixed=new ClassPathResource("/paravec");
  SentenceIterator iter=new AggregatingSentenceIterator.Builder().addSentenceIterator(new BasicLineIterator(resource_sentences.getFile())).addSentenceIterator(new FileSentenceIterator(resource_mixed.getFile())).build();
  TokenizerFactory t=new DefaultTokenizerFactory();
  t.setTokenPreProcessor(new CommonPreprocessor());
  Word2Vec wordVectors=new Word2Vec.Builder().minWordFrequency(1).batchSize(250).iterations(1).epochs(3).learningRate(0.025).layerSize(150).minLearningRate(0.001).elementsLearningAlgorithm(new SkipGram<VocabWord>()).useHierarchicSoftmax(true).windowSize(5).iterate(iter).tokenizerFactory(t).build();
  wordVectors.fit();
  ParagraphVectors pv=new ParagraphVectors.Builder().tokenizerFactory(t).iterations(10).useHierarchicSoftmax(true).trainWordVectors(true).useExistingWordVectors(wordVectors).negativeSample(0).sequenceLearningAlgorithm(new DM<VocabWord>()).build();
  INDArray vec1=pv.inferVector("This text is pretty awesome");
  INDArray vec2=pv.inferVector("Fantastic process of crazy things happening inside just for history purposes");
  log.info("vec1/vec2: {}",Transforms.cosineSim(vec1,vec2));
}
