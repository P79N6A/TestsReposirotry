@Test public void testMathOps(){
  ParameterSpace<Integer> firstLayerSize=new IntegerParameterSpace(10,30);
  ParameterSpace<Integer> secondLayerSize=new MathOp<>(firstLayerSize,Op.MUL,3);
  ParameterSpace<Double> firstLayerLR=new ContinuousParameterSpace(0.01,0.1);
  ParameterSpace<Double> secondLayerLR=new MathOp<>(firstLayerLR,Op.ADD,0.2);
  MultiLayerSpace mls=new MultiLayerSpace.Builder().updater(new Sgd(0.005)).seed(12345).layer(new DenseLayerSpace.Builder().nOut(firstLayerSize).updater(new AdamSpace(firstLayerLR)).build()).layer(new OutputLayerSpace.Builder().nOut(secondLayerSize).updater(new AdamSpace(secondLayerLR)).activation(Activation.SOFTMAX).build()).setInputType(InputType.feedForward(10)).build();
  int nParams=mls.numParameters();
  assertEquals(2,nParams);
  new RandomSearchGenerator(mls,null);
  Random r=new Random(12345);
  for (int i=0; i < 10; i++) {
    double[] d=new double[nParams];
    for (int j=0; j < d.length; j++) {
      d[j]=r.nextDouble();
    }
    MultiLayerConfiguration conf=mls.getValue(d).getMultiLayerConfiguration();
    long l0Size=((FeedForwardLayer)conf.getConf(0).getLayer()).getNOut();
    long l1Size=((FeedForwardLayer)conf.getConf(1).getLayer()).getNOut();
    assertEquals(3 * l0Size,l1Size);
    double l0Lr=((FeedForwardLayer)conf.getConf(0).getLayer()).getIUpdater().getLearningRate(0,0);
    double l1Lr=((FeedForwardLayer)conf.getConf(1).getLayer()).getIUpdater().getLearningRate(0,0);
    assertEquals(l0Lr + 0.2,l1Lr,1e-6);
  }
}
