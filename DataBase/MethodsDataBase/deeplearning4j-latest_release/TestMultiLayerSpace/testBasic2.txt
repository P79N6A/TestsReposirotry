@Test public void testBasic2(){
  MultiLayerSpace mls=new MultiLayerSpace.Builder().updater(new SgdSpace(new ContinuousParameterSpace(0.0001,0.1))).l2(new ContinuousParameterSpace(0.2,0.5)).convolutionMode(ConvolutionMode.Same).addLayer(new ConvolutionLayerSpace.Builder().nIn(3).nOut(3).kernelSize(2,2).stride(1,1).build()).addLayer(new DenseLayerSpace.Builder().nIn(10).nOut(10).activation(new DiscreteParameterSpace<>(Activation.RELU,Activation.TANH)).build(),new IntegerParameterSpace(1,3)).addLayer(new OutputLayerSpace.Builder().nIn(10).nOut(10).activation(Activation.SOFTMAX).build()).pretrain(false).backprop(true).build();
  int nParams=mls.numParameters();
  assertEquals(4,nParams);
  List<ParameterSpace> noDuplicatesList=LeafUtils.getUniqueObjects(mls.collectLeaves());
  int c=0;
  for (  ParameterSpace ps : noDuplicatesList) {
    int np=ps.numParameters();
    if (np == 1) {
      ps.setIndices(c++);
    }
 else {
      int[] values=new int[np];
      for (int j=0; j < np; j++)       values[c++]=j;
      ps.setIndices(values);
    }
  }
  int[] nLayerCounts=new int[3];
  int reluCount=0;
  int tanhCount=0;
  Random r=new Random(12345);
  for (int i=0; i < 50; i++) {
    double[] rvs=new double[nParams];
    for (int j=0; j < rvs.length; j++)     rvs[j]=r.nextDouble();
    MultiLayerConfiguration conf=mls.getValue(rvs).getMultiLayerConfiguration();
    assertEquals(false,conf.isPretrain());
    assertEquals(true,conf.isBackprop());
    int nLayers=conf.getConfs().size();
    assertTrue(nLayers >= 3 && nLayers <= 5);
    int nLayersExOutputLayer=nLayers - 1;
    nLayerCounts[nLayersExOutputLayer - 2]++;
    for (int j=0; j < nLayers; j++) {
      NeuralNetConfiguration layerConf=conf.getConf(j);
      double lr=((Sgd)((BaseLayer)layerConf.getLayer()).getIUpdater()).getLearningRate();
      assertTrue(lr >= 0.0001 && lr <= 0.1);
      double l2=((BaseLayer)layerConf.getLayer()).getL2();
      assertTrue(l2 >= 0.2 && l2 <= 0.5);
      if (j == nLayers - 1) {
        assertEquals(Activation.SOFTMAX.getActivationFunction(),((BaseLayer)layerConf.getLayer()).getActivationFn());
      }
 else       if (j == 0) {
        ConvolutionLayer cl=(ConvolutionLayer)layerConf.getLayer();
        assertEquals(3,cl.getNIn());
        assertEquals(3,cl.getNOut());
        assertEquals(ConvolutionMode.Same,cl.getConvolutionMode());
      }
 else {
        IActivation actFn=((BaseLayer)layerConf.getLayer()).getActivationFn();
        assertTrue(Activation.RELU.getActivationFunction().equals(actFn) || Activation.TANH.getActivationFunction().equals(actFn));
        if (Activation.RELU.getActivationFunction().equals(actFn))         reluCount++;
 else         tanhCount++;
      }
    }
  }
  for (int i=0; i < 3; i++) {
    assertTrue(nLayerCounts[i] >= 5);
  }
  System.out.println("Number of layers: " + Arrays.toString(nLayerCounts));
  System.out.println("ReLU vs. Tanh: " + reluCount + "\t"+ tanhCount);
}
