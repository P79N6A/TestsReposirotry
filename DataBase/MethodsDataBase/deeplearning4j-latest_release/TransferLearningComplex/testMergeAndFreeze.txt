@Test public void testMergeAndFreeze(){
  ComputationGraphConfiguration conf=new NeuralNetConfiguration.Builder().updater(new Adam(1e-4)).activation(Activation.LEAKYRELU).graphBuilder().addInputs("in1","in2").addLayer("A",new DenseLayer.Builder().nIn(10).nOut(9).build(),"in1").addLayer("B",new DenseLayer.Builder().nIn(9).nOut(8).build(),"A").addLayer("C",new DenseLayer.Builder().nIn(7).nOut(6).build(),"in2").addLayer("D",new DenseLayer.Builder().nIn(8 + 7).nOut(5).build(),"B","C").addLayer("out",new OutputLayer.Builder().nIn(5).nOut(4).activation(Activation.LEAKYRELU).build(),"D").setOutputs("out").validateOutputLayerConfig(false).build();
  ComputationGraph graph=new ComputationGraph(conf);
  graph.init();
  int[] topologicalOrder=graph.topologicalSortOrder();
  org.deeplearning4j.nn.graph.vertex.GraphVertex[] vertices=graph.getVertices();
  for (int i=0; i < topologicalOrder.length; i++) {
    org.deeplearning4j.nn.graph.vertex.GraphVertex v=vertices[topologicalOrder[i]];
    log.info(i + "\t" + v.getVertexName());
  }
  ComputationGraph graph2=new TransferLearning.GraphBuilder(graph).fineTuneConfiguration(new FineTuneConfiguration.Builder().updater(new Adam(2e-2)).build()).setFeatureExtractor("C").validateOutputLayerConfig(false).build();
  boolean cFound=false;
  Layer[] layers=graph2.getLayers();
  for (  Layer l : layers) {
    String name=l.conf().getLayer().getLayerName();
    log.info(name + "\t frozen: " + (l instanceof FrozenLayer));
    if ("C".equals(l.conf().getLayer().getLayerName())) {
      cFound=true;
      assertTrue(name,l instanceof FrozenLayer);
    }
 else {
      assertFalse(name,l instanceof FrozenLayer);
    }
    BaseLayer bl=((BaseLayer)l.conf().getLayer());
    assertEquals(new Adam(2e-2),bl.getIUpdater());
    assertEquals(Activation.LEAKYRELU.getActivationFunction(),bl.getActivationFn());
  }
  assertTrue(cFound);
}
