@Test public void testCompareCudnnStandardOutputsVsMode() throws Exception {
  ConvolutionMode[] cm=new ConvolutionMode[]{ConvolutionMode.Strict,ConvolutionMode.Truncate,ConvolutionMode.Same};
  for (  ConvolutionMode c : cm) {
    for (    ConvolutionLayer.AlgoMode a : new ConvolutionLayer.AlgoMode[]{ConvolutionLayer.AlgoMode.NO_WORKSPACE,ConvolutionLayer.AlgoMode.PREFER_FASTEST}) {
      for (      boolean conv : new boolean[]{true,false}) {
        org.deeplearning4j.nn.conf.layers.Layer l;
        if (conv) {
          l=new ConvolutionLayer.Builder().nOut(4).kernelSize(4,4).stride(2,2).build();
        }
 else {
          l=new SubsamplingLayer.Builder().kernelSize(4,4).stride(2,2).build();
        }
        MultiLayerConfiguration conf=new NeuralNetConfiguration.Builder().seed(12345).l2(0.0005).updater(new Sgd(0.01)).weightInit(WeightInit.XAVIER).convolutionMode(c).cudnnAlgoMode(a).list().layer(0,l).layer(1,new OutputLayer.Builder(LossFunctions.LossFunction.NEGATIVELOGLIKELIHOOD).nOut(10).activation(Activation.SOFTMAX).build()).setInputType(InputType.convolutionalFlat(28,28,1)).build();
        if (conv) {
          assertEquals(a,((ConvolutionLayer)l).getCudnnAlgoMode());
        }
        Nd4j.getRandom().setSeed(12345);
        MultiLayerNetwork net1=new MultiLayerNetwork(conf);
        net1.init();
        net1.initGradientsView();
        Nd4j.getRandom().setSeed(12345);
        MultiLayerNetwork net2=new MultiLayerNetwork(conf);
        net2.init();
        net2.initGradientsView();
        Layer layerCudnn=net1.getLayer(0);
        Layer layerStandard=net2.getLayer(0);
        Field f=layerStandard.getClass().getDeclaredField("helper");
        f.setAccessible(true);
        f.set(layerStandard,null);
        if (f.get(layerCudnn) == null)         throw new RuntimeException();
        if (f.get(layerStandard) != null)         throw new RuntimeException();
        INDArray in=Nd4j.rand(new int[]{1,1,20,20});
        INDArray outCudnn=layerCudnn.activate(in,false,LayerWorkspaceMgr.noWorkspaces());
        INDArray outStd=layerStandard.activate(in,false,LayerWorkspaceMgr.noWorkspaces());
        assertEquals(outStd,outCudnn);
        INDArray epsilon=Nd4j.rand(outStd.shape());
        Pair<Gradient,INDArray> pCudnn=layerCudnn.backpropGradient(epsilon,LayerWorkspaceMgr.noWorkspaces());
        Pair<Gradient,INDArray> pStd=layerStandard.backpropGradient(epsilon,LayerWorkspaceMgr.noWorkspaces());
        System.out.println(Arrays.toString(pStd.getSecond().data().asFloat()));
        System.out.println(Arrays.toString(pCudnn.getSecond().data().asFloat()));
        INDArray epsOutStd=pStd.getSecond();
        INDArray epsOutCudnn=pCudnn.getSecond();
        assertTrue(epsOutStd.equalsWithEps(epsOutCudnn,1e-4));
        if (conv) {
          INDArray gradStd=pStd.getFirst().gradient();
          INDArray gradCudnn=pCudnn.getFirst().gradient();
          assertTrue(gradStd.equalsWithEps(gradCudnn,1e-4));
        }
      }
    }
  }
}
