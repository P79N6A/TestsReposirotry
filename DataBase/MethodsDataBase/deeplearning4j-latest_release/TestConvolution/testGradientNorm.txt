@Test public void testGradientNorm() throws Exception {
  int height=100;
  int width=100;
  int channels=1;
  int numLabels=10;
  for (  int batchSize : new int[]{1,32}) {
    long seed=12345;
    double nonZeroBias=1;
    MultiLayerConfiguration conf=new NeuralNetConfiguration.Builder().seed(seed).weightInit(WeightInit.DISTRIBUTION).dist(new NormalDistribution(0.0,0.01)).activation(Activation.RELU).updater(new Adam(5e-3)).gradientNormalization(GradientNormalization.RenormalizeL2PerLayer).l2(5 * 1e-4).list().layer(convInit("cnn1",channels,96,new int[]{11,11},new int[]{4,4},new int[]{3,3},0)).layer(maxPool("maxpool1",new int[]{3,3})).layer(conv5x5("cnn2",256,new int[]{1,1},new int[]{2,2},nonZeroBias)).layer(maxPool("maxpool2",new int[]{3,3})).layer(conv3x3("cnn3",384,0)).layer(conv3x3("cnn4",384,nonZeroBias)).layer(conv3x3("cnn5",256,nonZeroBias)).layer(maxPool("maxpool3",new int[]{3,3})).layer(fullyConnected("ffn1",4096,nonZeroBias,new GaussianDistribution(0,0.005))).layer(fullyConnected("ffn2",4096,nonZeroBias,new GaussianDistribution(0,0.005))).layer(new OutputLayer.Builder(LossFunctions.LossFunction.NEGATIVELOGLIKELIHOOD).name("output").nOut(numLabels).activation(Activation.SOFTMAX).build()).backprop(true).pretrain(false).setInputType(InputType.convolutional(height,width,channels)).build();
    MultiLayerNetwork netNoCudnn=new MultiLayerNetwork(conf.clone());
    netNoCudnn.init();
    MultiLayerNetwork netWithCudnn=new MultiLayerNetwork(conf.clone());
    netWithCudnn.init();
    CuDNNTestUtils.removeHelpers(netNoCudnn.getLayers());
    Nd4j.getRandom().setSeed(12345);
    for (int j=0; j < 3; j++) {
      INDArray f=Nd4j.rand(new int[]{batchSize,channels,height,width});
      INDArray l=TestUtils.randomOneHot(batchSize,numLabels);
      netNoCudnn.fit(f,l);
      netWithCudnn.fit(f,l);
      assertEquals(netNoCudnn.score(),netWithCudnn.score(),1e-5);
      for (      Map.Entry<String,INDArray> e : netNoCudnn.paramTable().entrySet()) {
        boolean pEq=e.getValue().equalsWithEps(netWithCudnn.paramTable().get(e.getKey()),1e-4);
        assertTrue(pEq);
      }
      boolean eq=netNoCudnn.params().equalsWithEps(netWithCudnn.params(),1e-4);
      assertTrue(eq);
    }
  }
}
