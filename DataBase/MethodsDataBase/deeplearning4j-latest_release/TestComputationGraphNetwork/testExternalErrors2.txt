@Test public void testExternalErrors2(){
  Nd4j.getExecutioner().setProfilingMode(OpExecutioner.ProfilingMode.SCOPE_PANIC);
  int nIn=4;
  int nOut=3;
  for (  WorkspaceMode ws : WorkspaceMode.values()) {
    System.out.println("***** WORKSPACE: " + ws);
    ComputationGraphConfiguration conf=new NeuralNetConfiguration.Builder().updater(new Adam(0.01)).trainingWorkspaceMode(ws).inferenceWorkspaceMode(ws).graphBuilder().addInputs("features").addVertex("rnn2ffn",new PreprocessorVertex(new RnnToFeedForwardPreProcessor()),"features").addLayer("predict",new DenseLayer.Builder().nIn(nIn).nOut(nOut).activation(Activation.RELU).build(),"rnn2ffn").addVertex("ffn2rnn",new PreprocessorVertex(new FeedForwardToRnnPreProcessor()),"predict").addLayer("output",new ActivationLayer.Builder().activation(Activation.IDENTITY).build(),"ffn2rnn").setOutputs("output").build();
    ComputationGraph graph=new ComputationGraph(conf);
    graph.init();
    final int minibatch=5;
    final int seqLen=6;
    INDArray param=Nd4j.create(new double[]{0.54,0.31,0.98,-0.30,-0.66,-0.19,-0.29,-0.62,0.13,-0.32,0.01,-0.03,0.00,0.00,0.00});
    graph.setParams(param);
    INDArray input=Nd4j.rand(new int[]{minibatch,nIn,seqLen},12);
    INDArray expected=Nd4j.ones(minibatch,nOut,seqLen);
    INDArray output=graph.outputSingle(false,false,input);
    INDArray error=output.sub(expected);
    for (    org.deeplearning4j.nn.api.Layer l : graph.getLayers()) {
      assertNotNull(l.input());
      assertFalse(l.input().isAttached());
    }
    Gradient gradient=graph.backpropGradient(error);
    graph.getUpdater().update(gradient,0,0,minibatch,LayerWorkspaceMgr.noWorkspaces());
    Nd4j.getWorkspaceManager().destroyAllWorkspacesForCurrentThread();
  }
  Nd4j.getExecutioner().setProfilingMode(OpExecutioner.ProfilingMode.DISABLED);
}
