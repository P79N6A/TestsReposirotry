@Test public void testSummary(){
  int V_WIDTH=130;
  int V_HEIGHT=130;
  int V_NFRAMES=150;
  ComputationGraphConfiguration confForArchitecture=new NeuralNetConfiguration.Builder().seed(12345).l2(0.001).updater(new AdaGrad(0.4)).graphBuilder().addInputs("in").addLayer("layer0",new ConvolutionLayer.Builder(10,10).nIn(3).nOut(30).stride(4,4).activation(Activation.RELU).weightInit(WeightInit.RELU).build(),"in").addLayer("layer1",new SubsamplingLayer.Builder(SubsamplingLayer.PoolingType.MAX).kernelSize(3,3).stride(2,2).build(),"layer0").addLayer("layer2",new ConvolutionLayer.Builder(3,3).nIn(30).nOut(10).stride(2,2).activation(Activation.RELU).weightInit(WeightInit.RELU).updater(Updater.ADAGRAD).build(),"layer1").addLayer("layer3",new DenseLayer.Builder().activation(Activation.RELU).nIn(490).nOut(50).weightInit(WeightInit.RELU).gradientNormalization(GradientNormalization.ClipElementWiseAbsoluteValue).gradientNormalizationThreshold(10).build(),"layer2").addLayer("layer4",new GravesLSTM.Builder().activation(Activation.SOFTSIGN).nIn(50).nOut(50).weightInit(WeightInit.XAVIER).updater(Updater.ADAGRAD).gradientNormalization(GradientNormalization.ClipElementWiseAbsoluteValue).gradientNormalizationThreshold(10).build(),"layer3").addLayer("layer5",new RnnOutputLayer.Builder(LossFunctions.LossFunction.MCXENT).activation(Activation.SOFTMAX).nIn(50).nOut(4).weightInit(WeightInit.XAVIER).gradientNormalization(GradientNormalization.ClipElementWiseAbsoluteValue).gradientNormalizationThreshold(10).build(),"layer4").setOutputs("layer5").inputPreProcessor("layer0",new RnnToCnnPreProcessor(V_HEIGHT,V_WIDTH,3)).inputPreProcessor("layer3",new CnnToFeedForwardPreProcessor(7,7,10)).inputPreProcessor("layer4",new FeedForwardToRnnPreProcessor()).backpropType(BackpropType.TruncatedBPTT).tBPTTForwardLength(V_NFRAMES / 5).tBPTTBackwardLength(V_NFRAMES / 5).build();
  ComputationGraph modelExpectedArch=new ComputationGraph(confForArchitecture);
  modelExpectedArch.init();
  ComputationGraph modelMow=new TransferLearning.GraphBuilder(modelExpectedArch).setFeatureExtractor("layer2").build();
  System.out.println(modelExpectedArch.summary());
  System.out.println(modelMow.summary());
  System.out.println(modelExpectedArch.summary(InputType.recurrent(V_HEIGHT * V_WIDTH * 3)));
}
