@Test public void testSerialization() throws Exception {
  for (  WorkspaceMode wsm : WorkspaceMode.values()) {
    log.info("*** Starting workspace mode: " + wsm);
    Nd4j.getRandom().setSeed(12345);
    MultiLayerConfiguration conf1=new NeuralNetConfiguration.Builder().activation(Activation.TANH).weightInit(WeightInit.XAVIER).trainingWorkspaceMode(wsm).inferenceWorkspaceMode(wsm).updater(new Adam()).list().layer(new Bidirectional(Bidirectional.Mode.ADD,new GravesLSTM.Builder().nIn(10).nOut(10).build())).layer(new Bidirectional(Bidirectional.Mode.ADD,new GravesLSTM.Builder().nIn(10).nOut(10).build())).layer(new RnnOutputLayer.Builder().lossFunction(LossFunctions.LossFunction.MSE).nIn(10).nOut(10).build()).build();
    MultiLayerNetwork net1=new MultiLayerNetwork(conf1);
    net1.init();
    INDArray in=Nd4j.rand(new int[]{3,10,5});
    INDArray labels=Nd4j.rand(new int[]{3,10,5});
    net1.fit(in,labels);
    byte[] bytes;
    try (ByteArrayOutputStream baos=new ByteArrayOutputStream()){
      ModelSerializer.writeModel(net1,baos,true);
      bytes=baos.toByteArray();
    }
     MultiLayerNetwork net2=ModelSerializer.restoreMultiLayerNetwork(new ByteArrayInputStream(bytes),true);
    in=Nd4j.rand(new int[]{3,10,5});
    labels=Nd4j.rand(new int[]{3,10,5});
    INDArray out1=net1.output(in);
    INDArray out2=net2.output(in);
    assertEquals(out1,out2);
    net1.setInput(in);
    net2.setInput(in);
    net1.setLabels(labels);
    net2.setLabels(labels);
    net1.computeGradientAndScore();
    net2.computeGradientAndScore();
    assertEquals(net1.score(),net2.score(),1e-6);
    assertEquals(net1.gradient().gradient(),net2.gradient().gradient());
  }
}
