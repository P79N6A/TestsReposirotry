@Test public void testSerializationCompGraph() throws Exception {
  for (  WorkspaceMode wsm : WorkspaceMode.values()) {
    log.info("*** Starting workspace mode: " + wsm);
    Nd4j.getRandom().setSeed(12345);
    ComputationGraphConfiguration conf1=new NeuralNetConfiguration.Builder().activation(Activation.TANH).weightInit(WeightInit.XAVIER).trainingWorkspaceMode(wsm).inferenceWorkspaceMode(wsm).updater(new Adam()).graphBuilder().addInputs("in").layer("0",new Bidirectional(Bidirectional.Mode.ADD,new GravesLSTM.Builder().nIn(10).nOut(10).build()),"in").layer("1",new Bidirectional(Bidirectional.Mode.ADD,new GravesLSTM.Builder().nIn(10).nOut(10).build()),"0").layer("2",new RnnOutputLayer.Builder().lossFunction(LossFunctions.LossFunction.MSE).nIn(10).nOut(10).build(),"1").setOutputs("2").build();
    ComputationGraph net1=new ComputationGraph(conf1);
    net1.init();
    INDArray in=Nd4j.rand(new int[]{3,10,5});
    INDArray labels=Nd4j.rand(new int[]{3,10,5});
    net1.fit(new DataSet(in,labels));
    byte[] bytes;
    try (ByteArrayOutputStream baos=new ByteArrayOutputStream()){
      ModelSerializer.writeModel(net1,baos,true);
      bytes=baos.toByteArray();
    }
     ComputationGraph net2=ModelSerializer.restoreComputationGraph(new ByteArrayInputStream(bytes),true);
    in=Nd4j.rand(new int[]{3,10,5});
    labels=Nd4j.rand(new int[]{3,10,5});
    INDArray out1=net1.outputSingle(in);
    INDArray out2=net2.outputSingle(in);
    assertEquals(out1,out2);
    net1.setInput(0,in);
    net2.setInput(0,in);
    net1.setLabels(labels);
    net2.setLabels(labels);
    net1.computeGradientAndScore();
    net2.computeGradientAndScore();
    assertEquals(net1.score(),net2.score(),1e-6);
    assertEquals(net1.gradient().gradient(),net2.gradient().gradient());
  }
}
