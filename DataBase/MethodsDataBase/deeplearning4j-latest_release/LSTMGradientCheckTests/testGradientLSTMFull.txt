@Test public void testGradientLSTMFull(){
  int timeSeriesLength=8;
  int nIn=7;
  int layerSize=9;
  int nOut=4;
  int miniBatchSize=6;
  boolean[] gravesLSTM=new boolean[]{true,false};
  for (  boolean graves : gravesLSTM) {
    Random r=new Random(12345L);
    INDArray input=Nd4j.rand(new int[]{miniBatchSize,nIn,timeSeriesLength},'f').subi(0.5);
    INDArray labels=Nd4j.zeros(miniBatchSize,nOut,timeSeriesLength);
    for (int i=0; i < miniBatchSize; i++) {
      for (int j=0; j < timeSeriesLength; j++) {
        int idx=r.nextInt(nOut);
        labels.putScalar(new int[]{i,idx,j},1.0f);
      }
    }
    double[] l2vals={0.4,0.0,0.4,0.4};
    double[] l1vals={0.0,0.0,0.5,0.0};
    double[] biasL2={0.0,0.0,0.0,0.2};
    double[] biasL1={0.0,0.0,0.6,0.0};
    Activation[] activFns={Activation.TANH,Activation.SOFTSIGN,Activation.TANH,Activation.TANH};
    LossFunction[] lossFunctions={LossFunction.MCXENT,LossFunction.MSE,LossFunction.MSE,LossFunction.MCXENT};
    Activation[] outputActivations={Activation.SOFTMAX,Activation.TANH,Activation.IDENTITY,Activation.SOFTMAX};
    for (int i=0; i < l2vals.length; i++) {
      LossFunction lf=lossFunctions[i];
      Activation outputActivation=outputActivations[i];
      double l2=l2vals[i];
      double l1=l1vals[i];
      Activation afn=activFns[i];
      NeuralNetConfiguration.Builder conf=new NeuralNetConfiguration.Builder().seed(12345L).weightInit(WeightInit.DISTRIBUTION).dist(new NormalDistribution(0,1)).updater(new NoOp());
      if (l1 > 0.0)       conf.l1(l1);
      if (l2 > 0.0)       conf.l2(l2);
      if (biasL2[i] > 0)       conf.l2Bias(biasL2[i]);
      if (biasL1[i] > 0)       conf.l1Bias(biasL1[i]);
      Layer layer;
      if (graves) {
        layer=new GravesLSTM.Builder().nIn(nIn).nOut(layerSize).activation(afn).build();
      }
 else {
        layer=new LSTM.Builder().nIn(nIn).nOut(layerSize).activation(afn).build();
      }
      NeuralNetConfiguration.ListBuilder conf2=conf.list().layer(0,layer).layer(1,new RnnOutputLayer.Builder(lf).activation(outputActivation).nIn(layerSize).nOut(nOut).build());
      MultiLayerNetwork mln=new MultiLayerNetwork(conf2.build());
      mln.init();
      String testName="testGradientLSTMFull(" + (graves ? "GravesLSTM" : "LSTM") + " - activationFn="+ afn+ ", lossFn="+ lf+ ", outputActivation="+ outputActivation+ ", l2="+ l2+ ", l1="+ l1;
      if (PRINT_RESULTS) {
        System.out.println(testName);
        for (int j=0; j < mln.getnLayers(); j++)         System.out.println("Layer " + j + " # params: "+ mln.getLayer(j).numParams());
      }
      boolean gradOK=GradientCheckUtil.checkGradients(mln,DEFAULT_EPS,DEFAULT_MAX_REL_ERROR,DEFAULT_MIN_ABS_ERROR,PRINT_RESULTS,RETURN_ON_FIRST_FAILURE,input,labels);
      assertTrue(testName,gradOK);
      TestUtils.testModelSerialization(mln);
    }
  }
}
