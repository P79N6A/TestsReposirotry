@Test public void testChangeLrCompGraph(){
  ComputationGraphConfiguration conf=new NeuralNetConfiguration.Builder().activation(Activation.TANH).seed(12345).graphBuilder().addInputs("in").addLayer("0",new DenseLayer.Builder().nIn(10).nOut(10).updater(new Adam(0.1)).build(),"in").addLayer("1",new DenseLayer.Builder().nIn(10).nOut(10).updater(new RmsProp(0.01)).build(),"0").addLayer("2",new OutputLayer.Builder().nIn(10).nOut(10).updater(new NoOp()).lossFunction(LossFunctions.LossFunction.MSE).build(),"1").setOutputs("2").build();
  ComputationGraph net=new ComputationGraph(conf);
  net.init();
  for (int i=0; i < 10; i++) {
    net.fit(new DataSet(Nd4j.rand(10,10),Nd4j.rand(10,10)));
  }
  ComputationGraphConfiguration conf2=new NeuralNetConfiguration.Builder().activation(Activation.TANH).seed(12345).graphBuilder().addInputs("in").addLayer("0",new DenseLayer.Builder().nIn(10).nOut(10).updater(new Adam(0.5)).build(),"in").addLayer("1",new DenseLayer.Builder().nIn(10).nOut(10).updater(new RmsProp(0.01)).build(),"0").addLayer("2",new OutputLayer.Builder().nIn(10).nOut(10).updater(new NoOp()).lossFunction(LossFunctions.LossFunction.MSE).build(),"1").setOutputs("2").build();
  ComputationGraph net2=new ComputationGraph(conf2);
  net2.init();
  net2.getUpdater().getStateViewArray().assign(net.getUpdater().getStateViewArray());
  conf2.setIterationCount(conf.getIterationCount());
  net2.setParams(net.params().dup());
  assertEquals(0.1,net.getLearningRate("0").doubleValue(),0.0);
  net.setLearningRate("0",0.5);
  assertEquals(0.5,net.getLearningRate("0").doubleValue(),0.0);
  assertEquals(conf,conf2);
  assertEquals(conf.toJson(),conf2.toJson());
  assertEquals(net.getUpdater().getStateViewArray(),net2.getUpdater().getStateViewArray());
  for (int i=0; i < 3; i++) {
    INDArray in=Nd4j.rand(10,10);
    INDArray l=Nd4j.rand(10,10);
    net.fit(new DataSet(in,l));
    net2.fit(new DataSet(in,l));
  }
  assertEquals(net.params(),net2.params());
  assertEquals(net.getUpdater().getStateViewArray(),net2.getUpdater().getStateViewArray());
  INDArray in1=Nd4j.rand(10,10);
  INDArray l1=Nd4j.rand(10,10);
  net.setInputs(in1);
  net.setLabels(l1);
  net.computeGradientAndScore();
  net2.setInputs(in1);
  net2.setLabels(l1);
  net2.computeGradientAndScore();
  assertEquals(net.score(),net2.score(),1e-8);
  MultiLayerConfiguration conf3=new NeuralNetConfiguration.Builder().activation(Activation.TANH).seed(12345).list().layer(new DenseLayer.Builder().nIn(10).nOut(10).updater(new Adam(0.3)).build()).layer(new DenseLayer.Builder().nIn(10).nOut(10).updater(new RmsProp(0.3)).build()).layer(new OutputLayer.Builder().nIn(10).nOut(10).updater(new NoOp()).lossFunction(LossFunctions.LossFunction.MSE).build()).build();
  MultiLayerNetwork net3=new MultiLayerNetwork(conf3);
  net3.init();
  net3.getUpdater().getStateViewArray().assign(net.getUpdater().getStateViewArray());
  conf3.setIterationCount(conf.getIterationCount());
  net3.setParams(net.params().dup());
  net.setLearningRate(0.3);
  for (int i=0; i < 3; i++) {
    INDArray in=Nd4j.rand(10,10);
    INDArray l=Nd4j.rand(10,10);
    net.fit(new DataSet(in,l));
    net3.fit(new DataSet(in,l));
  }
  assertEquals(net.params(),net3.params());
  assertEquals(net.getUpdater().getStateViewArray(),net3.getUpdater().getStateViewArray());
}
