@Test public void testVaePretrain(){
  Nd4j.getRandom().setSeed(12345);
  Activation[] activFns={Activation.IDENTITY,Activation.TANH,Activation.IDENTITY,Activation.TANH};
  LossFunction[] lossFunctions={LossFunction.MCXENT,LossFunction.MCXENT,LossFunction.MSE,LossFunction.MSE};
  Activation[] outputActivations={Activation.SOFTMAX,Activation.SOFTMAX,Activation.TANH,Activation.TANH};
  Activation[] pzxAfns={Activation.IDENTITY,Activation.TANH,Activation.IDENTITY,Activation.TANH};
  Activation[] pxzAfns={Activation.TANH,Activation.IDENTITY,Activation.TANH,Activation.TANH};
  double[] l2vals={0.4,0.0,0.4,0.4};
  double[] l1vals={0.0,0.0,0.5,0.0};
  double[] biasL2={0.0,0.0,0.0,0.2};
  double[] biasL1={0.0,0.0,0.6,0.0};
  int[][] encoderLayerSizes=new int[][]{{5},{5},{5,6},{5,6}};
  int[][] decoderLayerSizes=new int[][]{{6},{7,8},{6},{7,8}};
  int[] minibatches=new int[]{1,5,4,3};
  Nd4j.getRandom().setSeed(12345);
  for (int i=0; i < activFns.length; i++) {
    LossFunction lf=lossFunctions[i];
    Activation outputActivation=outputActivations[i];
    double l2=l2vals[i];
    double l1=l1vals[i];
    int[] encoderSizes=encoderLayerSizes[i];
    int[] decoderSizes=decoderLayerSizes[i];
    int minibatch=minibatches[i];
    INDArray input=Nd4j.rand(minibatch,4);
    INDArray labels=Nd4j.create(minibatch,3);
    for (int j=0; j < minibatch; j++) {
      labels.putScalar(j,j % 3,1.0);
    }
    Activation afn=activFns[i];
    Activation pzxAfn=pzxAfns[i];
    Activation pxzAfn=pxzAfns[i];
    MultiLayerConfiguration conf=new NeuralNetConfiguration.Builder().l2(l2).l1(l1).l2Bias(biasL2[i]).l1Bias(biasL1[i]).updater(new NoOp()).seed(12345L).weightInit(WeightInit.XAVIER).list().layer(0,new VariationalAutoencoder.Builder().nIn(4).nOut(3).encoderLayerSizes(encoderSizes).decoderLayerSizes(decoderSizes).pzxActivationFunction(pzxAfn).reconstructionDistribution(new GaussianReconstructionDistribution(pxzAfn)).activation(afn).build()).pretrain(true).backprop(false).build();
    MultiLayerNetwork mln=new MultiLayerNetwork(conf);
    mln.init();
    mln.initGradientsView();
    org.deeplearning4j.nn.api.Layer layer=mln.getLayer(0);
    String msg="testVaePretrain() - activationFn=" + afn + ", p(z|x) afn = "+ pzxAfn+ ", p(x|z) afn = "+ pxzAfn+ ", encLayerSizes = "+ Arrays.toString(encoderSizes)+ ", decLayerSizes = "+ Arrays.toString(decoderSizes)+ ", l2="+ l2+ ", l1="+ l1;
    if (PRINT_RESULTS) {
      System.out.println(msg);
      for (int l=0; l < mln.getnLayers(); l++)       System.out.println("Layer " + l + " # params: "+ mln.getLayer(l).numParams());
    }
    boolean gradOK=GradientCheckUtil.checkGradientsPretrainLayer(layer,DEFAULT_EPS,DEFAULT_MAX_REL_ERROR,DEFAULT_MIN_ABS_ERROR,PRINT_RESULTS,RETURN_ON_FIRST_FAILURE,input,12345);
    assertTrue(msg,gradOK);
    TestUtils.testModelSerialization(mln);
  }
}
