@Test public void testVaePretrainReconstructionDistributions(){
  int inOutSize=6;
  ReconstructionDistribution[] reconstructionDistributions=new ReconstructionDistribution[]{new GaussianReconstructionDistribution(Activation.IDENTITY),new GaussianReconstructionDistribution(Activation.TANH),new BernoulliReconstructionDistribution(Activation.SIGMOID),new CompositeReconstructionDistribution.Builder().addDistribution(2,new GaussianReconstructionDistribution(Activation.IDENTITY)).addDistribution(2,new BernoulliReconstructionDistribution()).addDistribution(2,new GaussianReconstructionDistribution(Activation.TANH)).build(),new ExponentialReconstructionDistribution(Activation.TANH),new LossFunctionWrapper(new ActivationTanH(),new LossMSE())};
  Nd4j.getRandom().setSeed(12345);
  for (int i=0; i < reconstructionDistributions.length; i++) {
    int minibatch=(i % 2 == 0 ? 1 : 3);
    INDArray data;
switch (i) {
case 0:
case 1:
      data=Nd4j.rand(minibatch,inOutSize);
    break;
case 2:
  data=Nd4j.create(minibatch,inOutSize);
Nd4j.getExecutioner().exec(new BernoulliDistribution(data,0.5),Nd4j.getRandom());
break;
case 3:
data=Nd4j.create(minibatch,inOutSize);
data.get(NDArrayIndex.all(),NDArrayIndex.interval(0,2)).assign(Nd4j.rand(minibatch,2));
Nd4j.getExecutioner().exec(new BernoulliDistribution(data.get(NDArrayIndex.all(),NDArrayIndex.interval(2,4)),0.5),Nd4j.getRandom());
data.get(NDArrayIndex.all(),NDArrayIndex.interval(4,6)).assign(Nd4j.rand(minibatch,2));
break;
case 4:
case 5:
data=Nd4j.rand(minibatch,inOutSize);
break;
default :
throw new RuntimeException();
}
MultiLayerConfiguration conf=new NeuralNetConfiguration.Builder().l2(0.2).l1(0.3).updater(new NoOp()).seed(12345L).weightInit(WeightInit.DISTRIBUTION).dist(new NormalDistribution(0,1)).list().layer(0,new VariationalAutoencoder.Builder().nIn(inOutSize).nOut(3).encoderLayerSizes(5).decoderLayerSizes(6).pzxActivationFunction(Activation.TANH).reconstructionDistribution(reconstructionDistributions[i]).activation(Activation.TANH).build()).pretrain(true).backprop(false).build();
MultiLayerNetwork mln=new MultiLayerNetwork(conf);
mln.init();
mln.initGradientsView();
org.deeplearning4j.nn.api.Layer layer=mln.getLayer(0);
String msg="testVaePretrainReconstructionDistributions() - " + reconstructionDistributions[i];
if (PRINT_RESULTS) {
System.out.println(msg);
for (int j=0; j < mln.getnLayers(); j++) System.out.println("Layer " + j + " # params: "+ mln.getLayer(j).numParams());
}
boolean gradOK=GradientCheckUtil.checkGradientsPretrainLayer(layer,DEFAULT_EPS,DEFAULT_MAX_REL_ERROR,DEFAULT_MIN_ABS_ERROR,PRINT_RESULTS,RETURN_ON_FIRST_FAILURE,data,12345);
assertTrue(msg,gradOK);
TestUtils.testModelSerialization(mln);
}
}
