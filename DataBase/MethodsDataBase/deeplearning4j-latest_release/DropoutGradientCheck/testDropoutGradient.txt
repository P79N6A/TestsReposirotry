@Test public void testDropoutGradient(){
  int minibatch=3;
  for (  boolean cnn : new boolean[]{false,true}) {
    for (int i=0; i < 5; i++) {
      IDropout dropout;
switch (i) {
case 0:
        dropout=new Dropout(0.6);
      break;
case 1:
    dropout=new AlphaDropout(0.6);
  break;
case 2:
dropout=new GaussianDropout(0.1);
break;
case 3:
dropout=new GaussianNoise(0.3);
break;
case 4:
dropout=new SpatialDropout(0.6);
break;
default :
throw new RuntimeException();
}
if (!cnn && i == 4) {
continue;
}
NeuralNetConfiguration.ListBuilder builder=new NeuralNetConfiguration.Builder().weightInit(WeightInit.DISTRIBUTION).dist(new NormalDistribution(0,1)).convolutionMode(ConvolutionMode.Same).dropOut(dropout).activation(Activation.TANH).updater(new NoOp()).list();
if (cnn) {
builder.layer(new ConvolutionLayer.Builder().kernelSize(3,3).stride(1,1).nOut(3).build());
builder.layer(new ConvolutionLayer.Builder().kernelSize(3,3).stride(1,1).nOut(3).build());
builder.setInputType(InputType.convolutional(8,8,3));
}
 else {
builder.layer(new DenseLayer.Builder().nOut(12).build());
builder.layer(new DenseLayer.Builder().nOut(12).build());
builder.setInputType(InputType.feedForward(8));
}
builder.layer(new OutputLayer.Builder().nOut(10).activation(Activation.SOFTMAX).lossFunction(LossFunction.MCXENT).build());
MultiLayerConfiguration conf=builder.build();
if (i == 4) {
conf.getConf(2).getLayer().setIDropout(null);
}
MultiLayerNetwork mln=new MultiLayerNetwork(conf);
mln.init();
String msg=(cnn ? "CNN" : "Dense") + ": " + dropout.getClass().getSimpleName();
INDArray f;
if (cnn) {
f=Nd4j.rand(new int[]{minibatch,3,8,8}).muli(10).subi(5);
}
 else {
f=Nd4j.rand(minibatch,8).muli(10).subi(5);
}
INDArray l=TestUtils.randomOneHot(minibatch,10);
log.info("*** Starting test: " + msg + " ***");
boolean gradOK=GradientCheckUtil.checkGradients(mln,DEFAULT_EPS,DEFAULT_MAX_REL_ERROR,DEFAULT_MIN_ABS_ERROR,PRINT_RESULTS,RETURN_ON_FIRST_FAILURE,f,l,null,null,false,-1,null,12345);
assertTrue(msg,gradOK);
TestUtils.testModelSerialization(mln);
}
}
}
