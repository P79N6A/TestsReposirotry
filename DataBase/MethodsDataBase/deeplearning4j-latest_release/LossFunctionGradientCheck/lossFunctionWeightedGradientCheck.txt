@Test public void lossFunctionWeightedGradientCheck(){
  Nd4j.getRandom().setSeed(12345);
  INDArray[] weights=new INDArray[]{Nd4j.create(new double[]{0.2,0.3,0.5}),Nd4j.create(new double[]{1.0,0.5,2.0})};
  List<String> passed=new ArrayList<>();
  List<String> failed=new ArrayList<>();
  for (  INDArray w : weights) {
    ILossFunction[] lossFunctions=new ILossFunction[]{new LossBinaryXENT(w),new LossL1(w),new LossL1(w),new LossL2(w),new LossL2(w),new LossMAE(w),new LossMAE(w),new LossMAPE(w),new LossMAPE(w),new LossMCXENT(w),new LossMSE(w),new LossMSE(w),new LossMSLE(w),new LossMSLE(w),new LossNegativeLogLikelihood(w),new LossNegativeLogLikelihood(w)};
    Activation[] outputActivationFn=new Activation[]{Activation.SIGMOID,Activation.TANH,Activation.SOFTMAX,Activation.TANH,Activation.SOFTMAX,Activation.IDENTITY,Activation.SOFTMAX,Activation.IDENTITY,Activation.SOFTMAX,Activation.SOFTMAX,Activation.IDENTITY,Activation.SOFTMAX,Activation.SIGMOID,Activation.SOFTMAX,Activation.SIGMOID,Activation.SOFTMAX};
    int[] minibatchSizes=new int[]{1,3};
    for (int i=0; i < lossFunctions.length; i++) {
      for (int j=0; j < minibatchSizes.length; j++) {
        String testName=lossFunctions[i] + " - " + outputActivationFn[i]+ " - minibatchSize = "+ minibatchSizes[j]+ "; weights = "+ w;
        Nd4j.getRandom().setSeed(12345);
        MultiLayerConfiguration conf=new NeuralNetConfiguration.Builder().optimizationAlgo(OptimizationAlgorithm.STOCHASTIC_GRADIENT_DESCENT).seed(12345).updater(new NoOp()).weightInit(WeightInit.DISTRIBUTION).dist(new NormalDistribution(0,1)).list().layer(0,new DenseLayer.Builder().nIn(4).nOut(4).activation(Activation.TANH).build()).layer(1,new OutputLayer.Builder().lossFunction(lossFunctions[i]).activation(outputActivationFn[i]).nIn(4).nOut(3).build()).validateOutputLayerConfig(false).build();
        MultiLayerNetwork net=new MultiLayerNetwork(conf);
        net.init();
        INDArray params=net.params();
        for (int x=0; x < params.length(); x++) {
          while (Math.abs(params.getDouble(x)) < 0.01 || Math.abs(params.getDouble(x)) > 1.5) {
            double d=Nd4j.getRandom().nextDouble();
            params.putScalar(x,-1.5 + d * 3);
          }
        }
        INDArray[] inOut=getFeaturesAndLabels(lossFunctions[i],minibatchSizes[j],4,3,12345);
        INDArray input=inOut[0];
        INDArray labels=inOut[1];
        log.info(" ***** Starting test: {} *****",testName);
        boolean gradOK;
        try {
          gradOK=GradientCheckUtil.checkGradients(net,DEFAULT_EPS,DEFAULT_MAX_REL_ERROR,DEFAULT_MIN_ABS_ERROR,PRINT_RESULTS,RETURN_ON_FIRST_FAILURE,input,labels);
        }
 catch (        Exception e) {
          e.printStackTrace();
          failed.add(testName + "\t" + "EXCEPTION");
          continue;
        }
        if (gradOK) {
          passed.add(testName);
        }
 else {
          failed.add(testName);
        }
        System.out.println("\n\n");
      }
    }
  }
  System.out.println("---- Passed ----");
  for (  String s : passed) {
    System.out.println(s);
  }
  System.out.println("---- Failed ----");
  for (  String s : failed) {
    System.out.println(s);
  }
  assertEquals("Tests failed",0,failed.size());
}
