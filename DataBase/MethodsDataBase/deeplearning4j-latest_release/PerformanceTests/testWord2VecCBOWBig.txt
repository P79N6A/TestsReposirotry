@Ignore @Test public void testWord2VecCBOWBig() throws Exception {
  SentenceIterator iter=new BasicLineIterator("/home/raver119/Downloads/corpus/namuwiki_raw.txt");
  TokenizerFactory t=new KoreanTokenizerFactory();
  Word2Vec vec=new Word2Vec.Builder().minWordFrequency(1).iterations(5).learningRate(0.025).layerSize(150).seed(42).sampling(0).negativeSample(0).useHierarchicSoftmax(true).windowSize(5).modelUtils(new BasicModelUtils<VocabWord>()).useAdaGrad(false).iterate(iter).workers(8).allowParallelTokenization(true).tokenizerFactory(t).elementsLearningAlgorithm(new CBOW<VocabWord>()).build();
  long time1=System.currentTimeMillis();
  vec.fit();
  long time2=System.currentTimeMillis();
  log.info("Total execution time: {}",(time2 - time1));
}
