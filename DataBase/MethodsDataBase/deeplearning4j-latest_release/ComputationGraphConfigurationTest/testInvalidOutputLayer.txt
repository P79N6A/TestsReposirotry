@Test public void testInvalidOutputLayer(){
  LossFunctions.LossFunction[] lf=new LossFunctions.LossFunction[]{LossFunctions.LossFunction.MCXENT,LossFunctions.LossFunction.MCXENT,LossFunctions.LossFunction.XENT,LossFunctions.LossFunction.XENT,LossFunctions.LossFunction.MCXENT};
  int[] nOut=new int[]{1,3,3,3,3};
  Activation[] activations=new Activation[]{Activation.SOFTMAX,Activation.TANH,Activation.SOFTMAX,Activation.RELU,Activation.SIGMOID};
  for (int i=0; i < lf.length; i++) {
    for (    boolean lossLayer : new boolean[]{false,true}) {
      for (      boolean validate : new boolean[]{true,false}) {
        String s="nOut=" + nOut[i] + ",lossFn="+ lf[i]+ ",lossLayer="+ lossLayer+ ",validate="+ validate;
        if (nOut[i] == 1 && lossLayer)         continue;
        try {
          new NeuralNetConfiguration.Builder().graphBuilder().addInputs("in").layer("0",new DenseLayer.Builder().nIn(10).nOut(10).build(),"in").layer("1",!lossLayer ? new OutputLayer.Builder().nIn(10).nOut(nOut[i]).activation(activations[i]).lossFunction(lf[i]).build() : new LossLayer.Builder().activation(activations[i]).lossFunction(lf[i]).build(),"0").setOutputs("1").validateOutputLayerConfig(validate).build();
          if (validate) {
            fail("Expected exception: " + s);
          }
        }
 catch (        DL4JInvalidConfigException e) {
          if (validate) {
            assertTrue(s,e.getMessage().toLowerCase().contains("invalid output"));
          }
 else {
            fail("Validation should not be enabled");
          }
        }
      }
    }
  }
}
