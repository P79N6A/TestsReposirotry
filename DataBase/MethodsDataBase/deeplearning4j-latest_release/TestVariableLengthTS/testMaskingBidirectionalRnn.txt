@Test public void testMaskingBidirectionalRnn(){
  Nd4j.getRandom().setSeed(12345);
  int nIn=4;
  int layerSize=3;
  int nOut=3;
  MultiLayerConfiguration conf=new NeuralNetConfiguration.Builder().weightInit(WeightInit.XAVIER).activation(Activation.TANH).list().layer(0,new GravesBidirectionalLSTM.Builder().nIn(nIn).nOut(layerSize).build()).layer(1,new GravesBidirectionalLSTM.Builder().nIn(layerSize).nOut(layerSize).build()).layer(2,new RnnOutputLayer.Builder().lossFunction(LossFunctions.LossFunction.MSE).nIn(layerSize).nOut(nOut).build()).build();
  MultiLayerNetwork net=new MultiLayerNetwork(conf);
  net.init();
  int tsLength=5;
  int minibatch=3;
  INDArray input=Nd4j.rand(new int[]{minibatch,nIn,tsLength});
  INDArray labels=Nd4j.rand(new int[]{minibatch,nOut,tsLength});
  INDArray featuresMask=Nd4j.create(new double[][]{{1,1,1,1,1},{1,1,1,1,0},{1,1,1,0,0}});
  INDArray labelsMask=featuresMask.dup();
  net.setLayerMaskArrays(featuresMask,labelsMask);
  INDArray outMasked=net.output(input);
  net.clearLayerMaskArrays();
  for (int i=0; i < minibatch; i++) {
    INDArrayIndex[] idx=new INDArrayIndex[]{NDArrayIndex.interval(i,i,true),NDArrayIndex.all(),NDArrayIndex.interval(0,tsLength - i)};
    INDArray expExampleOut=net.output(input.get(idx));
    INDArray actualExampleOut=outMasked.get(idx);
    assertEquals(expExampleOut,actualExampleOut);
  }
  DataSet ds=new DataSet(input,labels,featuresMask,labelsMask);
  INDArray exampleScores=net.scoreExamples(ds,false);
  assertArrayEquals(new long[]{minibatch,1},exampleScores.shape());
  for (int i=0; i < minibatch; i++) {
    INDArrayIndex[] idx=new INDArrayIndex[]{NDArrayIndex.interval(i,i,true),NDArrayIndex.all(),NDArrayIndex.interval(0,tsLength - i)};
    DataSet dsSingle=new DataSet(input.get(idx),labels.get(idx));
    INDArray exampleSingleScore=net.scoreExamples(dsSingle,false);
    double exp=exampleSingleScore.getDouble(0);
    double act=exampleScores.getDouble(i);
    assertEquals(exp,act,1e-6);
  }
}
