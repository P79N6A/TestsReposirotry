@Test public void testPerOutputMaskingMLP(){
  int nIn=6;
  int layerSize=4;
  INDArray mask1=Nd4j.create(new double[]{1,0,0,1,0});
  INDArray mask3=Nd4j.create(new double[][]{{1,1,1,1,1},{0,1,0,1,0},{1,0,0,1,1}});
  INDArray[] labelMasks=new INDArray[]{mask1,mask3};
  ILossFunction[] lossFunctions=new ILossFunction[]{new LossBinaryXENT(),new LossHinge(),new LossKLD(),new LossKLD(),new LossL1(),new LossL2(),new LossMAE(),new LossMAE(),new LossMAPE(),new LossMAPE(),new LossMCXENT(),new LossMSE(),new LossMSE(),new LossMSLE(),new LossMSLE(),new LossNegativeLogLikelihood(),new LossPoisson(),new LossSquaredHinge()};
  Activation[] act=new Activation[]{Activation.SIGMOID,Activation.TANH,Activation.SIGMOID,Activation.SOFTMAX,Activation.TANH,Activation.TANH,Activation.TANH,Activation.SOFTMAX,Activation.TANH,Activation.SOFTMAX,Activation.SIGMOID,Activation.TANH,Activation.SOFTMAX,Activation.SIGMOID,Activation.SOFTMAX,Activation.SIGMOID,Activation.SIGMOID,Activation.TANH};
  for (  INDArray labelMask : labelMasks) {
    val minibatch=labelMask.size(0);
    val nOut=labelMask.size(1);
    for (int i=0; i < lossFunctions.length; i++) {
      ILossFunction lf=lossFunctions[i];
      Activation a=act[i];
      MultiLayerConfiguration conf=new NeuralNetConfiguration.Builder().updater(new NoOp()).weightInit(WeightInit.DISTRIBUTION).dist(new NormalDistribution(0,1)).seed(12345).list().layer(0,new DenseLayer.Builder().nIn(nIn).nOut(layerSize).activation(Activation.TANH).build()).layer(1,new OutputLayer.Builder().nIn(layerSize).nOut(nOut).lossFunction(lf).activation(a).build()).validateOutputLayerConfig(false).build();
      MultiLayerNetwork net=new MultiLayerNetwork(conf);
      net.init();
      INDArray[] fl=LossFunctionGradientCheck.getFeaturesAndLabels(lf,minibatch,nIn,nOut,12345);
      INDArray features=fl[0];
      INDArray labels=fl[1];
      String msg="testPerOutputMaskingMLP(): maskShape = " + Arrays.toString(labelMask.shape()) + ", loss function = "+ lf+ ", activation = "+ a;
      System.out.println(msg);
      boolean gradOK=GradientCheckUtil.checkGradients(net,DEFAULT_EPS,DEFAULT_MAX_REL_ERROR,DEFAULT_MIN_ABS_ERROR,PRINT_RESULTS,RETURN_ON_FIRST_FAILURE,features,labels,null,labelMask);
      assertTrue(msg,gradOK);
      TestUtils.testModelSerialization(net);
    }
  }
}
