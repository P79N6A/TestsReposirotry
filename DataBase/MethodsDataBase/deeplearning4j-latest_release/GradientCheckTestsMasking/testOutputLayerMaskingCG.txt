@Test public void testOutputLayerMaskingCG(){
  Nd4j.getRandom().setSeed(12345);
  int mb=10;
  int tsLength=5;
  ComputationGraphConfiguration conf=new NeuralNetConfiguration.Builder().weightInit(new NormalDistribution(0,2)).updater(new NoOp()).graphBuilder().addInputs("in").layer("0",new LSTM.Builder().nIn(10).nOut(10).build(),"in").layer("1",new GlobalPoolingLayer.Builder().poolingType(PoolingType.AVG).build(),"0").layer("out",new OutputLayer.Builder().nIn(10).nOut(10).activation(Activation.SOFTMAX).build(),"1").setOutputs("out").setInputTypes(InputType.recurrent(10)).build();
  ComputationGraph net=new ComputationGraph(conf);
  net.init();
  INDArray f=Nd4j.rand(new int[]{mb,10,tsLength});
  INDArray l=TestUtils.randomOneHot(mb,10);
  INDArray lm=TestUtils.randomBernoulli(mb,1);
  assertTrue(lm.sumNumber().intValue() > 0);
  boolean gradOK=GradientCheckUtil.checkGradients(net,DEFAULT_EPS,DEFAULT_MAX_REL_ERROR,DEFAULT_MIN_ABS_ERROR,PRINT_RESULTS,RETURN_ON_FIRST_FAILURE,new INDArray[]{f},new INDArray[]{l},null,new INDArray[]{lm});
  assertTrue(gradOK);
  double score=net.score(new DataSet(f,l,null,lm));
  for (int i=0; i < mb; i++) {
    if (lm.getDouble(i) != 0.0) {
      continue;
    }
    INDArray fView=f.get(point(i),all(),all());
    fView.assign(Nd4j.rand(fView.shape()));
    INDArray lView=l.get(point(i),all());
    lView.assign(TestUtils.randomOneHot(1,lView.size(1)));
    double score2=net.score(new DataSet(f,l,null,lm));
    assertEquals(String.valueOf(i),score,score2,1e-8);
  }
}
