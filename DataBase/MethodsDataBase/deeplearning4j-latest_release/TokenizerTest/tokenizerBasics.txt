@Test public void tokenizerBasics(){
  int numDocs=5;
  int numWords=12;
  KerasTokenizer tokenizer=new KerasTokenizer(numWords);
  String[] texts=new String[]{"Black then white are all I see","In my infancy","Red and yellow then came to be","Reaching out to me","Lets me see."};
  tokenizer.fitOnTexts(texts);
  assertEquals(numDocs,tokenizer.getDocumentCount().intValue());
  INDArray matrix=tokenizer.textsToMatrix(texts,TokenizerMode.BINARY);
  assertArrayEquals(new long[]{numDocs,numWords},matrix.shape());
  Integer[][] sequences=tokenizer.textsToSequences(texts);
  tokenizer.sequencesToTexts(sequences);
  tokenizer.sequencesToMatrix(sequences,TokenizerMode.TFIDF);
  tokenizer.fitOnSequences(sequences);
}
