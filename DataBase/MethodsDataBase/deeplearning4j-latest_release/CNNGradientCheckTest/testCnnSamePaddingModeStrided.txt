@Test public void testCnnSamePaddingModeStrided(){
  int nOut=2;
  int[] minibatchSizes={1,3};
  int width=16;
  int height=16;
  int[] kernelSizes=new int[]{2,3};
  int[] strides={1,2,3};
  int[] inputDepths={1,3};
  Nd4j.getRandom().setSeed(12345);
  for (  int inputDepth : inputDepths) {
    for (    int minibatchSize : minibatchSizes) {
      for (      int stride : strides) {
        for (        int k : kernelSizes) {
          for (          boolean convFirst : new boolean[]{true,false}) {
            INDArray input=Nd4j.rand(minibatchSize,width * height * inputDepth);
            INDArray labels=Nd4j.zeros(minibatchSize,nOut);
            for (int i=0; i < minibatchSize; i++) {
              labels.putScalar(new int[]{i,i % nOut},1.0);
            }
            Layer convLayer=new ConvolutionLayer.Builder().name("layer 0").kernelSize(k,k).cudnnAllowFallback(false).stride(stride,stride).padding(0,0).nIn(inputDepth).nOut(2).build();
            Layer poolLayer=new SubsamplingLayer.Builder().poolingType(SubsamplingLayer.PoolingType.MAX).kernelSize(k,k).cudnnAllowFallback(false).stride(stride,stride).padding(0,0).build();
            MultiLayerConfiguration conf=new NeuralNetConfiguration.Builder().seed(12345).updater(new NoOp()).activation(Activation.TANH).convolutionMode(Same).list().layer(0,convFirst ? convLayer : poolLayer).layer(1,convFirst ? poolLayer : convLayer).layer(2,new OutputLayer.Builder(LossFunctions.LossFunction.MCXENT).activation(Activation.SOFTMAX).nOut(nOut).build()).setInputType(InputType.convolutionalFlat(height,width,inputDepth)).build();
            MultiLayerNetwork net=new MultiLayerNetwork(conf);
            net.init();
            for (int i=0; i < net.getLayers().length; i++) {
              System.out.println("nParams, layer " + i + ": "+ net.getLayer(i).numParams());
            }
            String msg="Minibatch=" + minibatchSize + ", inDepth="+ inputDepth+ ", height="+ height+ ", kernelSize="+ k+ ", stride = "+ stride+ ", convLayer first = "+ convFirst;
            System.out.println(msg);
            boolean gradOK=GradientCheckUtil.checkGradients(net,DEFAULT_EPS,DEFAULT_MAX_REL_ERROR,DEFAULT_MIN_ABS_ERROR,PRINT_RESULTS,RETURN_ON_FIRST_FAILURE,input,labels);
            assertTrue(msg,gradOK);
            TestUtils.testModelSerialization(net);
          }
        }
      }
    }
  }
}
