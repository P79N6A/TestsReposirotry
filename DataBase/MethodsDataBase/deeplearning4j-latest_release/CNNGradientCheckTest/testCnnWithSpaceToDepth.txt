@Ignore @Test public void testCnnWithSpaceToDepth(){
  Nd4j.getRandom().setSeed(12345);
  int nOut=4;
  int minibatchSize=2;
  int width=5;
  int height=5;
  int inputDepth=1;
  int[] kernel={2,2};
  int blocks=2;
  String[] activations={"sigmoid"};
  SubsamplingLayer.PoolingType[] poolingTypes=new SubsamplingLayer.PoolingType[]{SubsamplingLayer.PoolingType.MAX,SubsamplingLayer.PoolingType.AVG,SubsamplingLayer.PoolingType.PNORM};
  for (  String afn : activations) {
    for (    SubsamplingLayer.PoolingType poolingType : poolingTypes) {
      INDArray input=Nd4j.rand(minibatchSize,width * height * inputDepth);
      INDArray labels=Nd4j.zeros(minibatchSize,nOut);
      for (int i=0; i < minibatchSize; i++) {
        labels.putScalar(new int[]{i,i % nOut},1.0);
      }
      MultiLayerConfiguration conf=new NeuralNetConfiguration.Builder().updater(new NoOp()).weightInit(WeightInit.DISTRIBUTION).dist(new NormalDistribution(0,1)).list().layer(new ConvolutionLayer.Builder(kernel).nIn(inputDepth).hasBias(false).cudnnAllowFallback(false).nOut(1).build()).layer(new SpaceToDepthLayer.Builder(blocks,SpaceToDepthLayer.DataFormat.NCHW).build()).layer(new OutputLayer.Builder(LossFunctions.LossFunction.MCXENT).activation(Activation.SOFTMAX).nIn(2 * 2 * 4).nOut(nOut).build()).setInputType(InputType.convolutionalFlat(height,width,inputDepth)).build();
      MultiLayerNetwork net=new MultiLayerNetwork(conf);
      net.init();
      String msg="PoolingType=" + poolingType + ", minibatch="+ minibatchSize+ ", activationFn="+ afn;
      if (PRINT_RESULTS) {
        System.out.println(msg);
        for (int j=0; j < net.getnLayers(); j++)         System.out.println("Layer " + j + " # params: "+ net.getLayer(j).numParams());
      }
      boolean gradOK=GradientCheckUtil.checkGradients(net,DEFAULT_EPS,DEFAULT_MAX_REL_ERROR,DEFAULT_MIN_ABS_ERROR,PRINT_RESULTS,RETURN_ON_FIRST_FAILURE,input,labels);
      assertTrue(msg,gradOK);
      TestUtils.testModelSerialization(net);
    }
  }
}
