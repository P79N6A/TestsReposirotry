@Test public void testBasicIrisWithMerging(){
  Nd4j.getRandom().setSeed(12345);
  ComputationGraphConfiguration conf=new NeuralNetConfiguration.Builder().seed(12345).optimizationAlgo(OptimizationAlgorithm.STOCHASTIC_GRADIENT_DESCENT).weightInit(WeightInit.DISTRIBUTION).dist(new NormalDistribution(0,1)).updater(new NoOp()).graphBuilder().addInputs("input").addLayer("l1",new DenseLayer.Builder().nIn(4).nOut(5).activation(Activation.TANH).build(),"input").addLayer("l2",new DenseLayer.Builder().nIn(4).nOut(5).activation(Activation.TANH).build(),"input").addVertex("merge",new MergeVertex(),"l1","l2").addLayer("outputLayer",new OutputLayer.Builder().lossFunction(LossFunctions.LossFunction.MCXENT).activation(Activation.SOFTMAX).nIn(5 + 5).nOut(3).build(),"merge").setOutputs("outputLayer").build();
  ComputationGraph graph=new ComputationGraph(conf);
  graph.init();
  int numParams=(4 * 5 + 5) + (4 * 5 + 5) + (10 * 3 + 3);
  assertEquals(numParams,graph.numParams());
  Nd4j.getRandom().setSeed(12345);
  long nParams=graph.numParams();
  INDArray newParams=Nd4j.rand(new long[]{1,nParams});
  graph.setParams(newParams);
  DataSet ds=new IrisDataSetIterator(150,150).next();
  INDArray min=ds.getFeatures().min(0);
  INDArray max=ds.getFeatures().max(0);
  ds.getFeatures().subiRowVector(min).diviRowVector(max.sub(min));
  INDArray input=ds.getFeatures();
  INDArray labels=ds.getLabels();
  if (PRINT_RESULTS) {
    System.out.println("testBasicIrisWithMerging()");
    for (int j=0; j < graph.getNumLayers(); j++)     System.out.println("Layer " + j + " # params: "+ graph.getLayer(j).numParams());
  }
  boolean gradOK=GradientCheckUtil.checkGradients(graph,DEFAULT_EPS,DEFAULT_MAX_REL_ERROR,DEFAULT_MIN_ABS_ERROR,PRINT_RESULTS,RETURN_ON_FIRST_FAILURE,new INDArray[]{input},new INDArray[]{labels});
  String msg="testBasicIrisWithMerging()";
  assertTrue(msg,gradOK);
  TestUtils.testModelSerialization(graph);
}
