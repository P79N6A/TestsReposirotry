@Test public void testUnkSerialization_1() throws Exception {
  val inputFile=new ClassPathResource("/big/raw_sentences.txt").getFile();
  val iter=new BasicLineIterator(inputFile);
  val t=new DefaultTokenizerFactory();
  t.setTokenPreProcessor(new CommonPreprocessor());
  val vec=new Word2Vec.Builder().minWordFrequency(1).epochs(1).layerSize(300).limitVocabularySize(1).windowSize(5).allowParallelTokenization(true).batchSize(512).learningRate(0.025).minLearningRate(0.0001).negativeSample(0.0).sampling(0.0).useAdaGrad(false).useHierarchicSoftmax(true).iterations(1).useUnknown(true).seed(42).iterate(iter).workers(4).tokenizerFactory(t).build();
  vec.fit();
  val tmpFile=File.createTempFile("temp","temp");
  tmpFile.deleteOnExit();
  WordVectorSerializer.writeWord2VecModel(vec,tmpFile);
}
