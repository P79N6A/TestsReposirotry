/** 
 * This test intended only to test activateSelectedLayers method, it does not involves fully-working AutoEncoder.
 */
@Test public void testSelectedActivations(){
  final int numRows=28;
  final int numColumns=28;
  int seed=123;
  int numSamples=3;
  int iterations=1;
  int listenerFreq=iterations / 5;
  log.info("Load data....");
  float[][] trainingData=new float[numSamples][numColumns * numRows];
  Arrays.fill(trainingData[0],0.95f);
  Arrays.fill(trainingData[1],0.5f);
  Arrays.fill(trainingData[2],0.05f);
  log.info("Build model....");
  MultiLayerConfiguration conf=new NeuralNetConfiguration.Builder().seed(seed).optimizationAlgo(OptimizationAlgorithm.LINE_GRADIENT_DESCENT).list().layer(0,new DenseLayer.Builder().nIn(numRows * numColumns).nOut(1000).build()).layer(1,new DenseLayer.Builder().nIn(1000).nOut(500).build()).layer(2,new DenseLayer.Builder().nIn(500).nOut(250).build()).layer(3,new DenseLayer.Builder().nIn(250).nOut(100).build()).layer(4,new DenseLayer.Builder().nIn(100).nOut(30).build()).layer(5,new DenseLayer.Builder().nIn(30).nOut(100).build()).layer(6,new DenseLayer.Builder().nIn(100).nOut(250).build()).layer(7,new DenseLayer.Builder().nIn(250).nOut(500).build()).layer(8,new DenseLayer.Builder().nIn(500).nOut(1000).build()).layer(9,new OutputLayer.Builder(LossFunctions.LossFunction.NEGATIVELOGLIKELIHOOD).nIn(1000).nOut(numRows * numColumns).activation(Activation.SOFTMAX).build()).pretrain(true).build();
  MultiLayerNetwork model=new MultiLayerNetwork(conf);
  model.init();
  model.addListeners(new ScoreIterationListener(listenerFreq));
  log.info("Train model....");
  int cnt=0;
  while (cnt < numSamples) {
    INDArray input=Nd4j.create(trainingData[cnt]);
    model.fit(new DataSet(input,input));
    cnt++;
  }
  log.info("Testing full cycle...");
  List<INDArray> comparableResult=model.feedForward(Nd4j.create(trainingData[0]));
  INDArray encodeResult=model.activateSelectedLayers(0,4,Nd4j.create(trainingData[0]));
  log.info("Compare feedForward results with selectedActivation");
  assertEquals(comparableResult.get(5),encodeResult);
  INDArray decodeResults=model.activateSelectedLayers(5,9,encodeResult);
  log.info("Decode results: " + decodeResults.columns() + " "+ decodeResults);
  log.info("Comparable  results: " + comparableResult.get(10).columns() + " "+ comparableResult.get(10));
  assertEquals(comparableResult.get(10),decodeResults);
}
