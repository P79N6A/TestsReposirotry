@Test public void testVaePretrainSimpleCG(){
  int nIn=8;
  Nd4j.getRandom().setSeed(12345);
  ComputationGraphConfiguration conf=new NeuralNetConfiguration.Builder().seed(12345).updater(new RmsProp()).weightInit(WeightInit.XAVIER).graphBuilder().addInputs("in").addLayer("0",new VariationalAutoencoder.Builder().nIn(8).nOut(10).encoderLayerSizes(12).decoderLayerSizes(13).reconstructionDistribution(new GaussianReconstructionDistribution(Activation.IDENTITY)).build(),"in").setOutputs("0").pretrain(true).backprop(false).build();
  int rddDataSetNumExamples=10;
  int totalAveragings=5;
  int averagingFrequency=3;
  ParameterAveragingTrainingMaster tm=new ParameterAveragingTrainingMaster.Builder(rddDataSetNumExamples).averagingFrequency(averagingFrequency).batchSizePerWorker(rddDataSetNumExamples).saveUpdater(true).workerPrefetchNumBatches(0).build();
  Nd4j.getRandom().setSeed(12345);
  SparkComputationGraph sparkNet=new SparkComputationGraph(sc,conf.clone(),tm);
  List<DataSet> trainData=new ArrayList<>();
  int nDataSets=numExecutors() * totalAveragings * averagingFrequency;
  for (int i=0; i < nDataSets; i++) {
    trainData.add(new DataSet(Nd4j.rand(rddDataSetNumExamples,nIn),null));
  }
  JavaRDD<DataSet> data=sc.parallelize(trainData);
  sparkNet.fit(data);
}
