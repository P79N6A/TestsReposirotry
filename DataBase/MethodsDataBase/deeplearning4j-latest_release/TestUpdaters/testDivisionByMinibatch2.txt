@Test public void testDivisionByMinibatch2(){
  MultiLayerConfiguration conf=new NeuralNetConfiguration.Builder().list().layer(new DenseLayer.Builder().nIn(10).nOut(9).build()).layer(new BatchNormalization.Builder().nOut(9).build()).layer(new DenseLayer.Builder().nIn(9).nOut(8).build()).layer(new BatchNormalization.Builder().nOut(8).build()).layer(new OutputLayer.Builder().nIn(8).nOut(7).activation(Activation.SOFTMAX).build()).build();
  MultiLayerNetwork net=new MultiLayerNetwork(conf);
  net.init();
  net.fit(Nd4j.create(1,10),Nd4j.create(1,7));
  BaseMultiLayerUpdater u=(BaseMultiLayerUpdater)net.getUpdater();
  List<INDArray> l=u.getGradientsForMinibatchDivision();
  assertNotNull(l);
  assertEquals(3,l.size());
  assertEquals(10 * 9 + 9 + 2 * 9,l.get(0).length());
  assertEquals(9 * 8 + 8 + 2 * 8,l.get(1).length());
  assertEquals(8 * 7 + 7,l.get(2).length());
  INDArray view=((BaseMultiLayerUpdater)net.getUpdater()).getFlattenedGradientsView();
  view.assign(Nd4j.linspace(1,view.length(),view.length()));
  INDArray expView1=view.get(point(0),interval(0,10 * 9 + 9 + 2 * 9));
  assertEquals(expView1,l.get(0));
  long start2=(10 * 9 + 9 + 2 * 9) + 2 * 9;
  long length2=9 * 8 + 8 + 2 * 8;
  INDArray expView2=view.get(point(0),interval(start2,start2 + length2));
  assertEquals(expView2,l.get(1));
  long start3=start2 + length2 + 2 * 8;
  long length3=8 * 7 + 7;
  INDArray expView3=view.get(point(0),interval(start3,start3 + length3));
  assertEquals(expView3,l.get(2));
}
