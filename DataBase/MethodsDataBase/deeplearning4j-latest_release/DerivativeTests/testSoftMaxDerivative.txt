@Test public void testSoftMaxDerivative(){
  Random r=new Random(12345L);
  int[] mb=new int[]{10,2,1};
  for (  int minibatch : mb) {
    System.out.println("Minibatch size: " + minibatch);
    INDArray z=Nd4j.zeros(minibatch,5);
    double[][] in=new double[minibatch][5];
    double[][] softmax=new double[minibatch][5];
    double[][] expOut=new double[minibatch][5];
    for (int i=0; i < minibatch; i++) {
      double rowSumExp=0.0;
      for (int j=0; j < 5; j++) {
        in[i][j]=10 * r.nextDouble();
        z.putScalar(new int[]{i,j},in[i][j]);
        rowSumExp+=FastMath.exp(in[i][j]);
      }
      for (int j=0; j < 5; j++) {
        softmax[i][j]=FastMath.exp(in[i][j]) / rowSumExp;
        expOut[i][j]=softmax[i][j] * (1.0 - softmax[i][j]);
      }
    }
    INDArray sm=Nd4j.getExecutioner().execAndReturn(new OldSoftMax(z.dup()));
    INDArray zPrime=Nd4j.getExecutioner().execAndReturn(new SoftMaxDerivative(z));
    System.out.println(Arrays.toString(sm.data().asDouble()));
    System.out.println(Arrays.toString(zPrime.data().asDouble()));
    assertNotEquals(sm,zPrime);
    for (int i=0; i < minibatch; i++) {
      for (int j=0; j < 5; j++) {
        double relError=Math.abs(expOut[i][j] - zPrime.getDouble(i,j)) / (Math.abs(expOut[i][j]) + Math.abs(zPrime.getDouble(i,j)));
        assertTrue(relError < REL_ERROR_TOLERANCE);
      }
    }
  }
}
