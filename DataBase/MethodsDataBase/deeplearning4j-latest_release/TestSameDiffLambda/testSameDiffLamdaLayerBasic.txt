@Test public void testSameDiffLamdaLayerBasic(){
  Nd4j.getRandom().setSeed(12345);
  ComputationGraphConfiguration conf=new NeuralNetConfiguration.Builder().seed(12345).updater(new Adam(0.01)).graphBuilder().addInputs("in").addLayer("0",new DenseLayer.Builder().nIn(5).nOut(5).activation(Activation.TANH).build(),"in").addLayer("1",new SameDiffSimpleLambdaLayer(),"0").addLayer("2",new OutputLayer.Builder().nIn(5).nOut(5).activation(Activation.SOFTMAX).lossFunction(LossFunctions.LossFunction.MCXENT).build(),"1").setOutputs("2").build();
  ComputationGraphConfiguration confStd=new NeuralNetConfiguration.Builder().seed(12345).updater(new Adam(0.01)).graphBuilder().addInputs("in").addLayer("0",new DenseLayer.Builder().nIn(5).nOut(5).activation(Activation.TANH).build(),"in").addVertex("1",new ShiftVertex(1.0),"0").addVertex("2",new ScaleVertex(2.0),"1").addLayer("3",new OutputLayer.Builder().nIn(5).nOut(5).activation(Activation.SOFTMAX).lossFunction(LossFunctions.LossFunction.MCXENT).build(),"2").setOutputs("3").build();
  ComputationGraph lambda=new ComputationGraph(conf);
  lambda.init();
  ComputationGraph std=new ComputationGraph(confStd);
  std.init();
  lambda.setParams(std.params());
  INDArray in=Nd4j.rand(3,5);
  INDArray labels=TestUtils.randomOneHot(3,5);
  DataSet ds=new DataSet(in,labels);
  INDArray outLambda=lambda.outputSingle(in);
  INDArray outStd=std.outputSingle(in);
  assertEquals(outLambda,outStd);
  double scoreLambda=lambda.score(ds);
  double scoreStd=std.score(ds);
  assertEquals(scoreStd,scoreLambda,1e-6);
  for (int i=0; i < 3; i++) {
    lambda.fit(ds);
    std.fit(ds);
    String s=String.valueOf(i);
    assertEquals(s,std.params(),lambda.params());
    assertEquals(s,std.getFlattenedGradients(),lambda.getFlattenedGradients());
  }
  ComputationGraph loaded=TestUtils.testModelSerialization(lambda);
  outLambda=loaded.outputSingle(in);
  outStd=std.outputSingle(in);
  assertEquals(outStd,outLambda);
}
