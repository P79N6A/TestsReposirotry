@Test public void testBadTuning(){
  Nd4j.getRandom().setSeed(12345);
  MultiLayerConfiguration conf=new NeuralNetConfiguration.Builder().seed(12345).optimizationAlgo(OptimizationAlgorithm.STOCHASTIC_GRADIENT_DESCENT).updater(new Sgd(1.0)).weightInit(WeightInit.XAVIER).list().layer(0,new OutputLayer.Builder().nIn(4).nOut(3).activation(Activation.SOFTMAX).lossFunction(LossFunctions.LossFunction.MCXENT).build()).build();
  MultiLayerNetwork net=new MultiLayerNetwork(conf);
  net.setListeners(new ScoreIterationListener(1));
  DataSetIterator irisIter=new IrisDataSetIterator(10,150);
  EarlyStoppingModelSaver<MultiLayerNetwork> saver=new InMemoryModelSaver<>();
  EarlyStoppingConfiguration<MultiLayerNetwork> esConf=new EarlyStoppingConfiguration.Builder<MultiLayerNetwork>().epochTerminationConditions(new MaxEpochsTerminationCondition(5000)).iterationTerminationConditions(new MaxTimeIterationTerminationCondition(1,TimeUnit.MINUTES),new MaxScoreIterationTerminationCondition(10)).scoreCalculator(new DataSetLossCalculator(irisIter,true)).modelSaver(saver).build();
  IEarlyStoppingTrainer<MultiLayerNetwork> trainer=new EarlyStoppingParallelTrainer<>(esConf,net,irisIter,null,2,2,1);
  EarlyStoppingResult result=trainer.fit();
  assertTrue(result.getTotalEpochs() < 5);
  assertEquals(EarlyStoppingResult.TerminationReason.IterationTerminationCondition,result.getTerminationReason());
  String expDetails=new MaxScoreIterationTerminationCondition(10).toString();
  assertEquals(expDetails,result.getTerminationDetails());
  assertTrue(result.getBestModelEpoch() <= 0);
  assertNotNull(result.getBestModel());
}
