@Test public void testDBNBNMultiLayer() throws Exception {
  DataSetIterator iter=new MnistDataSetIterator(2,2);
  DataSet next=iter.next();
  MultiLayerConfiguration conf=new NeuralNetConfiguration.Builder().optimizationAlgo(OptimizationAlgorithm.STOCHASTIC_GRADIENT_DESCENT).seed(123).list().layer(0,new DenseLayer.Builder().nIn(28 * 28).nOut(10).weightInit(WeightInit.XAVIER).activation(Activation.RELU).build()).layer(1,new BatchNormalization.Builder().nOut(10).build()).layer(2,new ActivationLayer.Builder().activation(Activation.RELU).build()).layer(3,new OutputLayer.Builder(LossFunctions.LossFunction.MCXENT).weightInit(WeightInit.XAVIER).activation(Activation.SOFTMAX).nIn(10).nOut(10).build()).build();
  MultiLayerNetwork network=new MultiLayerNetwork(conf);
  network.init();
  network.setInput(next.getFeatures());
  INDArray activationsActual=network.activate(next.getFeatures());
  assertEquals(10,activationsActual.shape()[1],1e-2);
  network.fit(next);
  INDArray actualGammaParam=network.getLayer(1).getParam(BatchNormalizationParamInitializer.GAMMA);
  INDArray actualBetaParam=network.getLayer(1).getParam(BatchNormalizationParamInitializer.BETA);
  assertTrue(actualGammaParam != null);
  assertTrue(actualBetaParam != null);
}
