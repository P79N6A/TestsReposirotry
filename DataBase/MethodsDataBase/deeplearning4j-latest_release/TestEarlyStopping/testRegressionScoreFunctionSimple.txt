@Test public void testRegressionScoreFunctionSimple() throws Exception {
  for (  RegressionEvaluation.Metric metric : new RegressionEvaluation.Metric[]{RegressionEvaluation.Metric.MSE,RegressionEvaluation.Metric.MAE}) {
    log.info("Metric: " + metric);
    MultiLayerConfiguration conf=new NeuralNetConfiguration.Builder().list().layer(new DenseLayer.Builder().nIn(784).nOut(32).build()).layer(new OutputLayer.Builder().nIn(32).nOut(784).activation(Activation.SIGMOID).lossFunction(LossFunctions.LossFunction.MSE).build()).build();
    MultiLayerNetwork net=new MultiLayerNetwork(conf);
    net.init();
    DataSetIterator iter=new MnistDataSetIterator(32,false,12345);
    List<DataSet> l=new ArrayList<>();
    for (int i=0; i < 10; i++) {
      DataSet ds=iter.next();
      l.add(new DataSet(ds.getFeatures(),ds.getFeatures()));
    }
    iter=new ExistingDataSetIterator(l);
    EarlyStoppingModelSaver<MultiLayerNetwork> saver=new InMemoryModelSaver<>();
    EarlyStoppingConfiguration<MultiLayerNetwork> esConf=new EarlyStoppingConfiguration.Builder<MultiLayerNetwork>().epochTerminationConditions(new MaxEpochsTerminationCondition(5)).iterationTerminationConditions(new MaxTimeIterationTerminationCondition(1,TimeUnit.MINUTES)).scoreCalculator(new RegressionScoreCalculator(metric,iter)).modelSaver(saver).build();
    EarlyStoppingTrainer trainer=new EarlyStoppingTrainer(esConf,net,iter);
    EarlyStoppingResult<MultiLayerNetwork> result=trainer.fit();
    assertNotNull(result.getBestModel());
    assertTrue(result.getBestModelScore() > 0.0);
  }
}
