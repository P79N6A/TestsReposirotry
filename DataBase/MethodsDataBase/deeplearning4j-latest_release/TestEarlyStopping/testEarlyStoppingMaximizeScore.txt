@Test public void testEarlyStoppingMaximizeScore() throws Exception {
  Nd4j.getRandom().setSeed(12345);
  int outputs=2;
  DataSet ds=new DataSet(Nd4j.rand(new int[]{3,10,50}),TestUtils.randomOneHotTimeSeries(3,outputs,50,12345));
  DataSetIterator train=new ExistingDataSetIterator(Arrays.asList(ds,ds,ds,ds,ds,ds,ds,ds,ds,ds));
  DataSetIterator test=new SingletonDataSetIterator(ds);
  MultiLayerConfiguration conf=new NeuralNetConfiguration.Builder().seed(123).weightInit(WeightInit.XAVIER).updater(new Adam(0.1)).activation(Activation.ELU).l2(1e-5).gradientNormalization(GradientNormalization.ClipElementWiseAbsoluteValue).gradientNormalizationThreshold(1.0).list().layer(0,new LSTM.Builder().nIn(10).nOut(10).activation(Activation.TANH).gateActivationFunction(Activation.SIGMOID).dropOut(0.5).build()).layer(1,new RnnOutputLayer.Builder().nIn(10).nOut(outputs).activation(Activation.SOFTMAX).lossFunction(LossFunctions.LossFunction.MCXENT).build()).build();
  File f=testDir.newFolder();
  EarlyStoppingModelSaver<MultiLayerNetwork> saver=new LocalFileModelSaver(f.getAbsolutePath());
  EarlyStoppingConfiguration<MultiLayerNetwork> esConf=new EarlyStoppingConfiguration.Builder<MultiLayerNetwork>().epochTerminationConditions(new MaxEpochsTerminationCondition(10),new ScoreImprovementEpochTerminationCondition(1)).iterationTerminationConditions(new MaxTimeIterationTerminationCondition(10,TimeUnit.MINUTES)).scoreCalculator(new ClassificationScoreCalculator(Evaluation.Metric.F1,test)).modelSaver(saver).saveLastModel(true).build();
  MultiLayerNetwork net=new MultiLayerNetwork(conf);
  net.init();
  EarlyStoppingTrainer t=new EarlyStoppingTrainer(esConf,net,train);
  EarlyStoppingResult<MultiLayerNetwork> result=t.fit();
  Map<Integer,Double> map=result.getScoreVsEpoch();
  for (int i=1; i < map.size(); i++) {
    if (i == map.size() - 1) {
      assertTrue(map.get(i) < +map.get(i - 1));
    }
 else {
      assertTrue(map.get(i) > map.get(i - 1));
    }
  }
}
