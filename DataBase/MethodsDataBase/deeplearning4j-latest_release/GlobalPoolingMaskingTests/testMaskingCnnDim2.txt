@Test public void testMaskingCnnDim2(){
  int minibatch=3;
  int depthIn=3;
  int depthOut=4;
  int nOut=5;
  int height=5;
  int width=4;
  PoolingType[] poolingTypes=new PoolingType[]{PoolingType.SUM,PoolingType.AVG,PoolingType.MAX,PoolingType.PNORM};
  for (  PoolingType pt : poolingTypes) {
    MultiLayerConfiguration conf=new NeuralNetConfiguration.Builder().weightInit(WeightInit.XAVIER).convolutionMode(ConvolutionMode.Same).seed(12345L).list().layer(0,new ConvolutionLayer.Builder().nIn(depthIn).nOut(depthOut).kernelSize(2,width).stride(1,width).activation(Activation.TANH).build()).layer(1,new org.deeplearning4j.nn.conf.layers.GlobalPoolingLayer.Builder().poolingType(pt).build()).layer(2,new OutputLayer.Builder(LossFunctions.LossFunction.MCXENT).activation(Activation.SOFTMAX).nIn(depthOut).nOut(nOut).build()).build();
    MultiLayerNetwork net=new MultiLayerNetwork(conf);
    net.init();
    INDArray inToBeMasked=Nd4j.rand(new int[]{minibatch,depthIn,height,width});
    INDArray maskArray=Nd4j.create(new double[][]{{1,1,1,1,1},{1,1,1,1,0},{1,1,1,0,0}}).reshape('c',minibatch,1,height,1);
    Nd4j.getExecutioner().exec(new BroadcastMulOp(inToBeMasked,maskArray,inToBeMasked,0,2));
    net.setLayerMaskArrays(maskArray,null);
    INDArray outMasked=net.output(inToBeMasked);
    net.clearLayerMaskArrays();
    for (int i=0; i < minibatch; i++) {
      int numSteps=height - i;
      INDArray subset=inToBeMasked.get(NDArrayIndex.interval(i,i,true),NDArrayIndex.all(),NDArrayIndex.interval(0,numSteps),NDArrayIndex.all());
      assertArrayEquals(new long[]{1,depthIn,height - i,width},subset.shape());
      INDArray outSubset=net.output(subset);
      INDArray outMaskedSubset=outMasked.getRow(i);
      assertEquals("minibatch: " + i,outSubset,outMaskedSubset);
    }
  }
}
