@Test public void testMaskingCnnDim2_SingleExample(){
  int minibatch=1;
  int depthIn=2;
  int depthOut=2;
  int nOut=2;
  int height=6;
  int width=3;
  PoolingType[] poolingTypes=new PoolingType[]{PoolingType.SUM,PoolingType.AVG,PoolingType.MAX,PoolingType.PNORM};
  for (  PoolingType pt : poolingTypes) {
    MultiLayerConfiguration conf=new NeuralNetConfiguration.Builder().weightInit(WeightInit.XAVIER).convolutionMode(ConvolutionMode.Same).seed(12345L).list().layer(0,new ConvolutionLayer.Builder().nIn(depthIn).nOut(depthOut).kernelSize(2,width).stride(1,width).activation(Activation.TANH).build()).layer(1,new org.deeplearning4j.nn.conf.layers.GlobalPoolingLayer.Builder().poolingType(pt).build()).layer(2,new OutputLayer.Builder(LossFunctions.LossFunction.MCXENT).activation(Activation.SOFTMAX).nIn(depthOut).nOut(nOut).build()).build();
    MultiLayerNetwork net=new MultiLayerNetwork(conf);
    net.init();
    INDArray inToBeMasked=Nd4j.rand(new int[]{minibatch,depthIn,height,width});
    INDArray maskArray=Nd4j.create(new double[]{1,1,1,1,1,0},new int[]{1,1,height,1});
    Nd4j.getExecutioner().exec(new BroadcastMulOp(inToBeMasked,maskArray,inToBeMasked,0,2));
    net.setLayerMaskArrays(maskArray,null);
    INDArray outMasked=net.output(inToBeMasked);
    net.clearLayerMaskArrays();
    int numSteps=height - 1;
    INDArray subset=inToBeMasked.get(NDArrayIndex.interval(0,0,true),NDArrayIndex.all(),NDArrayIndex.interval(0,numSteps),NDArrayIndex.all());
    assertArrayEquals(new long[]{1,depthIn,5,width},subset.shape());
    INDArray outSubset=net.output(subset);
    INDArray outMaskedSubset=outMasked.getRow(0);
    assertEquals(outSubset,outMaskedSubset);
    net.setLayerMaskArrays(maskArray,null);
    net.setInput(inToBeMasked);
    INDArray labels=Nd4j.create(new double[]{0,1});
    net.setLabels(labels);
    net.computeGradientAndScore();
  }
}
