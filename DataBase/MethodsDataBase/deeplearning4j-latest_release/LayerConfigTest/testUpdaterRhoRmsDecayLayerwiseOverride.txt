@Test public void testUpdaterRhoRmsDecayLayerwiseOverride(){
  MultiLayerConfiguration conf=new NeuralNetConfiguration.Builder().updater(new AdaDelta(0.5,0.9)).list().layer(0,new DenseLayer.Builder().nIn(2).nOut(2).build()).layer(1,new DenseLayer.Builder().nIn(2).nOut(2).updater(new AdaDelta(0.01,0.9)).build()).build();
  MultiLayerNetwork net=new MultiLayerNetwork(conf);
  net.init();
  assertTrue(((BaseLayer)conf.getConf(0).getLayer()).getIUpdater() instanceof AdaDelta);
  assertTrue(((BaseLayer)conf.getConf(1).getLayer()).getIUpdater() instanceof AdaDelta);
  assertEquals(0.5,((AdaDelta)((BaseLayer)conf.getConf(0).getLayer()).getIUpdater()).getRho(),0.0);
  assertEquals(0.01,((AdaDelta)((BaseLayer)conf.getConf(1).getLayer()).getIUpdater()).getRho(),0.0);
  conf=new NeuralNetConfiguration.Builder().updater(new RmsProp(1.0,2.0,RmsProp.DEFAULT_RMSPROP_EPSILON)).list().layer(0,new DenseLayer.Builder().nIn(2).nOut(2).updater(new RmsProp(1.0,1.0,RmsProp.DEFAULT_RMSPROP_EPSILON)).build()).layer(1,new DenseLayer.Builder().nIn(2).nOut(2).updater(new AdaDelta(0.5,AdaDelta.DEFAULT_ADADELTA_EPSILON)).build()).build();
  net=new MultiLayerNetwork(conf);
  net.init();
  assertTrue(((BaseLayer)conf.getConf(0).getLayer()).getIUpdater() instanceof RmsProp);
  assertTrue(((BaseLayer)conf.getConf(1).getLayer()).getIUpdater() instanceof AdaDelta);
  assertEquals(1.0,((RmsProp)((BaseLayer)conf.getConf(0).getLayer()).getIUpdater()).getRmsDecay(),0.0);
  assertEquals(0.5,((AdaDelta)((BaseLayer)conf.getConf(1).getLayer()).getIUpdater()).getRho(),0.0);
}
