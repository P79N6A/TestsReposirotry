@Test public void testNoutChanges(){
  DataSet randomData=new DataSet(Nd4j.rand(10,4),Nd4j.rand(10,2));
  NeuralNetConfiguration.Builder overallConf=new NeuralNetConfiguration.Builder().updater(new Sgd(0.1)).activation(Activation.IDENTITY);
  FineTuneConfiguration fineTuneConfiguration=new FineTuneConfiguration.Builder().updater(new Sgd(0.1)).activation(Activation.IDENTITY).build();
  ComputationGraph modelToFineTune=new ComputationGraph(overallConf.graphBuilder().addInputs("layer0In").addLayer("layer0",new DenseLayer.Builder().nIn(4).nOut(5).build(),"layer0In").addLayer("layer1",new DenseLayer.Builder().nIn(3).nOut(2).build(),"layer0").addLayer("layer2",new DenseLayer.Builder().nIn(2).nOut(3).build(),"layer1").addLayer("layer3",new org.deeplearning4j.nn.conf.layers.OutputLayer.Builder(LossFunctions.LossFunction.MCXENT).activation(Activation.SOFTMAX).nIn(3).nOut(3).build(),"layer2").setOutputs("layer3").build());
  modelToFineTune.init();
  ComputationGraph modelNow=new TransferLearning.GraphBuilder(modelToFineTune).fineTuneConfiguration(fineTuneConfiguration).nOutReplace("layer3",2,WeightInit.XAVIER).nOutReplace("layer0",3,new NormalDistribution(1,1e-1),WeightInit.XAVIER).build();
  BaseLayer bl0=((BaseLayer)modelNow.getLayer("layer0").conf().getLayer());
  BaseLayer bl1=((BaseLayer)modelNow.getLayer("layer1").conf().getLayer());
  BaseLayer bl3=((BaseLayer)modelNow.getLayer("layer3").conf().getLayer());
  assertEquals(bl0.getWeightInit(),WeightInit.DISTRIBUTION);
  assertEquals(bl0.getDist(),new NormalDistribution(1,1e-1));
  assertEquals(bl1.getWeightInit(),WeightInit.XAVIER);
  assertEquals(bl1.getDist(),null);
  assertEquals(bl1.getWeightInit(),WeightInit.XAVIER);
  ComputationGraph modelExpectedArch=new ComputationGraph(overallConf.graphBuilder().addInputs("layer0In").addLayer("layer0",new DenseLayer.Builder().nIn(4).nOut(3).build(),"layer0In").addLayer("layer1",new DenseLayer.Builder().nIn(3).nOut(2).build(),"layer0").addLayer("layer2",new DenseLayer.Builder().nIn(2).nOut(3).build(),"layer1").addLayer("layer3",new org.deeplearning4j.nn.conf.layers.OutputLayer.Builder(LossFunctions.LossFunction.MCXENT).activation(Activation.SOFTMAX).nIn(3).nOut(2).build(),"layer2").setOutputs("layer3").build());
  modelExpectedArch.init();
  assertArrayEquals(modelExpectedArch.params().shape(),modelNow.params().shape());
  assertArrayEquals(modelExpectedArch.getLayer("layer0").params().shape(),modelNow.getLayer("layer0").params().shape());
  assertArrayEquals(modelExpectedArch.getLayer("layer1").params().shape(),modelNow.getLayer("layer1").params().shape());
  assertArrayEquals(modelExpectedArch.getLayer("layer2").params().shape(),modelNow.getLayer("layer2").params().shape());
  assertArrayEquals(modelExpectedArch.getLayer("layer3").params().shape(),modelNow.getLayer("layer3").params().shape());
  modelNow.setParams(modelExpectedArch.params());
  modelExpectedArch.fit(randomData);
  modelNow.fit(randomData);
  assertEquals(modelExpectedArch.score(),modelNow.score(),1e-8);
  assertEquals(modelExpectedArch.params(),modelNow.params());
}
