@Test public void simpleFineTune(){
  long rng=12345L;
  DataSet randomData=new DataSet(Nd4j.rand(10,4),Nd4j.rand(10,3));
  ComputationGraphConfiguration confToChange=new NeuralNetConfiguration.Builder().seed(rng).optimizationAlgo(OptimizationAlgorithm.LBFGS).updater(new Nesterovs(0.01,0.99)).graphBuilder().addInputs("layer0In").setInputTypes(InputType.feedForward(4)).addLayer("layer0",new DenseLayer.Builder().nIn(4).nOut(3).build(),"layer0In").addLayer("layer1",new org.deeplearning4j.nn.conf.layers.OutputLayer.Builder(LossFunctions.LossFunction.MCXENT).activation(Activation.SOFTMAX).nIn(3).nOut(3).build(),"layer0").setOutputs("layer1").build();
  ComputationGraphConfiguration expectedConf=new NeuralNetConfiguration.Builder().seed(rng).updater(new RmsProp(0.2)).graphBuilder().addInputs("layer0In").setInputTypes(InputType.feedForward(4)).addLayer("layer0",new DenseLayer.Builder().nIn(4).nOut(3).build(),"layer0In").addLayer("layer1",new org.deeplearning4j.nn.conf.layers.OutputLayer.Builder(LossFunctions.LossFunction.MCXENT).activation(Activation.SOFTMAX).nIn(3).nOut(3).build(),"layer0").setOutputs("layer1").build();
  ComputationGraph expectedModel=new ComputationGraph(expectedConf);
  expectedModel.init();
  ComputationGraph modelToFineTune=new ComputationGraph(expectedConf);
  modelToFineTune.init();
  modelToFineTune.setParams(expectedModel.params());
  ComputationGraph modelNow=new TransferLearning.GraphBuilder(modelToFineTune).fineTuneConfiguration(new FineTuneConfiguration.Builder().seed(rng).updater(new RmsProp(0.2)).build()).build();
  assertEquals(expectedConf.toJson(),modelNow.getConfiguration().toJson());
  modelNow.fit(randomData);
  expectedModel.fit(randomData);
  assertEquals(modelNow.score(),expectedModel.score(),1e-8);
  assertEquals(modelNow.params(),expectedModel.params());
}
