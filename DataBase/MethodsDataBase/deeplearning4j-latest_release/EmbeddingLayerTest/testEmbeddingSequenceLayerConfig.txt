@Test public void testEmbeddingSequenceLayerConfig(){
  int inputLength=6;
  int nIn=10;
  int embeddingDim=5;
  int nout=4;
  for (  boolean hasBias : new boolean[]{true,false}) {
    MultiLayerConfiguration conf=new NeuralNetConfiguration.Builder().activation(Activation.TANH).list().layer(new EmbeddingSequenceLayer.Builder().hasBias(hasBias).inputLength(inputLength).nIn(nIn).nOut(embeddingDim).build()).layer(new RnnOutputLayer.Builder().nIn(embeddingDim).nOut(nout).activation(Activation.SOFTMAX).build()).build();
    MultiLayerNetwork net=new MultiLayerNetwork(conf);
    net.init();
    Layer l0=net.getLayer(0);
    assertEquals(org.deeplearning4j.nn.layers.feedforward.embedding.EmbeddingSequenceLayer.class,l0.getClass());
    assertEquals(10,((FeedForwardLayer)l0.conf().getLayer()).getNIn());
    assertEquals(5,((FeedForwardLayer)l0.conf().getLayer()).getNOut());
    INDArray weights=l0.getParam(DefaultParamInitializer.WEIGHT_KEY);
    INDArray bias=l0.getParam(DefaultParamInitializer.BIAS_KEY);
    assertArrayEquals(new long[]{10,5},weights.shape());
    if (hasBias) {
      assertArrayEquals(new long[]{1,5},bias.shape());
    }
  }
}
