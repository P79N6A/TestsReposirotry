@Test public void testDropoutSimple() throws Exception {
  int nIn=8;
  int nOut=8;
  MultiLayerConfiguration conf=new NeuralNetConfiguration.Builder().updater(new Sgd()).dropOut(0.5).list().layer(0,new OutputLayer.Builder().activation(Activation.IDENTITY).lossFunction(LossFunctions.LossFunction.MSE).nIn(nIn).nOut(nOut).weightInit(WeightInit.XAVIER).build()).build();
  MultiLayerNetwork net=new MultiLayerNetwork(conf);
  net.init();
  net.getLayer(0).getParam("W").assign(Nd4j.eye(nIn));
  int nTests=15;
  Nd4j.getRandom().setSeed(12345);
  int noDropoutCount=0;
  for (int i=0; i < nTests; i++) {
    INDArray in=Nd4j.rand(1,nIn);
    INDArray out=Nd4j.rand(1,nOut);
    INDArray inCopy=in.dup();
    List<INDArray> l=net.feedForward(in,true);
    INDArray postDropout=l.get(l.size() - 1);
    for (int j=0; j < inCopy.length(); j++) {
      double origValue=inCopy.getDouble(j);
      double doValue=postDropout.getDouble(j);
      if (doValue > 0.0) {
        assertEquals(origValue * 2.0,doValue,0.0001);
      }
    }
    INDArray in2=Nd4j.rand(1,nIn);
    INDArray out2=Nd4j.rand(1,nOut);
    INDArray outTest1=net.output(in2,false);
    INDArray outTest2=net.output(in2,false);
    INDArray outTest3=net.output(in2,false);
    assertEquals(outTest1,outTest2);
    assertEquals(outTest1,outTest3);
    double score1=net.score(new DataSet(in2,out2),false);
    double score2=net.score(new DataSet(in2,out2),false);
    double score3=net.score(new DataSet(in2,out2),false);
    assertEquals(score1,score2,0.0);
    assertEquals(score1,score3,0.0);
  }
  if (noDropoutCount >= nTests / 3) {
    fail("Too many instances of dropout not being applied");
  }
}
