@Test public void testFrozenMLN(){
  MultiLayerNetwork orig=getOriginalNet(12345);
  for (  double l1 : new double[]{0.0,0.3}) {
    for (    double l2 : new double[]{0.0,0.4}) {
      System.out.println("--------------------");
      String msg="l1=" + l1 + ", l2="+ l2;
      FineTuneConfiguration ftc=new FineTuneConfiguration.Builder().updater(new Sgd(0.5)).l1(l1).l2(l2).build();
      MultiLayerNetwork transfer=new TransferLearning.Builder(orig).fineTuneConfiguration(ftc).setFeatureExtractor(4).removeOutputLayer().addLayer(new OutputLayer.Builder().nIn(64).nOut(10).lossFunction(LossFunctions.LossFunction.MEAN_ABSOLUTE_ERROR).build()).build();
      assertEquals(6,transfer.getnLayers());
      for (int i=0; i < 5; i++) {
        assertTrue(transfer.getLayer(i) instanceof FrozenLayer);
      }
      Map<String,INDArray> paramsBefore=new LinkedHashMap<>();
      for (      Map.Entry<String,INDArray> entry : transfer.paramTable().entrySet()) {
        paramsBefore.put(entry.getKey(),entry.getValue().dup());
      }
      for (int i=0; i < 20; i++) {
        INDArray f=Nd4j.rand(new int[]{16,1,28,28});
        INDArray l=Nd4j.rand(new int[]{16,10});
        transfer.fit(f,l);
      }
      for (      Map.Entry<String,INDArray> entry : transfer.paramTable().entrySet()) {
        String s=msg + " - " + entry.getKey();
        if (entry.getKey().startsWith("5_")) {
          assertNotEquals(s,paramsBefore.get(entry.getKey()),entry.getValue());
        }
 else {
          assertEquals(s,paramsBefore.get(entry.getKey()),entry.getValue());
        }
      }
    }
  }
}
