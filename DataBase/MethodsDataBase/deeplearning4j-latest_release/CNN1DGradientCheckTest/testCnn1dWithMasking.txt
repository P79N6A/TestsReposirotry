@Test public void testCnn1dWithMasking(){
  int length=12;
  int convNIn=2;
  int convNOut1=3;
  int convNOut2=4;
  int finalNOut=3;
  int pnorm=2;
  SubsamplingLayer.PoolingType[] poolingTypes=new SubsamplingLayer.PoolingType[]{SubsamplingLayer.PoolingType.MAX,SubsamplingLayer.PoolingType.AVG};
  for (  SubsamplingLayer.PoolingType poolingType : poolingTypes) {
    for (    ConvolutionMode cm : new ConvolutionMode[]{ConvolutionMode.Same,ConvolutionMode.Truncate}) {
      for (      int stride : new int[]{1,2}) {
        String s=cm + ", stride=" + stride+ ", pooling="+ poolingType;
        log.info("Starting test: " + s);
        Nd4j.getRandom().setSeed(12345);
        MultiLayerConfiguration conf=new NeuralNetConfiguration.Builder().updater(new NoOp()).weightInit(WeightInit.DISTRIBUTION).activation(Activation.TANH).dist(new NormalDistribution(0,1)).convolutionMode(cm).seed(12345).list().layer(new Convolution1DLayer.Builder().kernelSize(2).stride(stride).nIn(convNIn).nOut(convNOut1).build()).layer(new Subsampling1DLayer.Builder(poolingType).kernelSize(2).stride(stride).pnorm(pnorm).build()).layer(new Convolution1DLayer.Builder().kernelSize(2).stride(stride).nIn(convNOut1).nOut(convNOut2).build()).layer(new GlobalPoolingLayer(PoolingType.AVG)).layer(new OutputLayer.Builder(LossFunctions.LossFunction.MCXENT).activation(Activation.SOFTMAX).nOut(finalNOut).build()).setInputType(InputType.recurrent(convNIn,length)).build();
        MultiLayerNetwork net=new MultiLayerNetwork(conf);
        net.init();
        INDArray f=Nd4j.rand(new int[]{2,convNIn,length});
        INDArray fm=Nd4j.create(2,length);
        fm.get(NDArrayIndex.point(0),NDArrayIndex.all()).assign(1);
        fm.get(NDArrayIndex.point(1),NDArrayIndex.interval(0,6)).assign(1);
        INDArray label=TestUtils.randomOneHot(2,finalNOut);
        boolean gradOK=GradientCheckUtil.checkGradients(net,DEFAULT_EPS,DEFAULT_MAX_REL_ERROR,DEFAULT_MIN_ABS_ERROR,PRINT_RESULTS,RETURN_ON_FIRST_FAILURE,f,label,fm,null);
        assertTrue(s,gradOK);
        TestUtils.testModelSerialization(net);
        DataSet ds=new DataSet(f,label,fm,null);
        double scoreBefore=net.score(ds);
        net.setInput(f);
        net.setLabels(label);
        net.setLayerMaskArrays(fm,null);
        net.computeGradientAndScore();
        INDArray gradBefore=net.getFlattenedGradients().dup();
        f.putScalar(1,0,10,10.0);
        f.putScalar(1,1,11,20.0);
        double scoreAfter=net.score(ds);
        net.setInput(f);
        net.setLabels(label);
        net.setLayerMaskArrays(fm,null);
        net.computeGradientAndScore();
        INDArray gradAfter=net.getFlattenedGradients().dup();
        assertEquals(scoreBefore,scoreAfter,1e-6);
        assertEquals(gradBefore,gradAfter);
      }
    }
  }
}
