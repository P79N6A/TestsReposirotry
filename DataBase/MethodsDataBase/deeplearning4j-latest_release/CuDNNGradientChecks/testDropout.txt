@Test public void testDropout(){
  int minibatch=3;
  for (  boolean cnn : new boolean[]{false,true}) {
    Nd4j.getRandom().setSeed(12345);
    IDropout dropout=new Dropout(0.6);
    NeuralNetConfiguration.ListBuilder builder=new NeuralNetConfiguration.Builder().seed(12345).weightInit(WeightInit.DISTRIBUTION).dist(new NormalDistribution(0,1)).convolutionMode(ConvolutionMode.Same).dropOut(dropout).activation(Activation.TANH).updater(new NoOp()).list();
    if (cnn) {
      builder.layer(new ConvolutionLayer.Builder().kernelSize(3,3).stride(1,1).nOut(3).build());
      builder.layer(new ConvolutionLayer.Builder().kernelSize(3,3).stride(1,1).nOut(3).build());
      builder.setInputType(InputType.convolutional(8,8,3));
    }
 else {
      builder.layer(new DenseLayer.Builder().nOut(12).build());
      builder.layer(new DenseLayer.Builder().nOut(12).build());
      builder.setInputType(InputType.feedForward(8));
    }
    builder.layer(new OutputLayer.Builder().nOut(10).activation(Activation.SOFTMAX).lossFunction(LossFunctions.LossFunction.MCXENT).build());
    MultiLayerConfiguration conf=builder.build();
    MultiLayerNetwork mln=new MultiLayerNetwork(conf);
    mln.init();
    for (    Layer l : mln.getLayers()) {
      Dropout d=(Dropout)l.conf().getLayer().getIDropout();
      assertNotNull(d);
      CudnnDropoutHelper h=(CudnnDropoutHelper)d.getHelper();
      assertNotNull(h);
    }
    String msg=(cnn ? "CNN" : "Dense") + ": " + dropout.getClass().getSimpleName();
    INDArray f;
    if (cnn) {
      f=Nd4j.rand(new int[]{minibatch,3,8,8}).muli(10).subi(5);
    }
 else {
      f=Nd4j.rand(minibatch,8).muli(10).subi(5);
    }
    INDArray l=TestUtils.randomOneHot(minibatch,10);
    Consumer<MultiLayerNetwork> c=new Consumer<MultiLayerNetwork>(){
      @Override public void accept(      MultiLayerNetwork net){
        Nd4j.getRandom().setSeed(12345);
        for (        Layer l : net.getLayers()) {
          Dropout d=(Dropout)l.conf().getLayer().getIDropout();
          if (d != null) {
            ((CudnnDropoutHelper)d.getHelper()).setMask(null);
            ((CudnnDropoutHelper)d.getHelper()).setRngStates(null);
          }
        }
      }
    }
;
    log.info("*** Starting test: " + msg + " ***");
    boolean gradOK=GradientCheckUtil.checkGradients(mln,DEFAULT_EPS,DEFAULT_MAX_REL_ERROR,DEFAULT_MIN_ABS_ERROR,PRINT_RESULTS,RETURN_ON_FIRST_FAILURE,f,l,null,null,false,-1,null,c);
    assertTrue(msg,gradOK);
    TestUtils.testModelSerialization(mln);
  }
}
