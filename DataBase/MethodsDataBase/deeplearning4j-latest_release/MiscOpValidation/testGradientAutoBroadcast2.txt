@Test public void testGradientAutoBroadcast2(){
  Nd4j.getRandom().setSeed(12345);
  List<String> failed=new ArrayList<>();
  for (  int[] dim_sz1s : new int[][]{{0,1},{0,2},{1,2},{0,1,2}}) {
    int[] otherShape={3,4,5};
    otherShape[dim_sz1s[0]]=1;
    otherShape[dim_sz1s[1]]=1;
    if (dim_sz1s.length == 3) {
      otherShape[dim_sz1s[2]]=1;
    }
    for (int i=0; i < 8; i++) {
      SameDiff sd=SameDiff.create();
      SDVariable in3=sd.var("in3",new int[]{3,4,5});
      SDVariable in2=sd.var("inToBc",otherShape);
      String name;
      SDVariable bcOp;
switch (i) {
case 0:
        bcOp=in3.add(in2);
      name="add";
    break;
case 1:
  bcOp=in3.sub(in2);
name="sub";
break;
case 2:
bcOp=in3.mul(in2);
name="mul";
break;
case 3:
bcOp=in3.div(in2);
name="div";
break;
case 4:
bcOp=in3.rsub(in2);
name="rsub";
break;
case 5:
bcOp=in3.rdiv(in2);
name="rdiv";
break;
case 6:
bcOp=sd.f().floorDiv(in3,in2);
name="floordiv";
break;
case 7:
bcOp=sd.f().floorMod(in3,in2);
name="floormod";
if (OpValidationSuite.IGNORE_FAILING) {
continue;
}
break;
default :
throw new RuntimeException();
}
SDVariable outVar=sd.sum(bcOp);
String msg="(test " + i + ": "+ name+ ", dimensions="+ Arrays.toString(dim_sz1s)+ ")";
log.info("*** Starting test: " + msg);
INDArray in3Arr=Nd4j.randn(new int[]{3,4,5}).muli(100);
INDArray in2Arr=Nd4j.randn(otherShape).muli(100);
sd.associateArrayWithVariable(in3Arr,in3);
sd.associateArrayWithVariable(in2Arr,in2);
TestCase tc=new TestCase(sd);
String error=OpValidation.validate(tc);
if (error != null) {
failed.add(name);
}
}
}
assertEquals("Failed: " + failed,0,failed.size());
}
