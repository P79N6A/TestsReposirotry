@Test public void regressionTestCNN1() throws Exception {
  File f=new ClassPathResource("regression_testing/080/080_ModelSerializer_Regression_CNN_1.zip").getTempFileFromArchive();
  MultiLayerNetwork net=ModelSerializer.restoreMultiLayerNetwork(f,true);
  MultiLayerConfiguration conf=net.getLayerWiseConfigurations();
  assertEquals(3,conf.getConfs().size());
  assertTrue(conf.isBackprop());
  assertFalse(conf.isPretrain());
  ConvolutionLayer l0=(ConvolutionLayer)conf.getConf(0).getLayer();
  assertTrue(l0.getActivationFn() instanceof ActivationTanH);
  assertEquals(3,l0.getNIn());
  assertEquals(3,l0.getNOut());
  assertEquals(WeightInit.RELU,l0.getWeightInit());
  assertTrue(l0.getIUpdater() instanceof RmsProp);
  RmsProp r=(RmsProp)l0.getIUpdater();
  assertEquals(0.96,r.getRmsDecay(),1e-6);
  assertEquals(0.15,r.getLearningRate(),1e-6);
  assertEquals(0.15,((RmsProp)l0.getIUpdater()).getLearningRate(),1e-6);
  assertArrayEquals(new int[]{2,2},l0.getKernelSize());
  assertArrayEquals(new int[]{1,1},l0.getStride());
  assertArrayEquals(new int[]{0,0},l0.getPadding());
  assertEquals(l0.getConvolutionMode(),ConvolutionMode.Same);
  SubsamplingLayer l1=(SubsamplingLayer)conf.getConf(1).getLayer();
  assertArrayEquals(new int[]{2,2},l1.getKernelSize());
  assertArrayEquals(new int[]{1,1},l1.getStride());
  assertArrayEquals(new int[]{0,0},l1.getPadding());
  assertEquals(PoolingType.MAX,l1.getPoolingType());
  assertEquals(l1.getConvolutionMode(),ConvolutionMode.Same);
  OutputLayer l2=(OutputLayer)conf.getConf(2).getLayer();
  assertTrue(l2.getActivationFn() instanceof ActivationSigmoid);
  assertTrue(l2.getLossFn() instanceof LossNegativeLogLikelihood);
  assertEquals(26 * 26 * 3,l2.getNIn());
  assertEquals(5,l2.getNOut());
  assertEquals(WeightInit.RELU,l2.getWeightInit());
  assertTrue(l2.getIUpdater() instanceof RmsProp);
  r=(RmsProp)l2.getIUpdater();
  assertEquals(0.96,r.getRmsDecay(),1e-6);
  assertEquals(0.15,r.getLearningRate(),1e-6);
  assertTrue(conf.getInputPreProcess(2) instanceof CnnToFeedForwardPreProcessor);
  int numParams=(int)net.numParams();
  assertEquals(Nd4j.linspace(1,numParams,numParams),net.params());
  int updaterSize=(int)new RmsProp().stateSize(numParams);
  assertEquals(Nd4j.linspace(1,updaterSize,updaterSize),net.getUpdater().getStateViewArray());
  assertTrue(net.getLayerWiseConfigurations().isLegacyBatchScaledL2());
  assertTrue(l2.isLegacyBatchScaledL2());
}
