@Test @SuppressWarnings("deprecation") public void testAbortRetryWhenProducerIdChanges() throws InterruptedException {
  final long producerId=343434L;
  TransactionManager transactionManager=new TransactionManager();
  transactionManager.setProducerIdAndEpoch(new ProducerIdAndEpoch(producerId,(short)0));
  setupWithTransactionState(transactionManager);
  client.setNode(new Node(1,"localhost",33343));
  int maxRetries=10;
  Metrics m=new Metrics();
  SenderMetricsRegistry senderMetrics=new SenderMetricsRegistry(m);
  Sender sender=new Sender(logContext,client,metadata,this.accumulator,true,MAX_REQUEST_SIZE,ACKS_ALL,maxRetries,senderMetrics,time,REQUEST_TIMEOUT,50,transactionManager,apiVersions);
  Future<RecordMetadata> responseFuture=accumulator.append(tp0,time.milliseconds(),"key".getBytes(),"value".getBytes(),null,null,MAX_BLOCK_TIMEOUT).future;
  sender.run(time.milliseconds());
  sender.run(time.milliseconds());
  String id=client.requests().peek().destination();
  Node node=new Node(Integer.valueOf(id),"localhost",0);
  assertEquals(1,client.inFlightRequestCount());
  assertTrue("Client ready status should be true",client.isReady(node,0L));
  client.disconnect(id);
  assertEquals(0,client.inFlightRequestCount());
  assertFalse("Client ready status should be false",client.isReady(node,0L));
  transactionManager.resetProducerId();
  transactionManager.setProducerIdAndEpoch(new ProducerIdAndEpoch(producerId + 1,(short)0));
  sender.run(time.milliseconds());
  sender.run(time.milliseconds());
  sender.run(time.milliseconds());
  assertEquals("Expected requests to be aborted after pid change",0,client.inFlightRequestCount());
  KafkaMetric recordErrors=m.metrics().get(senderMetrics.recordErrorRate);
  assertTrue("Expected non-zero value for record send errors",(Double)recordErrors.metricValue() > 0);
  assertTrue(responseFuture.isDone());
  assertEquals(0,(long)transactionManager.sequenceNumber(tp0));
}
