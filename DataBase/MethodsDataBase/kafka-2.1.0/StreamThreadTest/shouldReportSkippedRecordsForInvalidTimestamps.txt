@Test public void shouldReportSkippedRecordsForInvalidTimestamps(){
  final LogCaptureAppender appender=LogCaptureAppender.createAndRegister();
  internalTopologyBuilder.addSource(null,"source1",null,null,null,topic1);
  final Properties config=configProps(false);
  config.setProperty(StreamsConfig.DEFAULT_TIMESTAMP_EXTRACTOR_CLASS_CONFIG,LogAndSkipOnInvalidTimestamp.class.getName());
  final StreamThread thread=createStreamThread(clientId,new StreamsConfig(config),false);
  thread.setState(StreamThread.State.RUNNING);
  thread.setState(StreamThread.State.PARTITIONS_REVOKED);
  final Set<TopicPartition> assignedPartitions=Collections.singleton(t1p1);
  thread.taskManager().setAssignmentMetadata(Collections.singletonMap(new TaskId(0,t1p1.partition()),assignedPartitions),Collections.<TaskId,Set<TopicPartition>>emptyMap());
  final MockConsumer<byte[],byte[]> mockConsumer=(MockConsumer<byte[],byte[]>)thread.consumer;
  mockConsumer.assign(Collections.singleton(t1p1));
  mockConsumer.updateBeginningOffsets(Collections.singletonMap(t1p1,0L));
  thread.rebalanceListener.onPartitionsAssigned(assignedPartitions);
  thread.runOnce();
  final MetricName skippedTotalMetric=metrics.metricName("skipped-records-total","stream-metrics",Collections.singletonMap("client-id",thread.getName()));
  final MetricName skippedRateMetric=metrics.metricName("skipped-records-rate","stream-metrics",Collections.singletonMap("client-id",thread.getName()));
  assertEquals(0.0,metrics.metric(skippedTotalMetric).metricValue());
  assertEquals(0.0,metrics.metric(skippedRateMetric).metricValue());
  long offset=-1;
  mockConsumer.addRecord(new ConsumerRecord<>(t1p1.topic(),t1p1.partition(),++offset,-1,TimestampType.CREATE_TIME,-1,-1,-1,new byte[0],new byte[0]));
  mockConsumer.addRecord(new ConsumerRecord<>(t1p1.topic(),t1p1.partition(),++offset,-1,TimestampType.CREATE_TIME,-1,-1,-1,new byte[0],new byte[0]));
  thread.runOnce();
  assertEquals(2.0,metrics.metric(skippedTotalMetric).metricValue());
  assertNotEquals(0.0,metrics.metric(skippedRateMetric).metricValue());
  mockConsumer.addRecord(new ConsumerRecord<>(t1p1.topic(),t1p1.partition(),++offset,-1,TimestampType.CREATE_TIME,-1,-1,-1,new byte[0],new byte[0]));
  mockConsumer.addRecord(new ConsumerRecord<>(t1p1.topic(),t1p1.partition(),++offset,-1,TimestampType.CREATE_TIME,-1,-1,-1,new byte[0],new byte[0]));
  mockConsumer.addRecord(new ConsumerRecord<>(t1p1.topic(),t1p1.partition(),++offset,-1,TimestampType.CREATE_TIME,-1,-1,-1,new byte[0],new byte[0]));
  mockConsumer.addRecord(new ConsumerRecord<>(t1p1.topic(),t1p1.partition(),++offset,-1,TimestampType.CREATE_TIME,-1,-1,-1,new byte[0],new byte[0]));
  thread.runOnce();
  assertEquals(6.0,metrics.metric(skippedTotalMetric).metricValue());
  assertNotEquals(0.0,metrics.metric(skippedRateMetric).metricValue());
  mockConsumer.addRecord(new ConsumerRecord<>(t1p1.topic(),t1p1.partition(),++offset,1,TimestampType.CREATE_TIME,-1,-1,-1,new byte[0],new byte[0]));
  mockConsumer.addRecord(new ConsumerRecord<>(t1p1.topic(),t1p1.partition(),++offset,1,TimestampType.CREATE_TIME,-1,-1,-1,new byte[0],new byte[0]));
  thread.runOnce();
  assertEquals(6.0,metrics.metric(skippedTotalMetric).metricValue());
  assertNotEquals(0.0,metrics.metric(skippedRateMetric).metricValue());
  LogCaptureAppender.unregister(appender);
  final List<String> strings=appender.getMessages();
  assertTrue(strings.contains("task [0_1] Skipping record due to negative extracted timestamp. " + "topic=[topic1] partition=[1] offset=[0] extractedTimestamp=[-1] " + "extractor=[org.apache.kafka.streams.processor.LogAndSkipOnInvalidTimestamp]"));
  assertTrue(strings.contains("task [0_1] Skipping record due to negative extracted timestamp. " + "topic=[topic1] partition=[1] offset=[1] extractedTimestamp=[-1] " + "extractor=[org.apache.kafka.streams.processor.LogAndSkipOnInvalidTimestamp]"));
  assertTrue(strings.contains("task [0_1] Skipping record due to negative extracted timestamp. " + "topic=[topic1] partition=[1] offset=[2] extractedTimestamp=[-1] " + "extractor=[org.apache.kafka.streams.processor.LogAndSkipOnInvalidTimestamp]"));
  assertTrue(strings.contains("task [0_1] Skipping record due to negative extracted timestamp. " + "topic=[topic1] partition=[1] offset=[3] extractedTimestamp=[-1] " + "extractor=[org.apache.kafka.streams.processor.LogAndSkipOnInvalidTimestamp]"));
  assertTrue(strings.contains("task [0_1] Skipping record due to negative extracted timestamp. " + "topic=[topic1] partition=[1] offset=[4] extractedTimestamp=[-1] " + "extractor=[org.apache.kafka.streams.processor.LogAndSkipOnInvalidTimestamp]"));
  assertTrue(strings.contains("task [0_1] Skipping record due to negative extracted timestamp. " + "topic=[topic1] partition=[1] offset=[5] extractedTimestamp=[-1] " + "extractor=[org.apache.kafka.streams.processor.LogAndSkipOnInvalidTimestamp]"));
}
