@Test public void shouldDuplicateRecordUsingNewHeaders(){
  Headers newHeaders=new ConnectHeaders().addString("h3","hv3");
  SinkRecord duplicate=record.newRecord(TOPIC_NAME,PARTITION_NUMBER,Schema.STRING_SCHEMA,"key",Schema.BOOLEAN_SCHEMA,false,KAFKA_TIMESTAMP,newHeaders);
  assertEquals(TOPIC_NAME,duplicate.topic());
  assertEquals(PARTITION_NUMBER,duplicate.kafkaPartition());
  assertEquals(Schema.STRING_SCHEMA,duplicate.keySchema());
  assertEquals("key",duplicate.key());
  assertEquals(Schema.BOOLEAN_SCHEMA,duplicate.valueSchema());
  assertEquals(false,duplicate.value());
  assertEquals(KAFKA_OFFSET,duplicate.kafkaOffset());
  assertEquals(KAFKA_TIMESTAMP,duplicate.timestamp());
  assertEquals(TS_TYPE,duplicate.timestampType());
  assertNotNull(duplicate.headers());
  assertEquals(newHeaders,duplicate.headers());
  assertSame(newHeaders,duplicate.headers());
  assertNotSame(record.headers(),duplicate.headers());
  assertNotEquals(record.headers(),duplicate.headers());
}
