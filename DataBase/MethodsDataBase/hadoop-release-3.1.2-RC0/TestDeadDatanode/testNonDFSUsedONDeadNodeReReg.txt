@Test public void testNonDFSUsedONDeadNodeReReg() throws Exception {
  Configuration conf=new HdfsConfiguration();
  conf.setInt(DFSConfigKeys.DFS_HEARTBEAT_INTERVAL_KEY,1);
  conf.setInt(DFSConfigKeys.DFS_NAMENODE_HEARTBEAT_RECHECK_INTERVAL_KEY,3000);
  conf.setInt(DFSConfigKeys.DFS_NAMENODE_STALE_DATANODE_INTERVAL_KEY,6 * 1000);
  long CAPACITY=5000L;
  long[] capacities=new long[]{4 * CAPACITY,4 * CAPACITY};
  try {
    cluster=new MiniDFSCluster.Builder(conf).numDataNodes(2).simulatedCapacities(capacities).build();
    long initialCapacity=cluster.getNamesystem(0).getCapacityTotal();
    assertTrue(initialCapacity > 0);
    DataNode dn1=cluster.getDataNodes().get(0);
    DataNode dn2=cluster.getDataNodes().get(1);
    final DatanodeDescriptor dn2Desc=cluster.getNamesystem(0).getBlockManager().getDatanodeManager().getDatanode(dn2.getDatanodeId());
    dn1.setHeartbeatsDisabledForTests(true);
    cluster.setDataNodeDead(dn1.getDatanodeId());
    assertEquals("Capacity shouldn't include DeadNode",dn2Desc.getCapacity(),cluster.getNamesystem(0).getCapacityTotal());
    assertEquals("NonDFS-used shouldn't include DeadNode",dn2Desc.getNonDfsUsed(),cluster.getNamesystem(0).getNonDfsUsedSpace());
    dn1.setHeartbeatsDisabledForTests(false);
    final DatanodeDescriptor dn1Desc=cluster.getNamesystem(0).getBlockManager().getDatanodeManager().getDatanode(dn1.getDatanodeId());
    GenericTestUtils.waitFor(new Supplier<Boolean>(){
      @Override public Boolean get(){
        return dn1Desc.isAlive() && dn1Desc.isHeartbeatedSinceRegistration();
      }
    }
,100,5000);
    assertEquals("Capacity should be 0 after all DNs dead",initialCapacity,cluster.getNamesystem(0).getCapacityTotal());
    long nonDfsAfterReg=cluster.getNamesystem(0).getNonDfsUsedSpace();
    assertEquals("NonDFS should include actual DN NonDFSUsed",dn1Desc.getNonDfsUsed() + dn2Desc.getNonDfsUsed(),nonDfsAfterReg);
  }
  finally {
    if (cluster != null) {
      cluster.shutdown();
    }
  }
}
