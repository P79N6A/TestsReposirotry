/** 
 * The corrupt block has to be removed when the number of valid replicas matches replication factor for the file. In this test, the above  condition is achieved by increasing the number of good replicas by  replicating on a new Datanode.  The test strategy :  Bring up Cluster with 3 DataNodes Create a file  of replication factor 3 Corrupt one replica of a block of the file  Verify that there are still 2 good replicas and 1 corrupt replica  (corrupt replica should not be removed since number of good replicas (2) is less  than replication factor (3))  Start a new data node  Verify that the a new replica is created and corrupt replica is removed.
 */
@Test public void testByAddingAnExtraDataNode() throws Exception {
  Configuration conf=new HdfsConfiguration();
  conf.setLong(DFSConfigKeys.DFS_BLOCKREPORT_INTERVAL_MSEC_KEY,1000L);
  conf.set(DFSConfigKeys.DFS_NAMENODE_RECONSTRUCTION_PENDING_TIMEOUT_SEC_KEY,Integer.toString(2));
  MiniDFSCluster cluster=new MiniDFSCluster.Builder(conf).numDataNodes(4).build();
  FileSystem fs=cluster.getFileSystem();
  final FSNamesystem namesystem=cluster.getNamesystem();
  DataNodeProperties dnPropsFourth=cluster.stopDataNode(3);
  try {
    final Path fileName=new Path("/foo1");
    DFSTestUtil.createFile(fs,fileName,2,(short)3,0L);
    DFSTestUtil.waitReplication(fs,fileName,(short)3);
    ExtendedBlock block=DFSTestUtil.getFirstBlock(fs,fileName);
    corruptBlock(cluster,fs,fileName,0,block);
    DFSTestUtil.waitReplication(fs,fileName,(short)2);
    assertEquals(2,countReplicas(namesystem,block).liveReplicas());
    assertEquals(1,countReplicas(namesystem,block).corruptReplicas());
    cluster.restartDataNode(dnPropsFourth);
    DFSTestUtil.waitReplication(fs,fileName,(short)3);
    assertEquals(3,countReplicas(namesystem,block).liveReplicas());
    assertEquals(0,countReplicas(namesystem,block).corruptReplicas());
  }
  finally {
    cluster.shutdown();
  }
}
