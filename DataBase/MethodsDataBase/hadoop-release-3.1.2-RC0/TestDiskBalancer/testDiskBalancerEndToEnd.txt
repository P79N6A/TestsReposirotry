/** 
 * This test simulates a real Data node working with DiskBalancer. <p> Here is the overview of this test. <p> 1. Write a bunch of blocks and move them to one disk to create imbalance. 2. Rewrite  the capacity of the disks in DiskBalancer Model so that planner will produce a move plan. 3. Execute the move plan and wait unitl the plan is done. 4. Verify the source disk has blocks now.
 * @throws Exception
 */
@Test public void testDiskBalancerEndToEnd() throws Exception {
  Configuration conf=new HdfsConfiguration();
  conf.setBoolean(DFSConfigKeys.DFS_DISK_BALANCER_ENABLED,true);
  final int blockCount=100;
  final int blockSize=1024;
  final int diskCount=2;
  final int dataNodeCount=1;
  final int dataNodeIndex=0;
  final int sourceDiskIndex=0;
  final long cap=blockSize * 2L * blockCount;
  MiniDFSCluster cluster=new ClusterBuilder().setBlockCount(blockCount).setBlockSize(blockSize).setDiskCount(diskCount).setNumDatanodes(dataNodeCount).setConf(conf).setCapacities(new long[]{cap,cap}).build();
  try {
    DataMover dataMover=new DataMover(cluster,dataNodeIndex,sourceDiskIndex,conf,blockSize,blockCount);
    dataMover.moveDataToSourceDisk();
    NodePlan plan=dataMover.generatePlan();
    dataMover.executePlan(plan);
    dataMover.verifyPlanExectionDone();
    dataMover.verifyAllVolumesHaveData(true);
    dataMover.verifyTolerance(plan,0,sourceDiskIndex,10);
  }
  finally {
    cluster.shutdown();
  }
}
