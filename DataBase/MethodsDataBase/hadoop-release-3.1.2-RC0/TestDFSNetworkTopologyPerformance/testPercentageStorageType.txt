/** 
 * This is a helper test, can be changed to different distribution each run. Changing the value percentage = X where X is between 0.0 to 1.0 will result in different outcomes. This is to help understanding what is the boundary that makes the new approach better than the old one. The lower X is, the less likely the old approach will succeed in one call, in which case the new approach is more likely to be better.
 * @throws Exception
 */
@Test public void testPercentageStorageType() throws Exception {
  double percentage=0.9;
  for (int i=0; i < NODE_NUM; i++) {
    if (coinFlip(percentage)) {
      types[i]=StorageType.ARCHIVE;
    }
 else {
      types[i]=StorageType.DISK;
    }
  }
  addNodeByTypes(types);
  Thread.sleep(1000);
  printMemUsage("before test1");
  totalStart=System.nanoTime();
  totalTrials=0;
  for (int i=0; i < OP_NUM; i++) {
    localStart=System.nanoTime();
    do {
      totalTrials+=1;
      node=cluster.chooseRandom("",excluded);
      assertNotNull(node);
      if (isType(node,StorageType.ARCHIVE)) {
        break;
      }
      excluded.add(node);
    }
 while (true);
    excluded.clear();
    localEnd=System.nanoTime();
    records[i]=localEnd - localStart;
  }
  totalEnd=System.nanoTime();
  totalMs=(totalEnd - totalStart) / NS_TO_MS;
  LOG.info("total time: {} avg time: {} avg trials: {}",totalMs,totalMs / OP_NUM,(float)totalTrials / OP_NUM);
  Thread.sleep(1000);
  printMemUsage("after test1 before test2");
  totalStart=System.nanoTime();
  for (int i=0; i < OP_NUM; i++) {
    localStart=System.nanoTime();
    node=dfscluster.chooseRandomWithStorageType("",excluded,StorageType.ARCHIVE);
    assertNotNull(node);
    assertTrue(isType(node,StorageType.ARCHIVE));
    localEnd=System.nanoTime();
    records[i]=localEnd - localStart;
  }
  totalEnd=System.nanoTime();
  totalMs=(totalEnd - totalStart) / NS_TO_MS;
  LOG.info("total time: {} avg time: {}",totalMs,totalMs / OP_NUM);
  printMemUsage("after test2");
}
