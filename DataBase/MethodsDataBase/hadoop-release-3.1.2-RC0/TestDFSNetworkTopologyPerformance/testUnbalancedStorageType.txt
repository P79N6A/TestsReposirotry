/** 
 * There are two storage types DISK and ARCHIVE. DISK compose the majority and ARCHIVE only compose 1/20 nodes, uniformly distributed. This test also runs two tests, one with old approach and one with the new approach. Try to search for ARCHIVE type devices. This test show how new approach can outperform the old one.
 * @throws Exception
 */
@Test public void testUnbalancedStorageType() throws Exception {
  for (int i=0; i < NODE_NUM; i++) {
    types[i]=StorageType.DISK;
  }
  for (int i=0; i < NODE_NUM / 20; i++) {
    types[RANDOM.nextInt(NODE_NUM)]=StorageType.ARCHIVE;
  }
  addNodeByTypes(types);
  Thread.sleep(1000);
  printMemUsage("before test1");
  totalStart=System.nanoTime();
  totalTrials=0;
  for (int i=0; i < OP_NUM; i++) {
    localStart=System.nanoTime();
    do {
      totalTrials+=1;
      node=cluster.chooseRandom("",excluded);
      assertNotNull(node);
      if (isType(node,StorageType.ARCHIVE)) {
        break;
      }
      excluded.add(node);
    }
 while (true);
    excluded.clear();
    localEnd=System.nanoTime();
    records[i]=localEnd - localStart;
  }
  totalEnd=System.nanoTime();
  totalMs=(totalEnd - totalStart) / NS_TO_MS;
  LOG.info("total time: {} avg time: {} avg trials: {}",totalMs,totalMs / OP_NUM,(float)totalTrials / OP_NUM);
  Thread.sleep(1000);
  printMemUsage("after test1 before test2");
  totalStart=System.nanoTime();
  for (int i=0; i < OP_NUM; i++) {
    localStart=System.nanoTime();
    node=dfscluster.chooseRandomWithStorageType("",excluded,StorageType.ARCHIVE);
    assertNotNull(node);
    assertTrue(isType(node,StorageType.ARCHIVE));
    localEnd=System.nanoTime();
    records[i]=localEnd - localStart;
  }
  totalEnd=System.nanoTime();
  totalMs=(totalEnd - totalStart) / NS_TO_MS;
  LOG.info("total time: {} avg time: {}",totalMs,totalMs / OP_NUM);
  printMemUsage("after test2");
}
