@Test public void testScratchDirCleared() throws Exception {
  MiniDFSCluster m_dfs=new MiniDFSCluster.Builder(new Configuration()).numDataNodes(1).format(true).build();
  HiveConf conf=new HiveConf();
  conf.addResource(m_dfs.getConfiguration(0));
  conf.set(HiveConf.ConfVars.HIVE_SCRATCH_DIR_LOCK.toString(),"true");
  conf.set(HiveConf.ConfVars.HIVE_SERVER2_CLEAR_DANGLING_SCRATCH_DIR.toString(),"true");
  Path scratchDir=new Path(HiveConf.getVar(conf,HiveConf.ConfVars.SCRATCHDIR));
  m_dfs.getFileSystem().mkdirs(scratchDir);
  m_dfs.getFileSystem().setPermission(scratchDir,new FsPermission("777"));
  SessionState.start(conf);
  conf.setVar(HiveConf.ConfVars.HIVESESSIONID,UUID.randomUUID().toString());
  SessionState.start(conf);
  Path fakeSessionPath=new Path(new Path(scratchDir,Utils.getUGI().getShortUserName()),UUID.randomUUID().toString());
  m_dfs.getFileSystem().mkdirs(fakeSessionPath);
  m_dfs.getFileSystem().create(new Path(fakeSessionPath,"inuse.lck")).close();
  FileStatus[] scratchDirs=m_dfs.getFileSystem().listStatus(new Path(scratchDir,Utils.getUGI().getShortUserName()));
  Assert.assertEquals(scratchDirs.length,3);
  HiveServer2.scheduleClearDanglingScratchDir(conf,0);
  long start=System.currentTimeMillis();
  long end;
  do {
    Thread.sleep(200);
    end=System.currentTimeMillis();
    if (end - start > 5000) {
      Assert.fail("timeout, scratch dir has not been cleared");
    }
    scratchDirs=m_dfs.getFileSystem().listStatus(new Path(scratchDir,Utils.getUGI().getShortUserName()));
  }
 while (scratchDirs.length != 2);
}
