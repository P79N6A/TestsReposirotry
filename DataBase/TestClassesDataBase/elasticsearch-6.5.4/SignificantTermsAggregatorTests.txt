public class SignificantTermsAggregatorTests extends AggregatorTestCase {
  private MappedFieldType fieldType;
  @Before public void setUpTest() throws Exception {
    super.setUp();
    fieldType=new KeywordFieldMapper.KeywordFieldType();
    fieldType.setHasDocValues(true);
    fieldType.setIndexOptions(IndexOptions.DOCS);
    fieldType.setName("field");
  }
  /** 
 * For each provided field type, we also register an alias with name <code>field</code>-alias.
 */
  @Override protected Map<String,MappedFieldType> getFieldAliases(  MappedFieldType... fieldTypes){
    return Arrays.stream(fieldTypes).collect(Collectors.toMap(ft -> ft.name() + "-alias",Function.identity()));
  }
  public void testParsedAsFilter() throws IOException {
    IndexReader indexReader=new MultiReader();
    IndexSearcher indexSearcher=newSearcher(indexReader);
    QueryBuilder filter=QueryBuilders.boolQuery().must(QueryBuilders.termQuery("field","foo")).should(QueryBuilders.termQuery("field","bar"));
    SignificantTermsAggregationBuilder builder=new SignificantTermsAggregationBuilder("test",ValueType.STRING).field("field").backgroundFilter(filter);
    AggregatorFactory<?> factory=createAggregatorFactory(builder,indexSearcher,fieldType);
    assertThat(factory,Matchers.instanceOf(SignificantTermsAggregatorFactory.class));
    SignificantTermsAggregatorFactory sigTermsFactory=(SignificantTermsAggregatorFactory)factory;
    Query parsedQuery=sigTermsFactory.filter;
    assertThat(parsedQuery,Matchers.instanceOf(BooleanQuery.class));
    assertEquals(2,((BooleanQuery)parsedQuery).clauses().size());
    assertEquals(1,((BooleanQuery)parsedQuery).getMinimumNumberShouldMatch());
  }
  /** 
 * Uses the significant terms aggregation to find the keywords in text fields
 */
  public void testSignificance() throws IOException {
    TextFieldType textFieldType=new TextFieldType();
    textFieldType.setName("text");
    textFieldType.setFielddata(true);
    textFieldType.setIndexAnalyzer(new NamedAnalyzer("my_analyzer",AnalyzerScope.GLOBAL,new StandardAnalyzer()));
    IndexWriterConfig indexWriterConfig=newIndexWriterConfig();
    indexWriterConfig.setMaxBufferedDocs(100);
    indexWriterConfig.setRAMBufferSizeMB(100);
    try (Directory dir=newDirectory();IndexWriter w=new IndexWriter(dir,indexWriterConfig)){
      addMixedTextDocs(textFieldType,w);
      SignificantTermsAggregationBuilder sigAgg=new SignificantTermsAggregationBuilder("sig_text",null).field("text");
      sigAgg.executionHint(randomExecutionHint());
      if (randomBoolean()) {
        sigAgg.backgroundFilter(QueryBuilders.termsQuery("text","common"));
      }
      SignificantTermsAggregationBuilder sigNumAgg=new SignificantTermsAggregationBuilder("sig_number",null).field("long_field");
      sigNumAgg.executionHint(randomExecutionHint());
      try (IndexReader reader=DirectoryReader.open(w)){
        assertEquals("test expects a single segment",1,reader.leaves().size());
        IndexSearcher searcher=new IndexSearcher(reader);
        SignificantTerms terms=searchAndReduce(searcher,new TermQuery(new Term("text","odd")),sigAgg,textFieldType);
        assertEquals(1,terms.getBuckets().size());
        assertNull(terms.getBucketByKey("even"));
        assertNull(terms.getBucketByKey("common"));
        assertNotNull(terms.getBucketByKey("odd"));
        terms=searchAndReduce(searcher,new TermQuery(new Term("text","even")),sigAgg,textFieldType);
        assertEquals(1,terms.getBuckets().size());
        assertNull(terms.getBucketByKey("odd"));
        assertNull(terms.getBucketByKey("common"));
        assertNotNull(terms.getBucketByKey("even"));
        sigAgg.includeExclude(new IncludeExclude("o.d",null));
        terms=searchAndReduce(searcher,new TermQuery(new Term("text","odd")),sigAgg,textFieldType);
        assertEquals(1,terms.getBuckets().size());
        assertNotNull(terms.getBucketByKey("odd"));
        assertNull(terms.getBucketByKey("common"));
        assertNull(terms.getBucketByKey("even"));
        String oddStrings[]=new String[]{"odd","weird"};
        String evenStrings[]=new String[]{"even","regular"};
        sigAgg.includeExclude(new IncludeExclude(oddStrings,evenStrings));
        sigAgg.significanceHeuristic(SignificanceHeuristicTests.getRandomSignificanceheuristic());
        terms=searchAndReduce(searcher,new TermQuery(new Term("text","odd")),sigAgg,textFieldType);
        assertEquals(1,terms.getBuckets().size());
        assertNotNull(terms.getBucketByKey("odd"));
        assertNull(terms.getBucketByKey("weird"));
        assertNull(terms.getBucketByKey("common"));
        assertNull(terms.getBucketByKey("even"));
        assertNull(terms.getBucketByKey("regular"));
        sigAgg.includeExclude(new IncludeExclude(evenStrings,oddStrings));
        terms=searchAndReduce(searcher,new TermQuery(new Term("text","odd")),sigAgg,textFieldType);
        assertEquals(0,terms.getBuckets().size());
        assertNull(terms.getBucketByKey("odd"));
        assertNull(terms.getBucketByKey("weird"));
        assertNull(terms.getBucketByKey("common"));
        assertNull(terms.getBucketByKey("even"));
        assertNull(terms.getBucketByKey("regular"));
      }
     }
   }
  /** 
 * Uses the significant terms aggregation to find the keywords in numeric fields
 */
  public void testNumericSignificance() throws IOException {
    NumberFieldType longFieldType=new NumberFieldMapper.NumberFieldType(NumberFieldMapper.NumberType.LONG);
    longFieldType.setName("long_field");
    TextFieldType textFieldType=new TextFieldType();
    textFieldType.setName("text");
    textFieldType.setIndexAnalyzer(new NamedAnalyzer("my_analyzer",AnalyzerScope.GLOBAL,new StandardAnalyzer()));
    IndexWriterConfig indexWriterConfig=newIndexWriterConfig();
    indexWriterConfig.setMaxBufferedDocs(100);
    indexWriterConfig.setRAMBufferSizeMB(100);
    final long ODD_VALUE=3;
    final long EVEN_VALUE=6;
    final long COMMON_VALUE=2;
    try (Directory dir=newDirectory();IndexWriter w=new IndexWriter(dir,indexWriterConfig)){
      for (int i=0; i < 10; i++) {
        Document doc=new Document();
        if (i % 2 == 0) {
          addFields(doc,NumberType.LONG.createFields("long_field",ODD_VALUE,true,true,false));
          doc.add(new Field("text","odd",textFieldType));
        }
 else {
          addFields(doc,NumberType.LONG.createFields("long_field",EVEN_VALUE,true,true,false));
          doc.add(new Field("text","even",textFieldType));
        }
        addFields(doc,NumberType.LONG.createFields("long_field",COMMON_VALUE,true,true,false));
        w.addDocument(doc);
      }
      SignificantTermsAggregationBuilder sigNumAgg=new SignificantTermsAggregationBuilder("sig_number",null).field("long_field");
      sigNumAgg.executionHint(randomExecutionHint());
      try (IndexReader reader=DirectoryReader.open(w)){
        assertEquals("test expects a single segment",1,reader.leaves().size());
        IndexSearcher searcher=new IndexSearcher(reader);
        SignificantLongTerms terms=searchAndReduce(searcher,new TermQuery(new Term("text","odd")),sigNumAgg,longFieldType);
        assertEquals(1,terms.getBuckets().size());
        assertNull(terms.getBucketByKey(Long.toString(EVEN_VALUE)));
        assertNull(terms.getBucketByKey(Long.toString(COMMON_VALUE)));
        assertNotNull(terms.getBucketByKey(Long.toString(ODD_VALUE)));
        terms=searchAndReduce(searcher,new TermQuery(new Term("text","even")),sigNumAgg,longFieldType);
        assertEquals(1,terms.getBuckets().size());
        assertNull(terms.getBucketByKey(Long.toString(ODD_VALUE)));
        assertNull(terms.getBucketByKey(Long.toString(COMMON_VALUE)));
        assertNotNull(terms.getBucketByKey(Long.toString(EVEN_VALUE)));
      }
     }
   }
  /** 
 * Uses the significant terms aggregation on an index with unmapped field
 */
  public void testUnmapped() throws IOException {
    TextFieldType textFieldType=new TextFieldType();
    textFieldType.setName("text");
    textFieldType.setFielddata(true);
    textFieldType.setIndexAnalyzer(new NamedAnalyzer("my_analyzer",AnalyzerScope.GLOBAL,new StandardAnalyzer()));
    IndexWriterConfig indexWriterConfig=newIndexWriterConfig();
    indexWriterConfig.setMaxBufferedDocs(100);
    indexWriterConfig.setRAMBufferSizeMB(100);
    try (Directory dir=newDirectory();IndexWriter w=new IndexWriter(dir,indexWriterConfig)){
      addMixedTextDocs(textFieldType,w);
      SignificantTermsAggregationBuilder sigAgg=new SignificantTermsAggregationBuilder("sig_text",null).field("unmapped_field");
      sigAgg.executionHint(randomExecutionHint());
      try (IndexReader reader=DirectoryReader.open(w)){
        assertEquals("test expects a single segment",1,reader.leaves().size());
        IndexSearcher searcher=new IndexSearcher(reader);
        SignificantTerms terms=searchAndReduce(searcher,new TermQuery(new Term("text","odd")),sigAgg,textFieldType);
        assertEquals(0,terms.getBuckets().size());
        assertNull(terms.getBucketByKey("even"));
        assertNull(terms.getBucketByKey("common"));
        assertNull(terms.getBucketByKey("odd"));
      }
     }
   }
  public void testFieldAlias() throws IOException {
    TextFieldType textFieldType=new TextFieldType();
    textFieldType.setName("text");
    textFieldType.setFielddata(true);
    textFieldType.setIndexAnalyzer(new NamedAnalyzer("my_analyzer",AnalyzerScope.GLOBAL,new StandardAnalyzer()));
    IndexWriterConfig indexWriterConfig=newIndexWriterConfig();
    indexWriterConfig.setMaxBufferedDocs(100);
    indexWriterConfig.setRAMBufferSizeMB(100);
    try (Directory dir=newDirectory();IndexWriter w=new IndexWriter(dir,indexWriterConfig)){
      addMixedTextDocs(textFieldType,w);
      SignificantTermsAggregationBuilder agg=significantTerms("sig_text").field("text");
      SignificantTermsAggregationBuilder aliasAgg=significantTerms("sig_text").field("text-alias");
      String executionHint=randomExecutionHint();
      agg.executionHint(executionHint);
      aliasAgg.executionHint(executionHint);
      if (randomBoolean()) {
        QueryBuilder backgroundFilter=QueryBuilders.termsQuery("text","common");
        agg.backgroundFilter(backgroundFilter);
        aliasAgg.backgroundFilter(backgroundFilter);
      }
      try (IndexReader reader=DirectoryReader.open(w)){
        assertEquals("test expects a single segment",1,reader.leaves().size());
        IndexSearcher searcher=new IndexSearcher(reader);
        SignificantTerms evenTerms=searchAndReduce(searcher,new TermQuery(new Term("text","even")),agg,textFieldType);
        SignificantTerms aliasEvenTerms=searchAndReduce(searcher,new TermQuery(new Term("text","even")),aliasAgg,textFieldType);
        assertFalse(evenTerms.getBuckets().isEmpty());
        assertEquals(evenTerms,aliasEvenTerms);
        SignificantTerms oddTerms=searchAndReduce(searcher,new TermQuery(new Term("text","odd")),agg,textFieldType);
        SignificantTerms aliasOddTerms=searchAndReduce(searcher,new TermQuery(new Term("text","odd")),aliasAgg,textFieldType);
        assertFalse(oddTerms.getBuckets().isEmpty());
        assertEquals(oddTerms,aliasOddTerms);
      }
     }
   }
  private void addMixedTextDocs(  TextFieldType textFieldType,  IndexWriter w) throws IOException {
    for (int i=0; i < 10; i++) {
      Document doc=new Document();
      StringBuilder text=new StringBuilder("common ");
      if (i % 2 == 0) {
        text.append("odd ");
      }
 else {
        text.append("even ");
      }
      doc.add(new Field("text",text.toString(),textFieldType));
      String json="{ \"text\" : \"" + text.toString() + "\" }";
      doc.add(new StoredField("_source",new BytesRef(json)));
      w.addDocument(doc);
    }
  }
  private void addFields(  Document doc,  List<Field> createFields){
    for (    Field field : createFields) {
      doc.add(field);
    }
  }
  public String randomExecutionHint(){
    return randomBoolean() ? null : randomFrom(ExecutionMode.values()).toString();
  }
}
