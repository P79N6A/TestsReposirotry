class SyncRollupIndexer extends RollupIndexer {
  private final IndexSearcher searcher;
  private final MappedFieldType[] fieldTypes;
  private final MappedFieldType timestampField;
  private final List<IndexRequest> documents=new ArrayList<>();
  private final CountDownLatch latch=new CountDownLatch(1);
  private Exception exc;
  SyncRollupIndexer(  Executor executor,  RollupJob job,  IndexSearcher searcher,  MappedFieldType[] fieldTypes,  MappedFieldType timestampField){
    super(executor,job,new AtomicReference<>(IndexerState.STARTED),null,new AtomicBoolean(newIDScheme));
    this.searcher=searcher;
    this.fieldTypes=fieldTypes;
    this.timestampField=timestampField;
  }
  @Override protected void onFinish(){
    latch.countDown();
  }
  @Override protected void onAbort(){
    assert false : "onAbort should not be called";
  }
  @Override protected void onFailure(  Exception e){
    latch.countDown();
    exc=e;
  }
  @Override protected void doNextSearch(  SearchRequest request,  ActionListener<SearchResponse> listener){
    assertNotNull(request.source());
    assertThat(request.source().query(),instanceOf(RangeQueryBuilder.class));
    RangeQueryBuilder range=(RangeQueryBuilder)request.source().query();
    final DateTimeZone timeZone=range.timeZone() != null ? DateTimeZone.forID(range.timeZone()) : null;
    Query query=timestampField.rangeQuery(range.from(),range.to(),range.includeLower(),range.includeUpper(),null,timeZone,Joda.forPattern(range.format()).toDateMathParser(),queryShardContext);
    assertThat(request.source().aggregations().getAggregatorFactories().size(),equalTo(1));
    assertThat(request.source().aggregations().getAggregatorFactories().iterator().next(),instanceOf(CompositeAggregationBuilder.class));
    CompositeAggregationBuilder aggBuilder=(CompositeAggregationBuilder)request.source().aggregations().getAggregatorFactories().iterator().next();
    CompositeAggregation result=null;
    try {
      result=search(searcher,query,aggBuilder,fieldTypes);
    }
 catch (    IOException e) {
      listener.onFailure(e);
    }
    SearchResponseSections sections=new SearchResponseSections(null,new Aggregations(Collections.singletonList(result)),null,false,null,null,1);
    SearchResponse response=new SearchResponse(sections,null,1,1,0,0,ShardSearchFailure.EMPTY_ARRAY,null);
    listener.onResponse(response);
  }
  @Override protected void doNextBulk(  BulkRequest request,  ActionListener<BulkResponse> listener){
    for (    DocWriteRequest<?> indexRequest : request.requests()) {
      if (indexRequest.getClass() == IndexRequest.class) {
        documents.add(((IndexRequest)indexRequest));
      }
 else {
        listener.onFailure(new IllegalStateException("invalid bulk request"));
      }
    }
    listener.onResponse(new BulkResponse(new BulkItemResponse[0],0));
  }
  @Override protected void doSaveState(  IndexerState state,  Map<String,Object> position,  Runnable next){
    assert state == IndexerState.INDEXING || state == IndexerState.STARTED || state == IndexerState.STOPPED;
    next.run();
  }
  public List<IndexRequest> triggerAndWaitForCompletion(  long now) throws Exception {
    assertTrue(maybeTriggerAsyncJob(now));
    try {
      latch.await(10,TimeUnit.SECONDS);
    }
 catch (    InterruptedException e) {
      throw new AssertionError(e);
    }
    if (exc != null) {
      throw exc;
    }
    assertThat(latch.getCount(),equalTo(0L));
    return documents;
  }
}
