public class SparkProducerTest extends CamelTestSupport {
  static JavaSparkContext sparkContext=createLocalSparkContext();
  static boolean shouldRunHive=parseBoolean(System.getenv("CAMEL_SPARK_HIVE_TESTS"));
  static HiveContext hiveContext;
  String sparkUri="spark:rdd?rdd=#testFileRdd";
  String sparkDataFrameUri="spark:dataframe?dataFrame=#jsonCars";
  String sparkHiveUri="spark:hive";
  int numberOfLinesInTestFile=19;
  @BeforeClass public static void beforeClass(){
    if (shouldRunHive) {
      hiveContext=new HiveContext(sparkContext.sc());
    }
  }
  @Override protected JndiRegistry createRegistry() throws Exception {
    JndiRegistry registry=super.createRegistry();
    registry.bind("testFileRdd",sparkContext.textFile("src/test/resources/testrdd.txt"));
    if (shouldRunHive) {
      registry.bind("hiveContext",hiveContext);
      Dataset<Row> jsonCars=hiveContext.read().json("src/test/resources/cars.json");
      jsonCars.registerTempTable("cars");
      registry.bind("jsonCars",jsonCars);
    }
    registry.bind("countLinesTransformation",new org.apache.camel.component.spark.RddCallback(){
      @Override public Object onRdd(      JavaRDDLike rdd,      Object... payloads){
        return rdd.count();
      }
    }
);
    return registry;
  }
  @Test public void shouldExecuteRddCallback(){
    long linesCount=template.requestBodyAndHeader(sparkUri,null,SPARK_RDD_CALLBACK_HEADER,new org.apache.camel.component.spark.RddCallback(){
      @Override public Long onRdd(      JavaRDDLike rdd,      Object... payloads){
        return rdd.count();
      }
    }
,Long.class);
    Truth.assertThat(linesCount).isEqualTo(numberOfLinesInTestFile);
  }
  @Test public void shouldExecuteRddCallbackWithSinglePayload(){
    long linesCount=template.requestBodyAndHeader(sparkUri,10,SPARK_RDD_CALLBACK_HEADER,new org.apache.camel.component.spark.RddCallback(){
      @Override public Long onRdd(      JavaRDDLike rdd,      Object... payloads){
        return rdd.count() * (int)payloads[0];
      }
    }
,Long.class);
    Truth.assertThat(linesCount).isEqualTo(numberOfLinesInTestFile * 10);
  }
  @Test public void shouldExecuteRddCallbackWithPayloads(){
    long linesCount=template.requestBodyAndHeader(sparkUri,asList(10,10),SPARK_RDD_CALLBACK_HEADER,new org.apache.camel.component.spark.RddCallback(){
      @Override public Long onRdd(      JavaRDDLike rdd,      Object... payloads){
        return rdd.count() * (int)payloads[0] * (int)payloads[1];
      }
    }
,Long.class);
    Truth.assertThat(linesCount).isEqualTo(numberOfLinesInTestFile * 10 * 10);
  }
  @Test public void shouldExecuteRddCallbackWithTypedPayloads(){
    ConvertingRddCallback rddCallback=new ConvertingRddCallback<Long>(context,int.class,int.class){
      @Override public Long doOnRdd(      JavaRDDLike rdd,      Object... payloads){
        return rdd.count() * (int)payloads[0] * (int)payloads[1];
      }
    }
;
    long linesCount=template.requestBodyAndHeader(sparkUri,asList("10","10"),SPARK_RDD_CALLBACK_HEADER,rddCallback,Long.class);
    Truth.assertThat(linesCount).isEqualTo(1900);
  }
  @Test public void shouldUseTransformationFromRegistry(){
    long linesCount=template.requestBody(sparkUri + "&rddCallback=#countLinesTransformation",null,Long.class);
    Truth.assertThat(linesCount).isGreaterThan(0L);
  }
  @Test public void shouldExecuteVoidCallback() throws IOException {
    final File output=File.createTempFile("camel","spark");
    output.delete();
    template.sendBodyAndHeader(sparkUri,null,SPARK_RDD_CALLBACK_HEADER,new VoidRddCallback(){
      @Override public void doOnRdd(      JavaRDDLike rdd,      Object... payloads){
        rdd.saveAsTextFile(output.getAbsolutePath());
      }
    }
);
    Truth.assertThat(output.length()).isGreaterThan(0L);
  }
  @Test public void shouldExecuteAnnotatedCallback(){
    org.apache.camel.component.spark.RddCallback rddCallback=annotatedRddCallback(new Object(){
      @RddCallback long countLines(      JavaRDD<String> textFile){
        return textFile.count();
      }
    }
);
    long pomLinesCount=template.requestBodyAndHeader(sparkUri,null,SPARK_RDD_CALLBACK_HEADER,rddCallback,Long.class);
    Truth.assertThat(pomLinesCount).isEqualTo(19);
  }
  @Test public void shouldExecuteAnnotatedVoidCallback() throws IOException {
    final File output=File.createTempFile("camel","spark");
    output.delete();
    org.apache.camel.component.spark.RddCallback rddCallback=annotatedRddCallback(new Object(){
      @RddCallback void countLines(      JavaRDD<String> textFile){
        textFile.saveAsTextFile(output.getAbsolutePath());
      }
    }
);
    template.sendBodyAndHeader(sparkUri,null,SPARK_RDD_CALLBACK_HEADER,rddCallback);
    Truth.assertThat(output.length()).isGreaterThan(0L);
  }
  @Test public void shouldExecuteAnnotatedCallbackWithParameters(){
    org.apache.camel.component.spark.RddCallback rddCallback=annotatedRddCallback(new Object(){
      @RddCallback long countLines(      JavaRDD<String> textFile,      int first,      int second){
        return textFile.count() * first * second;
      }
    }
);
    long pomLinesCount=template.requestBodyAndHeader(sparkUri,asList(10,10),SPARK_RDD_CALLBACK_HEADER,rddCallback,Long.class);
    Truth.assertThat(pomLinesCount).isEqualTo(numberOfLinesInTestFile * 10 * 10);
  }
  @Test public void shouldExecuteAnnotatedCallbackWithConversions(){
    org.apache.camel.component.spark.RddCallback rddCallback=annotatedRddCallback(new Object(){
      @RddCallback long countLines(      JavaRDD<String> textFile,      int first,      int second){
        return textFile.count() * first * second;
      }
    }
,context);
    long pomLinesCount=template.requestBodyAndHeader(sparkUri,asList(10,"10"),SPARK_RDD_CALLBACK_HEADER,rddCallback,Long.class);
    Truth.assertThat(pomLinesCount).isEqualTo(numberOfLinesInTestFile * 10 * 10);
  }
  @Test public void shouldExecuteHiveQuery(){
    assumeTrue(shouldRunHive);
    List<Row> cars=template.requestBody(sparkHiveUri,"SELECT * FROM cars",List.class);
    Truth.assertThat(cars.get(0).getString(1)).isEqualTo("X-trail");
  }
  @Test public void shouldExecuteHiveCountQuery(){
    assumeTrue(shouldRunHive);
    long carsCount=template.requestBody(sparkHiveUri + "?collect=false","SELECT * FROM cars",Long.class);
    Truth.assertThat(carsCount).isEqualTo(2);
  }
  @Test public void shouldCountFrame(){
    assumeTrue(shouldRunHive);
    DataFrameCallback callback=new DataFrameCallback<Long>(){
      @Override public Long onDataFrame(      Dataset<Row> dataFrame,      Object... payloads){
        return dataFrame.count();
      }
    }
;
    long tablesCount=template.requestBodyAndHeader(sparkDataFrameUri,null,SPARK_DATAFRAME_CALLBACK_HEADER,callback,Long.class);
    Truth.assertThat(tablesCount).isEqualTo(2);
  }
  @Test public void shouldExecuteConditionalFrameCount(){
    assumeTrue(shouldRunHive);
    DataFrameCallback callback=new DataFrameCallback<Long>(){
      @Override public Long onDataFrame(      Dataset<Row> dataFrame,      Object... payloads){
        String model=(String)payloads[0];
        return dataFrame.where(dataFrame.col("model").eqNullSafe(model)).count();
      }
    }
;
    long tablesCount=template.requestBodyAndHeader(sparkDataFrameUri,"Micra",SPARK_DATAFRAME_CALLBACK_HEADER,callback,Long.class);
    Truth.assertThat(tablesCount).isEqualTo(1);
  }
}
