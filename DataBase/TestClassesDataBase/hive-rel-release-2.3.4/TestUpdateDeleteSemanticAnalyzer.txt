public class TestUpdateDeleteSemanticAnalyzer {
  static final private Logger LOG=LoggerFactory.getLogger(TestUpdateDeleteSemanticAnalyzer.class.getName());
  private QueryState queryState;
  private HiveConf conf;
  private Hive db;
  @Test public void testInsertSelect() throws Exception {
    try {
      ReturnInfo rc=parseAndAnalyze("insert into table T select a, b from U","testInsertSelect");
      LOG.info(explain((SemanticAnalyzer)rc.sem,rc.plan));
    }
  finally {
      cleanupTables();
    }
  }
  @Test public void testDeleteAllNonPartitioned() throws Exception {
    try {
      ReturnInfo rc=parseAndAnalyze("delete from T","testDeleteAllNonPartitioned");
      LOG.info(explain((SemanticAnalyzer)rc.sem,rc.plan));
    }
  finally {
      cleanupTables();
    }
  }
  @Test public void testDeleteWhereNoPartition() throws Exception {
    try {
      ReturnInfo rc=parseAndAnalyze("delete from T where a > 5","testDeleteWhereNoPartition");
      LOG.info(explain((SemanticAnalyzer)rc.sem,rc.plan));
    }
  finally {
      cleanupTables();
    }
  }
  @Test public void testDeleteAllPartitioned() throws Exception {
    try {
      ReturnInfo rc=parseAndAnalyze("delete from U","testDeleteAllPartitioned");
      LOG.info(explain((SemanticAnalyzer)rc.sem,rc.plan));
    }
  finally {
      cleanupTables();
    }
  }
  @Test public void testDeleteAllWherePartitioned() throws Exception {
    try {
      ReturnInfo rc=parseAndAnalyze("delete from U where a > 5","testDeleteAllWherePartitioned");
      LOG.info(explain((SemanticAnalyzer)rc.sem,rc.plan));
    }
  finally {
      cleanupTables();
    }
  }
  @Test public void testDeleteOnePartition() throws Exception {
    try {
      ReturnInfo rc=parseAndAnalyze("delete from U where ds = 'today'","testDeleteFromPartitionOnly");
      LOG.info(explain((SemanticAnalyzer)rc.sem,rc.plan));
    }
  finally {
      cleanupTables();
    }
  }
  @Test public void testDeleteOnePartitionWhere() throws Exception {
    try {
      ReturnInfo rc=parseAndAnalyze("delete from U where ds = 'today' and a > 5","testDeletePartitionWhere");
      LOG.info(explain((SemanticAnalyzer)rc.sem,rc.plan));
    }
  finally {
      cleanupTables();
    }
  }
  @Test public void testUpdateAllNonPartitioned() throws Exception {
    try {
      ReturnInfo rc=parseAndAnalyze("update T set b = 5","testUpdateAllNonPartitioned");
      LOG.info(explain((SemanticAnalyzer)rc.sem,rc.plan));
    }
  finally {
      cleanupTables();
    }
  }
  @Test public void testUpdateAllNonPartitionedWhere() throws Exception {
    try {
      ReturnInfo rc=parseAndAnalyze("update T set b = 5 where b > 5","testUpdateAllNonPartitionedWhere");
      LOG.info(explain((SemanticAnalyzer)rc.sem,rc.plan));
    }
  finally {
      cleanupTables();
    }
  }
  @Test public void testUpdateAllPartitioned() throws Exception {
    try {
      ReturnInfo rc=parseAndAnalyze("update U set b = 5","testUpdateAllPartitioned");
      LOG.info(explain((SemanticAnalyzer)rc.sem,rc.plan));
    }
  finally {
      cleanupTables();
    }
  }
  @Test public void testUpdateAllPartitionedWhere() throws Exception {
    try {
      ReturnInfo rc=parseAndAnalyze("update U set b = 5 where b > 5","testUpdateAllPartitionedWhere");
      LOG.info(explain((SemanticAnalyzer)rc.sem,rc.plan));
    }
  finally {
      cleanupTables();
    }
  }
  @Test public void testUpdateOnePartition() throws Exception {
    try {
      ReturnInfo rc=parseAndAnalyze("update U set b = 5 where ds = 'today'","testUpdateOnePartition");
      LOG.info(explain((SemanticAnalyzer)rc.sem,rc.plan));
    }
  finally {
      cleanupTables();
    }
  }
  @Test public void testUpdateOnePartitionWhere() throws Exception {
    try {
      ReturnInfo rc=parseAndAnalyze("update U set b = 5 where ds = 'today' and b > 5","testUpdateOnePartitionWhere");
      LOG.info(explain((SemanticAnalyzer)rc.sem,rc.plan));
    }
  finally {
      cleanupTables();
    }
  }
  @Test public void testInsertValues() throws Exception {
    try {
      ReturnInfo rc=parseAndAnalyze("insert into table T values ('abc', 3), ('ghi', null)","testInsertValues");
      LOG.info(explain((SemanticAnalyzer)rc.sem,rc.plan));
    }
  finally {
      cleanupTables();
    }
  }
  @Test public void testInsertValuesPartitioned() throws Exception {
    try {
      ReturnInfo rc=parseAndAnalyze("insert into table U partition (ds) values " + "('abc', 3, 'today'), ('ghi', 5, 'tomorrow')","testInsertValuesPartitioned");
      LOG.info(explain((SemanticAnalyzer)rc.sem,rc.plan));
    }
  finally {
      cleanupTables();
    }
  }
  @Before public void setup(){
    queryState=new QueryState(null);
    conf=queryState.getConf();
    conf.setVar(HiveConf.ConfVars.HIVE_AUTHORIZATION_MANAGER,"org.apache.hadoop.hive.ql.security.authorization.plugin.sqlstd.SQLStdHiveAuthorizerFactory");
    conf.setVar(HiveConf.ConfVars.DYNAMICPARTITIONINGMODE,"nonstrict");
    conf.setVar(HiveConf.ConfVars.HIVEMAPREDMODE,"nonstrict");
    conf.setVar(HiveConf.ConfVars.HIVE_TXN_MANAGER,"org.apache.hadoop.hive.ql.lockmgr.DbTxnManager");
  }
  public void cleanupTables() throws HiveException {
    if (db != null) {
      db.dropTable("T");
      db.dropTable("U");
    }
  }
private class ReturnInfo {
    BaseSemanticAnalyzer sem;
    QueryPlan plan;
    ReturnInfo(    BaseSemanticAnalyzer s,    QueryPlan p){
      sem=s;
      plan=p;
    }
  }
  private ReturnInfo parseAndAnalyze(  String query,  String testName) throws IOException, ParseException, HiveException {
    SessionState.start(conf);
    Context ctx=new Context(conf);
    ctx.setCmd(query);
    ctx.setHDFSCleanup(true);
    ASTNode tree=ParseUtils.parse(query,ctx);
    BaseSemanticAnalyzer sem=SemanticAnalyzerFactory.get(queryState,tree);
    SessionState.get().initTxnMgr(conf);
    db=sem.getDb();
    Map<String,String> params=new HashMap<String,String>(1);
    params.put(hive_metastoreConstants.TABLE_IS_TRANSACTIONAL,"true");
    db.createTable("T",Arrays.asList("a","b"),null,OrcInputFormat.class,OrcOutputFormat.class,2,Arrays.asList("a"),params);
    db.createTable("U",Arrays.asList("a","b"),Arrays.asList("ds"),OrcInputFormat.class,OrcOutputFormat.class,2,Arrays.asList("a"),params);
    Table u=db.getTable("U");
    Map<String,String> partVals=new HashMap<String,String>(2);
    partVals.put("ds","yesterday");
    db.createPartition(u,partVals);
    partVals.clear();
    partVals.put("ds","today");
    db.createPartition(u,partVals);
    sem.analyze(tree,ctx);
    sem.validate();
    QueryPlan plan=new QueryPlan(query,sem,0L,testName,null,null);
    return new ReturnInfo(sem,plan);
  }
  private String explain(  SemanticAnalyzer sem,  QueryPlan plan) throws IOException {
    FileSystem fs=FileSystem.get(conf);
    File f=File.createTempFile("TestSemanticAnalyzer","explain");
    Path tmp=new Path(f.getPath());
    fs.create(tmp);
    fs.deleteOnExit(tmp);
    ExplainConfiguration config=new ExplainConfiguration();
    config.setExtended(true);
    ExplainWork work=new ExplainWork(tmp,sem.getParseContext(),sem.getRootTasks(),sem.getFetchTask(),sem,config,null);
    ExplainTask task=new ExplainTask();
    task.setWork(work);
    task.initialize(queryState,plan,null,null);
    task.execute(null);
    FSDataInputStream in=fs.open(tmp);
    StringBuilder builder=new StringBuilder();
    final int bufSz=4096;
    byte[] buf=new byte[bufSz];
    long pos=0L;
    while (true) {
      int bytesRead=in.read(pos,buf,0,bufSz);
      if (bytesRead > 0) {
        pos+=bytesRead;
        builder.append(new String(buf,0,bytesRead));
      }
 else {
        in.close();
        break;
      }
    }
    return builder.toString().replaceAll("pfile:/.*\n","pfile:MASKED-OUT\n").replaceAll("location file:/.*\n","location file:MASKED-OUT\n").replaceAll("file:/.*\n","file:MASKED-OUT\n").replaceAll("transient_lastDdlTime.*\n","transient_lastDdlTime MASKED-OUT\n");
  }
}
