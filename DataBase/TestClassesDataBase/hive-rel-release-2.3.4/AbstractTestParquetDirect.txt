public abstract class AbstractTestParquetDirect {
  public static FileSystem localFS=null;
  @BeforeClass public static void initializeFS() throws IOException {
    localFS=FileSystem.getLocal(new Configuration());
  }
  @Rule public final TemporaryFolder tempDir=new TemporaryFolder();
public interface DirectWriter {
    public void write(    RecordConsumer consumer);
  }
public static class DirectWriteSupport extends WriteSupport<Void> {
    private RecordConsumer recordConsumer;
    private final MessageType type;
    private final DirectWriter writer;
    private final Map<String,String> metadata;
    private DirectWriteSupport(    MessageType type,    DirectWriter writer,    Map<String,String> metadata){
      this.type=type;
      this.writer=writer;
      this.metadata=metadata;
    }
    @Override public WriteContext init(    Configuration configuration){
      return new WriteContext(type,metadata);
    }
    @Override public void prepareForWrite(    RecordConsumer recordConsumer){
      this.recordConsumer=recordConsumer;
    }
    @Override public void write(    Void record){
      writer.write(recordConsumer);
    }
  }
  public Path writeDirect(  String name,  MessageType type,  DirectWriter writer) throws IOException {
    File temp=tempDir.newFile(name + ".parquet");
    temp.deleteOnExit();
    temp.delete();
    Path path=new Path(temp.getPath());
    ParquetWriter<Void> parquetWriter=new ParquetWriter<Void>(path,new DirectWriteSupport(type,writer,new HashMap<String,String>()));
    parquetWriter.write(null);
    parquetWriter.close();
    return path;
  }
  public static ArrayWritable record(  Writable... fields){
    return new ArrayWritable(Writable.class,fields);
  }
  public static ArrayWritable list(  Writable... elements){
    return new ArrayWritable(ArrayWritable.class,new ArrayWritable[]{new ArrayWritable(Writable.class,elements)});
  }
  public static String toString(  ArrayWritable arrayWritable){
    Writable[] writables=arrayWritable.get();
    String[] strings=new String[writables.length];
    for (int i=0; i < writables.length; i+=1) {
      if (writables[i] instanceof ArrayWritable) {
        strings[i]=toString((ArrayWritable)writables[i]);
      }
 else {
        strings[i]=String.valueOf(writables[i]);
      }
    }
    return Arrays.toString(strings);
  }
  public static void assertEquals(  String message,  ArrayWritable expected,  ArrayWritable actual){
    Assert.assertEquals(message,toString(expected),toString(actual));
  }
  public static List<ArrayWritable> read(  Path parquetFile) throws IOException {
    List<ArrayWritable> records=new ArrayList<ArrayWritable>();
    RecordReader<NullWritable,ArrayWritable> reader=new MapredParquetInputFormat().getRecordReader(new FileSplit(parquetFile,0,fileLength(parquetFile),(String[])null),new JobConf(),null);
    NullWritable alwaysNull=reader.createKey();
    ArrayWritable record=reader.createValue();
    while (reader.next(alwaysNull,record)) {
      records.add(record);
      record=reader.createValue();
    }
    return records;
  }
  public static long fileLength(  Path localFile) throws IOException {
    return localFS.getFileStatus(localFile).getLen();
  }
  private static final Joiner COMMA=Joiner.on(",");
  public void deserialize(  Writable record,  List<String> columnNames,  List<String> columnTypes) throws Exception {
    ParquetHiveSerDe serde=new ParquetHiveSerDe();
    Properties props=new Properties();
    props.setProperty(serdeConstants.LIST_COLUMNS,COMMA.join(columnNames));
    props.setProperty(serdeConstants.LIST_COLUMN_TYPES,COMMA.join(columnTypes));
    serde.initialize(null,props);
    serde.deserialize(record);
  }
}
