public class TestMultiSessionsHS2WithLocalClusterSpark {
  public static final String TEST_TAG="miniHS2.localClusterSpark.tag";
  public static final String TEST_TAG_VALUE="miniHS2.localClusterSpark.value";
  private static final int PARALLEL_NUMBER=3;
public static class LocalClusterSparkSessionHook implements HiveSessionHook {
    @Override public void run(    HiveSessionHookContext sessionHookContext) throws HiveSQLException {
      sessionHookContext.getSessionConf().set(TEST_TAG,TEST_TAG_VALUE);
    }
  }
  private static MiniHS2 miniHS2=null;
  private static HiveConf conf;
  private static Path dataFilePath;
  private static String dbName="sparkTestDb";
  private ThreadLocal<Connection> localConnection=new ThreadLocal<Connection>();
  private ThreadLocal<Statement> localStatement=new ThreadLocal<Statement>();
  private ExecutorService pool=null;
  private static HiveConf createHiveConf(){
    HiveConf conf=new HiveConf();
    conf.set("hive.exec.parallel","true");
    conf.set("hive.execution.engine","spark");
    conf.set("spark.serializer","org.apache.spark.serializer.KryoSerializer");
    conf.set("spark.master","local-cluster[2,2,1024]");
    conf.set("spark.deploy.defaultCores","2");
    return conf;
  }
  @BeforeClass public static void beforeTest() throws Exception {
    Class.forName(MiniHS2.getJdbcDriverName());
    conf=createHiveConf();
    conf.setBoolVar(ConfVars.HIVE_SUPPORT_CONCURRENCY,false);
    String dataFileDir=conf.get("test.data.files").replace('\\','/').replace("c:","");
    dataFilePath=new Path(dataFileDir,"kv1.txt");
    DriverManager.setLoginTimeout(0);
    conf.setBoolVar(ConfVars.HIVE_SUPPORT_CONCURRENCY,false);
    miniHS2=new MiniHS2(conf,MiniClusterType.MR);
    Map<String,String> overlayProps=new HashMap<String,String>();
    overlayProps.put(ConfVars.HIVE_SERVER2_SESSION_HOOK.varname,LocalClusterSparkSessionHook.class.getName());
    miniHS2.start(overlayProps);
    createDb();
  }
  private static void createDb() throws Exception {
    Connection conn=DriverManager.getConnection(miniHS2.getJdbcURL(),System.getProperty("user.name"),"bar");
    Statement stmt2=conn.createStatement();
    stmt2.execute("DROP DATABASE IF EXISTS " + dbName + " CASCADE");
    stmt2.execute("CREATE DATABASE " + dbName);
    stmt2.close();
    conn.close();
  }
  @Before public void setUp() throws Exception {
    pool=Executors.newFixedThreadPool(PARALLEL_NUMBER,new ThreadFactoryBuilder().setDaemon(true).setNameFormat("Test-Thread-%d").build());
    createConnection();
  }
  @After public void tearDown() throws Exception {
    pool.shutdownNow();
    closeConnection();
  }
  private void createConnection() throws Exception {
    Connection connection=DriverManager.getConnection(miniHS2.getJdbcURL(dbName),System.getProperty("user.name"),"bar");
    Statement statement=connection.createStatement();
    localConnection.set(connection);
    localStatement.set(statement);
    statement.execute("USE " + dbName);
  }
  private void closeConnection() throws SQLException {
    if (localStatement.get() != null) {
      localStatement.get().close();
    }
    if (localConnection.get() != null) {
      localConnection.get().close();
    }
  }
  @AfterClass public static void afterTest() throws Exception {
    if (miniHS2 != null && miniHS2.isStarted()) {
      miniHS2.stop();
    }
  }
  /** 
 * Run nonSpark query
 * @throws Exception
 */
  @Test public void testNonSparkQuery() throws Exception {
    String tableName="kvTable1";
    setupTable(tableName);
    Callable<Void> runNonSparkQuery=getNonSparkQueryCallable(tableName);
    runInParallel(runNonSparkQuery);
    dropTable(tableName);
  }
  /** 
 * Run spark query
 * @throws Exception
 */
  @Test public void testSparkQuery() throws Exception {
    String tableName="kvTable2";
    setupTable(tableName);
    Callable<Void> runSparkQuery=getSparkQueryCallable(tableName);
    runInParallel(runSparkQuery);
    dropTable(tableName);
  }
  private void runInParallel(  Callable<Void> runNonSparkQuery) throws InterruptedException, ExecutionException {
    List<Future> futureList=new LinkedList<Future>();
    for (int i=0; i < PARALLEL_NUMBER; i++) {
      Future future=pool.submit(runNonSparkQuery);
      futureList.add(future);
    }
    for (    Future future : futureList) {
      future.get();
    }
  }
  private Callable<Void> getNonSparkQueryCallable(  final String tableName){
    return new Callable<Void>(){
      @Override public Void call() throws Exception {
        String resultVal="val_238";
        String queryStr="SELECT * FROM " + tableName;
        testKvQuery(queryStr,resultVal);
        return null;
      }
    }
;
  }
  private Callable<Void> getSparkQueryCallable(  final String tableName){
    return new Callable<Void>(){
      @Override public Void call() throws Exception {
        String resultVal="val_238";
        String queryStr="SELECT * FROM " + tableName + " where value = '"+ resultVal+ "'";
        testKvQuery(queryStr,resultVal);
        return null;
      }
    }
;
  }
  private void testKvQuery(  String queryStr,  String resultVal) throws Exception {
    createConnection();
    verifyResult(queryStr,resultVal,2);
    closeConnection();
  }
  private void setupTable(  String tableName) throws SQLException {
    Statement statement=localStatement.get();
    statement.execute("CREATE TABLE " + tableName + " (under_col INT COMMENT 'the under column', value STRING)"+ " COMMENT ' test table'");
    statement.execute("LOAD DATA LOCAL INPATH '" + dataFilePath.toString() + "' INTO TABLE "+ tableName);
  }
  private void dropTable(  String tableName) throws SQLException {
    localStatement.get().execute("DROP TABLE " + tableName);
  }
  private void verifyResult(  String queryStr,  String expString,  int colPos) throws SQLException {
    ResultSet res=localStatement.get().executeQuery(queryStr);
    assertTrue(res.next());
    assertEquals(expString,res.getString(colPos));
    res.close();
  }
}
