public class TestMapredParquetOutputFormat {
  @Test public void testConstructor(){
    new MapredParquetOutputFormat();
  }
  @SuppressWarnings("unchecked") @Test public void testConstructorWithFormat(){
    new MapredParquetOutputFormat((ParquetOutputFormat<ParquetHiveRecord>)mock(ParquetOutputFormat.class));
  }
  @Test public void testGetRecordWriterThrowsException(){
    try {
      new MapredParquetOutputFormat().getRecordWriter(null,null,null,null);
      fail("should throw runtime exception.");
    }
 catch (    Exception e) {
      assertEquals("Should never be used",e.getMessage());
    }
  }
  @SuppressWarnings("unchecked") @Test public void testGetHiveRecordWriter() throws IOException {
    Properties tableProps=new Properties();
    tableProps.setProperty("columns","foo,bar");
    tableProps.setProperty("columns.types","int:int");
    final Progressable mockProgress=mock(Progressable.class);
    final ParquetOutputFormat<ParquetHiveRecord> outputFormat=(ParquetOutputFormat<ParquetHiveRecord>)mock(ParquetOutputFormat.class);
    JobConf jobConf=new JobConf();
    try {
      new MapredParquetOutputFormat(outputFormat){
        @Override protected ParquetRecordWriterWrapper getParquerRecordWriterWrapper(        ParquetOutputFormat<ParquetHiveRecord> realOutputFormat,        JobConf jobConf,        String finalOutPath,        Progressable progress,        Properties tableProperties) throws IOException {
          assertEquals(outputFormat,realOutputFormat);
          assertNotNull(jobConf.get(DataWritableWriteSupport.PARQUET_HIVE_SCHEMA));
          assertEquals("/foo",finalOutPath.toString());
          assertEquals(mockProgress,progress);
          throw new RuntimeException("passed tests");
        }
      }
.getHiveRecordWriter(jobConf,new Path("/foo"),null,false,tableProps,mockProgress);
      fail("should throw runtime exception.");
    }
 catch (    RuntimeException e) {
      assertEquals("passed tests",e.getMessage());
    }
  }
  @Test(expected=IllegalArgumentException.class) public void testInvalidCompressionTableProperties() throws IOException {
    Properties tableProps=new Properties();
    tableProps.setProperty("parquet.compression","unsupported");
    tableProps.setProperty("columns","foo,bar");
    tableProps.setProperty("columns.types","int:int");
    JobConf jobConf=new JobConf();
    new MapredParquetOutputFormat().getHiveRecordWriter(jobConf,new Path("/foo"),null,false,tableProps,null);
  }
}
