/** 
 * Created by binesh on 6/13/2017. 
 */
public class ShiftVertexTest extends BaseDL4JTest {
  @Test public void testShiftVertexNumParamsTrue(){
    ShiftVertex sv=new ShiftVertex(0.7);
    Assert.assertEquals(0,sv.numParams(true));
  }
  @Test public void testShiftVertexNumParamsFalse(){
    ShiftVertex sv=new ShiftVertex(0.7);
    Assert.assertEquals(0,sv.numParams(false));
  }
  @Test public void testGet(){
    ShiftVertex sv=new ShiftVertex(0.7);
    Assert.assertEquals(0.7,sv.getShiftFactor(),this.epsilon);
  }
  @Test public void testSimple(){
    INDArray input=Nd4j.create(new double[][]{{0.2,0.3,0.5},{0.7,1.1,1.3},{1.7,1.9,2.3},{2.9,3.1,3.7}});
    double sf=4.1;
    ComputationGraphConfiguration cgc=new NeuralNetConfiguration.Builder().graphBuilder().addInputs("input").addLayer("denselayer",new DenseLayer.Builder().nIn(input.columns()).nOut(1).activation(Activation.IDENTITY).build(),"input").addLayer("identityinputactivation",new ActivationLayer.Builder().activation(Activation.IDENTITY).build(),"input").addVertex("shiftvertex",new ShiftVertex(sf),"identityinputactivation").addLayer("identityshiftvertex",new ActivationLayer.Builder().activation(Activation.IDENTITY).build(),"shiftvertex").setOutputs("identityshiftvertex","denselayer").build();
    ComputationGraph cg=new ComputationGraph(cgc);
    cg.init();
    INDArray output=cg.output(true,input)[0];
    INDArray target=Nd4j.zeros(input.shape());
    target.addi(input);
    target.addi(sf);
    INDArray squared=output.sub(target);
    double rms=squared.mul(squared).sumNumber().doubleValue();
    Assert.assertEquals(0.0,rms,this.epsilon);
  }
  @Test public void testComprehensive(){
    BaseActivationFunction a1=new ActivationTanH();
    BaseActivationFunction a2=new ActivationSigmoid();
    INDArray input=Nd4j.create(new double[][]{{0.2,0.3,0.5},{0.7,1.1,1.3},{1.7,1.9,2.3},{2.9,3.1,3.7}});
    double sf=4.1;
    INDArray target=Nd4j.create(new double[][]{{0.05,0.10,0.15,0.20,0.25},{0.30,0.35,0.40,0.45,0.50},{0.55,0.60,0.65,0.70,0.75},{0.80,0.85,0.90,0.95,0.99}});
    ComputationGraphConfiguration cgc=new NeuralNetConfiguration.Builder().weightInit(WeightInit.XAVIER).updater(new Sgd(0.01)).optimizationAlgo(OptimizationAlgorithm.STOCHASTIC_GRADIENT_DESCENT).graphBuilder().addInputs("input").addLayer("denselayer",new DenseLayer.Builder().nIn(input.columns()).nOut(input.columns()).activation(a1).build(),"input").addVertex("shiftvertex",new ShiftVertex(sf),"denselayer").addLayer("output",new OutputLayer.Builder().nIn(input.columns()).nOut(target.columns()).activation(a2).lossFunction(LossFunction.MSE).build(),"shiftvertex").setOutputs("output").build();
    ComputationGraph cg=new ComputationGraph(cgc);
    cg.init();
    cg.setInput(0,input);
    cg.setLabel(0,target);
    cg.computeGradientAndScore();
    double score_dl4j=cg.score();
    Map<String,INDArray> weights=cg.paramTable();
    Gradient g=cg.gradient();
    Map<String,INDArray> gradients=g.gradientForVariable();
    Map<String,INDArray> manual_gradients=new TreeMap<String,INDArray>();
    INDArray W=nullsafe(weights.get("denselayer_W"));
    INDArray b=nullsafe(weights.get("denselayer_b"));
    INDArray V=nullsafe(weights.get("output_W"));
    INDArray c=nullsafe(weights.get("output_b"));
    Map<String,INDArray> manual_weights=new TreeMap<String,INDArray>();
    manual_weights.put("denselayer_W",W);
    manual_weights.put("denselayer_b",b);
    manual_weights.put("output_W",V);
    manual_weights.put("output_b",c);
    int batchsz=(int)input.shape()[0];
    INDArray z=input.mmul(W).add(b.repmat(batchsz,1));
    INDArray a=a1.getActivation(z.dup(),true).add(sf);
    INDArray q=a.mmul(V).add(c.repmat(batchsz,1));
    INDArray o=nullsafe(a2.getActivation(q.dup(),true));
    double score_manual=sum_errors(o,target) / (o.columns() * o.rows());
    INDArray dEdo=Nd4j.zeros(target.shape());
    dEdo.addi(o).subi(target).muli(2);
    dEdo.divi(target.shape()[1]);
    Pair<INDArray,INDArray> derivs2=a2.backprop(q,dEdo);
    INDArray dEdq=derivs2.getFirst();
    INDArray dqdc=Nd4j.ones(1,batchsz);
    INDArray dEdc=dqdc.mmul(dEdq);
    INDArray dEdV=a.transpose().mmul(dEdq);
    INDArray dEda=dEdq.mmul(V.transpose());
    Pair<INDArray,INDArray> derivs1=a1.backprop(z,dEda);
    INDArray dEdz=derivs1.getFirst();
    INDArray dzdb=Nd4j.ones(1,batchsz);
    INDArray dEdb=dzdb.mmul(dEdz);
    INDArray dEdW=input.transpose().mmul(dEdz);
    manual_gradients.put("output_b",dEdc);
    manual_gradients.put("output_W",dEdV);
    manual_gradients.put("denselayer_b",dEdb);
    manual_gradients.put("denselayer_W",dEdW);
    double summse=Math.pow((score_manual - score_dl4j),2);
    int denominator=1;
    for (    Map.Entry<String,INDArray> mesi : gradients.entrySet()) {
      String name=mesi.getKey();
      INDArray dl4j_gradient=nullsafe(mesi.getValue());
      INDArray manual_gradient=nullsafe(manual_gradients.get(name));
      double se=sum_errors(dl4j_gradient,manual_gradient);
      summse+=se;
      denominator+=dl4j_gradient.columns() * dl4j_gradient.rows();
    }
    Assert.assertEquals(0.0,summse / denominator,this.epsilon);
  }
  private static double sum_errors(  INDArray a,  INDArray b){
    INDArray o=a.sub(b);
    return o.mul(o).sumNumber().doubleValue();
  }
  private static <T>T nullsafe(  T obj){
    if (obj == null)     throw new NullPointerException();
    T clean=obj;
    return clean;
  }
  private double epsilon=1e-10;
}
