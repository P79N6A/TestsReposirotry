/** 
 * @author susaneraly
 */
@Slf4j @RunWith(Parameterized.class) public class UnderSamplingPreProcessorTest extends BaseNd4jTest {
  int shortSeq=10000;
  int longSeq=20020;
  int window=5000;
  int minibatchSize=3;
  double targetDist=0.3;
  double tolerancePerc=0.03;
  public UnderSamplingPreProcessorTest(  Nd4jBackend backend){
    super(backend);
  }
  @Test public void allMajority(){
    float[] someTargets=new float[]{0.01f,0.1f,0.5f};
    DataSet d=allMajorityDataSet(false);
    DataSet dToPreProcess;
    for (int i=0; i < someTargets.length; i++) {
      UnderSamplingByMaskingPreProcessor preProcessor=new UnderSamplingByMaskingPreProcessor(someTargets[i],shortSeq / 2);
      dToPreProcess=d.copy();
      preProcessor.preProcess(dToPreProcess);
      assertEquals(Nd4j.zeros(dToPreProcess.getLabelsMaskArray().shape()),dToPreProcess.getLabelsMaskArray());
      preProcessor.donotMaskAllMajorityWindows();
      dToPreProcess=d.copy();
      preProcessor.preProcess(dToPreProcess);
      INDArray percentagesNow=dToPreProcess.getLabelsMaskArray().sum(1).div(shortSeq);
      assertTrue(Nd4j.valueArrayOf(percentagesNow.shape(),1 - someTargets[i]).equalsWithEps(percentagesNow,tolerancePerc));
    }
  }
  @Test public void allMinority(){
    float[] someTargets=new float[]{0.01f,0.1f,0.5f};
    DataSet d=allMinorityDataSet(false);
    DataSet dToPreProcess;
    for (int i=0; i < someTargets.length; i++) {
      UnderSamplingByMaskingPreProcessor preProcessor=new UnderSamplingByMaskingPreProcessor(someTargets[i],shortSeq / 2);
      dToPreProcess=d.copy();
      preProcessor.preProcess(dToPreProcess);
      assertEquals(Nd4j.ones(minibatchSize,shortSeq),dToPreProcess.getLabelsMaskArray());
      preProcessor.overrideMinorityDefault();
      preProcessor.donotMaskAllMajorityWindows();
      dToPreProcess=d.copy();
      preProcessor.preProcess(dToPreProcess);
      INDArray percentagesNow=dToPreProcess.getLabelsMaskArray().sum(1).div(shortSeq);
      assertTrue(Nd4j.valueArrayOf(percentagesNow.shape(),1 - someTargets[i]).equalsWithEps(percentagesNow,tolerancePerc));
    }
  }
  @Test public void mixedDist(){
    UnderSamplingByMaskingPreProcessor preProcessor=new UnderSamplingByMaskingPreProcessor(targetDist,window);
    DataSet dataSet=knownDistVariedDataSet(new float[]{0.1f,0.2f,0.8f},false);
    int loop=2;
    for (int i=0; i < loop; i++) {
      DataSet dataSetToPreProcess=dataSet.copy();
      INDArray labelsBefore=dataSetToPreProcess.getLabels().dup();
      preProcessor.preProcess(dataSetToPreProcess);
      INDArray labels=dataSetToPreProcess.getLabels();
      assertEquals(labelsBefore,labels);
      INDArray masks=dataSetToPreProcess.getLabelsMaskArray();
      INDArray shouldBeAllZeros=masks.get(NDArrayIndex.interval(0,3),NDArrayIndex.interval(shortSeq,longSeq));
      assertEquals(Nd4j.zeros(shouldBeAllZeros.shape()),shouldBeAllZeros);
      for (int j=(int)Math.ceil((double)longSeq / window); j > 0; j--) {
        int maxIndex=min(longSeq,j * window);
        int minIndex=min(0,maxIndex - window);
        INDArray maskWindow=masks.get(NDArrayIndex.all(),NDArrayIndex.interval(minIndex,maxIndex));
        INDArray labelWindow=labels.get(NDArrayIndex.all(),NDArrayIndex.point(0),NDArrayIndex.interval(minIndex,maxIndex));
        INDArray minorityDist=labelWindow.mul(maskWindow).sum(1).div(maskWindow.sum(1));
        if (j < shortSeq / window) {
          assertEquals("Failed on window " + j + " batch 0, loop "+ i,targetDist,minorityDist.getFloat(0,0),tolerancePerc);
          assertEquals("Failed on window " + j + " batch 1, loop "+ i,targetDist,minorityDist.getFloat(1,0),tolerancePerc);
          assertEquals("Failed on window " + j + " batch 2, loop "+ i,0.8,minorityDist.getFloat(2,0),tolerancePerc);
        }
        assertEquals("Failed on window " + j + " batch 3, loop "+ i,targetDist,minorityDist.getFloat(3,0),tolerancePerc);
        assertEquals("Failed on window " + j + " batch 4, loop "+ i,targetDist,minorityDist.getFloat(4,0),tolerancePerc);
        assertEquals("Failed on window " + j + " batch 5, loop "+ i,0.8,minorityDist.getFloat(5,0),tolerancePerc);
      }
    }
  }
  @Test public void mixedDistOneHot(){
    UnderSamplingByMaskingPreProcessor preProcessor=new UnderSamplingByMaskingPreProcessor(targetDist,window);
    preProcessor.overrideMinorityDefault();
    DataSet dataSet=knownDistVariedDataSet(new float[]{0.9f,0.8f,0.2f},true);
    int loop=10;
    for (int i=0; i < loop; i++) {
      DataSet dataSetToPreProcess=dataSet.copy();
      preProcessor.preProcess(dataSetToPreProcess);
      INDArray labels=dataSetToPreProcess.getLabels();
      INDArray masks=dataSetToPreProcess.getLabelsMaskArray();
      INDArray shouldBeAllZeros=masks.get(NDArrayIndex.interval(0,3),NDArrayIndex.interval(shortSeq,longSeq));
      assertEquals(Nd4j.zeros(shouldBeAllZeros.shape()),shouldBeAllZeros);
      for (int j=(int)Math.ceil((double)longSeq / window); j > 0; j--) {
        int maxIndex=min(longSeq,j * window);
        int minIndex=min(0,maxIndex - window);
        INDArray maskWindow=masks.get(NDArrayIndex.all(),NDArrayIndex.interval(minIndex,maxIndex));
        INDArray labelWindow=labels.get(NDArrayIndex.all(),NDArrayIndex.all(),NDArrayIndex.interval(minIndex,maxIndex));
        INDArray minorityClass=labelWindow.get(NDArrayIndex.all(),NDArrayIndex.point(0),NDArrayIndex.all()).mul(maskWindow);
        INDArray majorityClass=labelWindow.get(NDArrayIndex.all(),NDArrayIndex.point(1),NDArrayIndex.all()).mul(maskWindow);
        INDArray minorityDist=minorityClass.sum(1).div(majorityClass.add(minorityClass).sum(1));
        if (j < shortSeq / window) {
          assertEquals("Failed on window " + j + " batch 0, loop "+ i,targetDist,minorityDist.getFloat(0,0),tolerancePerc);
          assertEquals("Failed on window " + j + " batch 1, loop "+ i,targetDist,minorityDist.getFloat(1,0),tolerancePerc);
          assertEquals("Failed on window " + j + " batch 2, loop "+ i,0.8,minorityDist.getFloat(2,0),tolerancePerc);
        }
        assertEquals("Failed on window " + j + " batch 3, loop "+ i,targetDist,minorityDist.getFloat(3,0),tolerancePerc);
        assertEquals("Failed on window " + j + " batch 4, loop "+ i,targetDist,minorityDist.getFloat(4,0),tolerancePerc);
        assertEquals("Failed on window " + j + " batch 5, loop "+ i,0.8,minorityDist.getFloat(5,0),tolerancePerc);
      }
    }
  }
  @Test public void testForMultiDataSet(){
    DataSet dataSetA=knownDistVariedDataSet(new float[]{0.8f,0.1f,0.2f},false);
    DataSet dataSetB=knownDistVariedDataSet(new float[]{0.2f,0.9f,0.8f},true);
    HashMap<Integer,Double> targetDists=new HashMap<>();
    targetDists.put(0,0.5);
    targetDists.put(1,0.3);
    UnderSamplingByMaskingMultiDataSetPreProcessor maskingMultiDataSetPreProcessor=new UnderSamplingByMaskingMultiDataSetPreProcessor(targetDists,window);
    maskingMultiDataSetPreProcessor.overrideMinorityDefault(1);
    MultiDataSet multiDataSet=fromDataSet(dataSetA,dataSetB);
    maskingMultiDataSetPreProcessor.preProcess(multiDataSet);
    INDArray labels;
    INDArray minorityCount;
    INDArray seqCount;
    INDArray minorityDist;
    labels=multiDataSet.getLabels(0).reshape(minibatchSize * 2,longSeq).mul(multiDataSet.getLabelsMaskArray(0));
    minorityCount=labels.sum(1);
    seqCount=multiDataSet.getLabelsMaskArray(0).sum(1);
    minorityDist=minorityCount.div(seqCount);
    assertEquals(minorityDist.getDouble(1,0),0.5,tolerancePerc);
    assertEquals(minorityDist.getDouble(2,0),0.5,tolerancePerc);
    assertEquals(minorityDist.getDouble(4,0),0.5,tolerancePerc);
    assertEquals(minorityDist.getDouble(5,0),0.5,tolerancePerc);
    labels=multiDataSet.getLabels(1).get(NDArrayIndex.all(),NDArrayIndex.point(0),NDArrayIndex.all()).mul(multiDataSet.getLabelsMaskArray(1));
    minorityCount=labels.sum(1);
    seqCount=multiDataSet.getLabelsMaskArray(1).sum(1);
    minorityDist=minorityCount.div(seqCount);
    assertEquals(minorityDist.getDouble(1,0),0.3,tolerancePerc);
    assertEquals(minorityDist.getDouble(2,0),0.3,tolerancePerc);
    assertEquals(minorityDist.getDouble(4,0),0.3,tolerancePerc);
    assertEquals(minorityDist.getDouble(5,0),0.3,tolerancePerc);
  }
  @Override public char ordering(){
    return 'c';
  }
  public MultiDataSet fromDataSet(  DataSet... dataSets){
    INDArray[] featureArr=new INDArray[dataSets.length];
    INDArray[] labelArr=new INDArray[dataSets.length];
    INDArray[] featureMaskArr=new INDArray[dataSets.length];
    INDArray[] labelMaskArr=new INDArray[dataSets.length];
    for (int i=0; i < dataSets.length; i++) {
      featureArr[i]=dataSets[i].getFeatures();
      labelArr[i]=dataSets[i].getLabels();
      featureMaskArr[i]=dataSets[i].getFeaturesMaskArray();
      labelMaskArr[i]=dataSets[i].getLabelsMaskArray();
    }
    return new MultiDataSet(featureArr,labelArr,featureMaskArr,labelMaskArr);
  }
  public DataSet allMinorityDataSet(  boolean twoClass){
    return makeDataSetSameL(minibatchSize,shortSeq,new float[]{1.0f,1.0f,1.0f},twoClass);
  }
  public DataSet allMajorityDataSet(  boolean twoClass){
    return makeDataSetSameL(minibatchSize,shortSeq,new float[]{0.0f,0.0f,0.0f},twoClass);
  }
  public DataSet knownDistVariedDataSet(  float[] dist,  boolean twoClass){
    DataSet batchATimeSteps=makeDataSetSameL(minibatchSize,shortSeq,dist,twoClass);
    DataSet batchBTimeSteps=makeDataSetSameL(minibatchSize,longSeq,dist,twoClass);
    List<DataSet> listofbatches=new ArrayList<>();
    listofbatches.add(batchATimeSteps);
    listofbatches.add(batchBTimeSteps);
    return DataSet.merge(listofbatches);
  }
  public static DataSet makeDataSetSameL(  int batchSize,  int timesteps,  float[] minorityDist,  boolean twoClass){
    INDArray features=Nd4j.rand(1,batchSize * timesteps * 2).reshape(batchSize,2,timesteps);
    INDArray labels;
    if (twoClass) {
      labels=Nd4j.zeros(new int[]{batchSize,2,timesteps});
    }
 else {
      labels=Nd4j.zeros(new int[]{batchSize,1,timesteps});
    }
    for (int i=0; i < batchSize; i++) {
      INDArray l;
      if (twoClass) {
        l=labels.get(NDArrayIndex.point(i),NDArrayIndex.point(1),NDArrayIndex.all());
        Nd4j.getExecutioner().exec(new BernoulliDistribution(l,minorityDist[i]));
        INDArray lOther=labels.get(NDArrayIndex.point(i),NDArrayIndex.point(0),NDArrayIndex.all());
        lOther.assign(Transforms.not(l.dup()));
      }
 else {
        l=labels.get(NDArrayIndex.point(i),NDArrayIndex.point(0),NDArrayIndex.all());
        Nd4j.getExecutioner().exec(new BernoulliDistribution(l,minorityDist[i]));
      }
    }
    return new DataSet(features,labels);
  }
}
