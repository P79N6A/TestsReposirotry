public class TestSequenceRecordReaderFunction extends BaseSparkTest {
  @Rule public TemporaryFolder testDir=new TemporaryFolder();
  @Test public void testSequenceRecordReaderFunctionCSV() throws Exception {
    JavaSparkContext sc=getContext();
    File f=testDir.newFolder();
    new ClassPathResource("datavec-spark/csvsequence/").copyDirectory(f);
    String path=f.getAbsolutePath() + "/*";
    JavaPairRDD<String,PortableDataStream> origData=sc.binaryFiles(path);
    assertEquals(3,origData.count());
    SequenceRecordReaderFunction srrf=new SequenceRecordReaderFunction(new CSVSequenceRecordReader(1,","));
    JavaRDD<List<List<Writable>>> rdd=origData.map(srrf);
    List<List<List<Writable>>> listSpark=rdd.collect();
    assertEquals(3,listSpark.size());
    for (int i=0; i < 3; i++) {
      List<List<Writable>> thisSequence=listSpark.get(i);
      assertEquals(4,thisSequence.size());
      for (      List<Writable> c : thisSequence) {
        assertEquals(3,c.size());
      }
    }
    InputSplit is=new FileSplit(f,new String[]{"txt"},true);
    SequenceRecordReader srr=new CSVSequenceRecordReader(1,",");
    srr.initialize(is);
    List<List<List<Writable>>> list=new ArrayList<>(3);
    while (srr.hasNext()) {
      list.add(srr.sequenceRecord());
    }
    assertEquals(3,list.size());
    boolean[] found=new boolean[3];
    for (int i=0; i < 3; i++) {
      int foundIndex=-1;
      List<List<Writable>> collection=listSpark.get(i);
      for (int j=0; j < 3; j++) {
        if (collection.equals(list.get(j))) {
          if (foundIndex != -1)           fail();
          foundIndex=j;
          if (found[foundIndex])           fail();
          found[foundIndex]=true;
        }
      }
    }
    int count=0;
    for (    boolean b : found)     if (b)     count++;
    assertEquals(3,count);
  }
  @Test public void testSequenceRecordReaderFunctionVideo() throws Exception {
    JavaSparkContext sc=getContext();
    File f=testDir.newFolder();
    new ClassPathResource("datavec-spark/video/").copyDirectory(f);
    String path=f.getAbsolutePath() + "/*";
    JavaPairRDD<String,PortableDataStream> origData=sc.binaryFiles(path);
    assertEquals(4,origData.count());
    SequenceRecordReader sparkSeqReader=new CodecRecordReader();
    Configuration conf=new Configuration();
    conf.set(CodecRecordReader.RAVEL,"true");
    conf.set(CodecRecordReader.START_FRAME,"0");
    conf.set(CodecRecordReader.TOTAL_FRAMES,"25");
    conf.set(CodecRecordReader.ROWS,"64");
    conf.set(CodecRecordReader.COLUMNS,"64");
    Configuration confCopy=new Configuration(conf);
    sparkSeqReader.setConf(conf);
    SequenceRecordReaderFunction srrf=new SequenceRecordReaderFunction(sparkSeqReader);
    JavaRDD<List<List<Writable>>> rdd=origData.map(srrf);
    List<List<List<Writable>>> listSpark=rdd.collect();
    assertEquals(4,listSpark.size());
    for (int i=0; i < 4; i++) {
      List<List<Writable>> thisSequence=listSpark.get(i);
      assertEquals(25,thisSequence.size());
      for (      List<Writable> c : thisSequence) {
        assertEquals(1,c.size());
        assertEquals(64 * 64 * 3,((ArrayWritable)c.iterator().next()).length());
      }
    }
    InputSplit is=new FileSplit(f,new String[]{"mp4"},true);
    SequenceRecordReader srr=new CodecRecordReader();
    srr.initialize(is);
    srr.setConf(confCopy);
    List<List<List<Writable>>> list=new ArrayList<>(4);
    while (srr.hasNext()) {
      list.add(srr.sequenceRecord());
    }
    assertEquals(4,list.size());
    boolean[] found=new boolean[4];
    for (int i=0; i < 4; i++) {
      int foundIndex=-1;
      List<List<Writable>> collection=listSpark.get(i);
      for (int j=0; j < 4; j++) {
        if (collection.equals(list.get(j))) {
          if (foundIndex != -1)           fail();
          foundIndex=j;
          if (found[foundIndex])           fail();
          found[foundIndex]=true;
        }
      }
    }
    int count=0;
    for (    boolean b : found)     if (b)     count++;
    assertEquals(4,count);
  }
}
