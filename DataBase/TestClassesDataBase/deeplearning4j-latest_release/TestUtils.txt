public class TestUtils {
  public static void assertTokenSurfacesEquals(  List<String> expectedSurfaces,  List<? extends TokenBase> actualTokens){
    List<String> actualSurfaces=new ArrayList<>();
    for (    TokenBase token : actualTokens) {
      actualSurfaces.add(token.getSurface());
    }
    assertEquals(expectedSurfaces,actualSurfaces);
  }
  public static void assertCanTokenizeStream(  InputStream untokenizedInput,  TokenizerBase tokenizer) throws IOException {
    BufferedReader untokenizedInputReader=new BufferedReader(new InputStreamReader(untokenizedInput,StandardCharsets.UTF_8));
    String untokenizedLine;
    while ((untokenizedLine=untokenizedInputReader.readLine()) != null) {
      assertCanTokenizeString(untokenizedLine,tokenizer);
    }
    assertTrue(true);
  }
  public static void assertCanTokenizeString(  String input,  TokenizerBase tokenizer){
    List<? extends TokenBase> tokens=tokenizer.tokenize(input);
    if (input.length() > 0) {
      assertFalse(tokens.isEmpty());
    }
 else {
      assertTrue(tokens.isEmpty());
    }
  }
  public static void assertTokenizedStreamEquals(  InputStream tokenizedInput,  InputStream untokenizedInput,  TokenizerBase tokenizer) throws IOException {
    BufferedReader untokenizedInputReader=new BufferedReader(new InputStreamReader(untokenizedInput,StandardCharsets.UTF_8));
    BufferedReader tokenizedInputReader=new BufferedReader(new InputStreamReader(tokenizedInput,StandardCharsets.UTF_8));
    String untokenizedLine;
    while ((untokenizedLine=untokenizedInputReader.readLine()) != null) {
      List<? extends TokenBase> tokens=tokenizer.tokenize(untokenizedLine);
      for (      TokenBase token : tokens) {
        String tokenLine=tokenizedInputReader.readLine();
        assertNotNull(tokenLine);
        String[] parts=tokenLine.split("\\t",2);
        String surface=parts[0];
        String features=parts[1];
        assertEquals(surface,token.getSurface());
        assertEquals(features,token.getAllFeatures());
      }
    }
  }
  public static void assertMultiThreadedTokenizedStreamEquals(  int numThreads,  final int perThreadRuns,  final String tokenizedInputResource,  final String untokenizedInputResource,  final TokenizerBase tokenizer) throws IOException, InterruptedException {
    List<Thread> threads=new ArrayList<>();
    for (int i=0; i < numThreads; i++) {
      Thread thread=new Thread(new Runnable(){
        @Override public void run(){
          for (int run=0; run < perThreadRuns; run++) {
            try {
              InputStream tokenizedInput=getClass().getResourceAsStream(tokenizedInputResource);
              InputStream untokenizedInput=getClass().getResourceAsStream(untokenizedInputResource);
              assertTokenizedStreamEquals(tokenizedInput,untokenizedInput,tokenizer);
              untokenizedInput.close();
              tokenizedInput.close();
            }
 catch (            IOException e) {
              fail(e.getMessage());
            }
          }
        }
      }
);
      threads.add(thread);
      thread.start();
    }
    for (    Thread thread : threads) {
      thread.join();
    }
    assertTrue(true);
  }
  public static void assertEqualTokenFeatureLengths(  String text,  TokenizerBase tokenizer){
    List<? extends TokenBase> tokens=tokenizer.tokenize(text);
    Set<Integer> lengths=new HashSet<>();
    for (    TokenBase token : tokens) {
      lengths.add(token.getAllFeaturesArray().length);
    }
    assertEquals(1,lengths.size());
  }
}
