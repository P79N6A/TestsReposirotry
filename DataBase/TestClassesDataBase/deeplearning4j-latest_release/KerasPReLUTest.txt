/** 
 * @author Max Pumperla
 */
public class KerasPReLUTest {
  private Keras1LayerConfiguration conf1=new Keras1LayerConfiguration();
  private Keras2LayerConfiguration conf2=new Keras2LayerConfiguration();
  private final String INIT_KERAS="glorot_normal";
  private final WeightInit INIT_DL4J=WeightInit.XAVIER;
  @Test public void testPReLULayer() throws Exception {
    Integer keras1=1;
    buildPReLULayer(conf1,keras1);
    Integer keras2=2;
    buildPReLULayer(conf2,keras2);
  }
  private void buildPReLULayer(  KerasLayerConfiguration conf,  Integer kerasVersion) throws Exception {
    Map<String,Object> layerConfig=new HashMap<>();
    layerConfig.put(conf.getLAYER_FIELD_CLASS_NAME(),conf.getLAYER_CLASS_NAME_LEAKY_RELU());
    Map<String,Object> config=new HashMap<>();
    String layerName="prelu";
    config.put(conf.getLAYER_FIELD_NAME(),layerName);
    layerConfig.put(conf.getLAYER_FIELD_CONFIG(),config);
    layerConfig.put(conf.getLAYER_FIELD_KERAS_VERSION(),kerasVersion);
    if (kerasVersion == 1) {
      config.put("alpha_initializer",INIT_KERAS);
    }
 else {
      Map<String,Object> init=new HashMap<>();
      init.put("class_name",conf.getINIT_GLOROT_NORMAL());
      config.put("alpha_initializer",init);
    }
    KerasPReLU kerasPReLU=new KerasPReLU(layerConfig);
    kerasPReLU.getOutputType(InputType.convolutional(5,4,3));
    PReLULayer layer=kerasPReLU.getPReLULayer();
    assertArrayEquals(layer.getInputShape(),new long[]{3,5,4});
    assertEquals(INIT_DL4J,layer.getWeightInit());
    assertEquals(layerName,layer.getLayerName());
  }
}
