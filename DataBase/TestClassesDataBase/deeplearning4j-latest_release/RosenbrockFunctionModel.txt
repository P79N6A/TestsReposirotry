/** 
 * Rosenbrock function: a multi-dimensional 'valley' type function. Has a single local/global minimum of f(x)=0 at x_i=1 for all x_i. Expect gradient-based optimization functions to find global minimum eventually, but optimization may be slow due to nearly flat gradient along valley. Restricted here to the range [-5,5]. This implementation gives infinite cost/score if any parameter is outside of this range. Parameters initialized in range [-4,4] See: http://www.sfu.ca/~ssurjano/rosen.html
 */
private static class RosenbrockFunctionModel extends SimpleOptimizableModel {
  private static final long serialVersionUID=-5129494342531033706L;
  private RosenbrockFunctionModel(  int nDimensions,  NeuralNetConfiguration conf){
    super(initParams(nDimensions),conf);
  }
  private static INDArray initParams(  int nDimensions){
    Random rng=new DefaultRandom(12345L);
    org.nd4j.linalg.api.rng.distribution.Distribution dist=new org.nd4j.linalg.api.rng.distribution.impl.UniformDistribution(rng,-4.0,4.0);
    return dist.sample(new int[]{1,nDimensions});
  }
  @Override public void computeGradientAndScore(  LayerWorkspaceMgr workspaceMgr){
    val nDims=parameters.length();
    INDArray gradient=Nd4j.zeros(nDims);
    double x0=parameters.getDouble(0);
    double x1=parameters.getDouble(1);
    double g0=-400 * x0 * (x1 - x0 * x0) + 2 * (x0 - 1);
    gradient.put(0,0,g0);
    for (int i=1; i < nDims - 1; i++) {
      double xim1=parameters.getDouble(i - 1);
      double xi=parameters.getDouble(i);
      double xip1=parameters.getDouble(i + 1);
      double g=200 * (xi - xim1 * xim1) - 400 * xi * (xip1 - xi * xi) + 2 * (xi - 1);
      gradient.put(0,i,g);
    }
    double xl=parameters.getDouble(nDims - 1);
    double xlm1=parameters.getDouble(nDims - 2);
    double gl=200 * (xl - xlm1 * xlm1);
    gradient.put(0,(int)nDims - 1,gl);
    Gradient g=new DefaultGradient();
    g.gradientForVariable().put("W",gradient);
    this.gradient=g;
    INDArray paramExceeds5=parameters.cond(new Condition(){
      @Override public int condtionNum(){
        return 0;
      }
      @Override public double getValue(){
        return 0;
      }
      @Override public double epsThreshold(){
        return 0;
      }
      @Override public Boolean apply(      Number input){
        return Math.abs(input.doubleValue()) > 5.0;
      }
    }
);
    int nExceeds5=paramExceeds5.sum(Integer.MAX_VALUE).getInt(0);
    if (nExceeds5 > 0)     this.score=Double.POSITIVE_INFINITY;
 else {
      double score=0.0;
      for (int i=0; i < nDims - 1; i++) {
        double xi=parameters.getDouble(i);
        double xi1=parameters.getDouble(i + 1);
        score+=100.0 * Math.pow((xi1 - xi * xi),2.0) + (xi - 1) * (xi - 1);
      }
      this.score=score;
    }
  }
  @Override public long numParams(  boolean backwards){
    return 0;
  }
  @Override public void setParamsViewArray(  INDArray params){
    throw new UnsupportedOperationException("Not supported");
  }
  @Override public void setBackpropGradientsViewArray(  INDArray gradients){
    throw new UnsupportedOperationException();
  }
  @Override public void setCacheMode(  CacheMode mode){
    throw new UnsupportedOperationException();
  }
  @Override public void setListeners(  TrainingListener... listeners){
  }
  @Override public int getIndex(){
    return 0;
  }
  @Override public void setInput(  INDArray input,  LayerWorkspaceMgr workspaceMgr){
  }
  @Override public boolean isPretrainLayer(){
    return false;
  }
  @Override public void clearNoiseWeightParams(){
  }
}
