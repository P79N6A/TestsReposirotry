@Slf4j public class TestGraphLocalExecution {
  @Rule public TemporaryFolder testDir=new TemporaryFolder();
  @Test public void testLocalExecutionDataSources() throws Exception {
    for (int dataApproach=0; dataApproach < 3; dataApproach++) {
      log.info("////////////////// Starting Test: {} ///////////////////",dataApproach);
      ComputationGraphSpace mls=new ComputationGraphSpace.Builder().optimizationAlgo(OptimizationAlgorithm.STOCHASTIC_GRADIENT_DESCENT).updater(new SgdSpace(new ContinuousParameterSpace(0.0001,0.1))).l2(new ContinuousParameterSpace(0.0001,0.01)).addInputs("in").addLayer("0",new DenseLayerSpace.Builder().nIn(784).nOut(new IntegerParameterSpace(10,20)).activation(new DiscreteParameterSpace<>(Activation.RELU,Activation.TANH)).build(),"in").addLayer("1",new OutputLayerSpace.Builder().nOut(10).activation(Activation.SOFTMAX).lossFunction(LossFunctions.LossFunction.MCXENT).build(),"0").setOutputs("1").setInputTypes(InputType.feedForward(784)).numEpochs(3).pretrain(false).backprop(true).build();
      DataProvider dp=null;
      Class<? extends DataSource> ds=null;
      Properties dsP=null;
      CandidateGenerator candidateGenerator;
      if (dataApproach == 0) {
        ds=TestDL4JLocalExecution.MnistDataSource.class;
        dsP=new Properties();
        dsP.setProperty("minibatch","8");
        candidateGenerator=new RandomSearchGenerator(mls);
      }
 else       if (dataApproach == 1) {
        dp=new TestDL4JLocalExecution.MnistDataProvider();
        candidateGenerator=new RandomSearchGenerator(mls);
      }
 else {
        Map<String,Object> commands=new HashMap<>();
        commands.put(DataSetIteratorFactoryProvider.FACTORY_KEY,TestDataFactoryProviderMnist.class.getCanonicalName());
        candidateGenerator=new RandomSearchGenerator(mls,commands);
        dp=new DataSetIteratorFactoryProvider();
      }
      File f=testDir.newFolder();
      File modelSave=new File(f,"modelSaveDir");
      OptimizationConfiguration configuration=new OptimizationConfiguration.Builder().candidateGenerator(candidateGenerator).dataProvider(dp).dataSource(ds,dsP).modelSaver(new FileModelSaver(modelSave)).scoreFunction(new TestSetLossScoreFunction()).terminationConditions(new MaxTimeCondition(2,TimeUnit.MINUTES),new MaxCandidatesCondition(5)).build();
      IOptimizationRunner runner=new LocalOptimizationRunner(configuration,new ComputationGraphTaskCreator(new ClassificationEvaluator()));
      runner.execute();
      List<ResultReference> results=runner.getResults();
      assertEquals(5,results.size());
      System.out.println("----- COMPLETE - " + results.size() + " results -----");
    }
  }
  @Test public void testLocalExecution() throws Exception {
    Map<String,Object> commands=new HashMap<>();
    commands.put(DataSetIteratorFactoryProvider.FACTORY_KEY,TestDataFactoryProviderMnist.class.getCanonicalName());
    ComputationGraphSpace mls=new ComputationGraphSpace.Builder().optimizationAlgo(OptimizationAlgorithm.STOCHASTIC_GRADIENT_DESCENT).updater(new SgdSpace(new ContinuousParameterSpace(0.0001,0.1))).l2(new ContinuousParameterSpace(0.0001,0.01)).addInputs("in").setInputTypes(InputType.feedForward(4)).addLayer("layer0",new DenseLayerSpace.Builder().nIn(784).nOut(new IntegerParameterSpace(2,10)).activation(new DiscreteParameterSpace<>(Activation.RELU,Activation.TANH)).build(),"in").addLayer("out",new OutputLayerSpace.Builder().nOut(10).activation(Activation.SOFTMAX).lossFunction(LossFunctions.LossFunction.MCXENT).build(),"layer0").setOutputs("out").numEpochs(3).pretrain(false).backprop(true).build();
    CandidateGenerator candidateGenerator=new RandomSearchGenerator(mls,commands);
    DataProvider dataProvider=new DataSetIteratorFactoryProvider();
    String modelSavePath=new File(System.getProperty("java.io.tmpdir"),"ArbiterDL4JTest\\").getAbsolutePath();
    File f=new File(modelSavePath);
    if (f.exists())     f.delete();
    f.mkdir();
    f.deleteOnExit();
    if (!f.exists())     throw new RuntimeException();
    OptimizationConfiguration configuration=new OptimizationConfiguration.Builder().candidateGenerator(candidateGenerator).dataProvider(dataProvider).modelSaver(new FileModelSaver(modelSavePath)).scoreFunction(ScoreFunctions.testSetLoss(true)).terminationConditions(new MaxTimeCondition(20,TimeUnit.SECONDS),new MaxCandidatesCondition(10)).build();
    IOptimizationRunner runner=new LocalOptimizationRunner(configuration,new ComputationGraphTaskCreator(new ClassificationEvaluator()));
    runner.execute();
    assertEquals(0,runner.numCandidatesFailed());
    assertTrue(runner.numCandidatesCompleted() > 0);
  }
  @Test public void testLocalExecutionMDS() throws Exception {
    ComputationGraphSpace mls=new ComputationGraphSpace.Builder().optimizationAlgo(OptimizationAlgorithm.STOCHASTIC_GRADIENT_DESCENT).updater(new SgdSpace(new ContinuousParameterSpace(0.0001,0.1))).l2(new ContinuousParameterSpace(0.0001,0.01)).addInputs("in").setInputTypes(InputType.feedForward(4)).addLayer("layer0",new DenseLayerSpace.Builder().nIn(784).nOut(new IntegerParameterSpace(2,10)).activation(new DiscreteParameterSpace<>(Activation.RELU,Activation.TANH)).build(),"in").addLayer("out",new OutputLayerSpace.Builder().nOut(10).activation(Activation.SOFTMAX).lossFunction(LossFunctions.LossFunction.MCXENT).build(),"layer0").setOutputs("out").numEpochs(3).pretrain(false).backprop(true).build();
    CandidateGenerator candidateGenerator=new RandomSearchGenerator(mls,null);
    String modelSavePath=new File(System.getProperty("java.io.tmpdir"),"ArbiterDL4JTest\\").getAbsolutePath();
    File f=new File(modelSavePath);
    if (f.exists())     f.delete();
    f.mkdir();
    f.deleteOnExit();
    if (!f.exists())     throw new RuntimeException();
    OptimizationConfiguration configuration=new OptimizationConfiguration.Builder().candidateGenerator(candidateGenerator).dataProvider(new TestMdsDataProvider(1,32)).modelSaver(new FileModelSaver(modelSavePath)).scoreFunction(ScoreFunctions.testSetLoss(true)).terminationConditions(new MaxTimeCondition(20,TimeUnit.SECONDS),new MaxCandidatesCondition(10)).scoreFunction(ScoreFunctions.testSetAccuracy()).build();
    IOptimizationRunner runner=new LocalOptimizationRunner(configuration,new ComputationGraphTaskCreator());
    runner.execute();
    assertEquals(0,runner.numCandidatesFailed());
    assertTrue(runner.numCandidatesCompleted() > 0);
  }
public static class TestMdsDataProvider implements DataProvider {
    private int numEpochs;
    private int batchSize;
    public TestMdsDataProvider(    @JsonProperty("numEpochs") int numEpochs,    @JsonProperty("batchSize") int batchSize){
      this.numEpochs=numEpochs;
      this.batchSize=batchSize;
    }
    private TestMdsDataProvider(){
    }
    @Override public Object trainData(    Map<String,Object> dataParameters){
      try {
        DataSetIterator underlying=new MnistDataSetIterator(batchSize,Math.min(60000,10 * batchSize),false,true,true,12345);
        return new MultiDataSetIteratorAdapter(new MultipleEpochsIterator(numEpochs,underlying));
      }
 catch (      IOException e) {
        throw new RuntimeException(e);
      }
    }
    @Override public Object testData(    Map<String,Object> dataParameters){
      try {
        DataSetIterator underlying=new MnistDataSetIterator(batchSize,Math.min(10000,5 * batchSize),false,false,false,12345);
        return new MultiDataSetIteratorAdapter(underlying);
      }
 catch (      IOException e) {
        throw new RuntimeException(e);
      }
    }
    @Override public Class<?> getDataType(){
      return MultiDataSetIterator.class;
    }
  }
  @Test public void testLocalExecutionEarlyStopping() throws Exception {
    EarlyStoppingConfiguration<ComputationGraph> esConf=new EarlyStoppingConfiguration.Builder<ComputationGraph>().epochTerminationConditions(new MaxEpochsTerminationCondition(15)).scoreCalculator(new ScoreProvider()).modelSaver(new InMemoryModelSaver()).build();
    Map<String,Object> commands=new HashMap<>();
    commands.put(DataSetIteratorFactoryProvider.FACTORY_KEY,TestDataFactoryProviderMnist.class.getCanonicalName());
    ComputationGraphSpace cgs=new ComputationGraphSpace.Builder().optimizationAlgo(OptimizationAlgorithm.STOCHASTIC_GRADIENT_DESCENT).updater(new AdamSpace(new ContinuousParameterSpace(0.0001,0.1))).l2(new ContinuousParameterSpace(0.0001,0.01)).addInputs("in").setInputTypes(InputType.feedForward(784)).addLayer("first",new DenseLayerSpace.Builder().nIn(784).nOut(new IntegerParameterSpace(2,10)).activation(new DiscreteParameterSpace<>(Activation.RELU,Activation.TANH)).build(),"in").addLayer("out",new OutputLayerSpace.Builder().nOut(10).activation(Activation.SOFTMAX).lossFunction(LossFunctions.LossFunction.MCXENT).build(),"first").setOutputs("out").earlyStoppingConfiguration(esConf).pretrain(false).backprop(true).build();
    CandidateGenerator candidateGenerator=new RandomSearchGenerator(cgs,commands);
    DataProvider dataProvider=new DataSetIteratorFactoryProvider();
    String modelSavePath=new File(System.getProperty("java.io.tmpdir"),"ArbiterDL4JTest2CG\\").getAbsolutePath();
    File f=new File(modelSavePath);
    if (f.exists())     f.delete();
    f.mkdir();
    f.deleteOnExit();
    if (!f.exists())     throw new RuntimeException();
    OptimizationConfiguration configuration=new OptimizationConfiguration.Builder().candidateGenerator(candidateGenerator).dataProvider(dataProvider).scoreFunction(ScoreFunctions.testSetF1()).modelSaver(new FileModelSaver(modelSavePath)).terminationConditions(new MaxTimeCondition(30,TimeUnit.SECONDS),new MaxCandidatesCondition(10)).build();
    IOptimizationRunner runner=new LocalOptimizationRunner(configuration,new ComputationGraphTaskCreator());
    runner.execute();
    assertEquals(0,runner.numCandidatesFailed());
    assertTrue(runner.numCandidatesCompleted() > 0);
  }
private static class ScoreProvider implements Supplier<ScoreCalculator>, Serializable {
    @Override public ScoreCalculator get(){
      try {
        return new DataSetLossCalculatorCG(new MnistDataSetIterator(128,1280),true);
      }
 catch (      Exception e) {
        throw new RuntimeException(e);
      }
    }
  }
}
