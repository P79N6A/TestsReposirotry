/** 
 * Created by agibsonccc on 1/23/15.
 */
public abstract class BaseSparkTest implements Serializable {
  protected transient JavaSparkContext sc;
  protected transient INDArray labels;
  protected transient INDArray input;
  protected transient INDArray rowSums;
  protected transient int nRows=200;
  protected transient int nIn=4;
  protected transient int nOut=3;
  protected transient DataSet data;
  protected transient JavaRDD<DataSet> sparkData;
  @Before public void before(){
    sc=getContext();
    Random r=new Random(12345);
    labels=Nd4j.create(nRows,nOut);
    input=Nd4j.rand(nRows,nIn);
    rowSums=input.sum(1);
    input.diviColumnVector(rowSums);
    for (int i=0; i < nRows; i++) {
      int x1=r.nextInt(nOut);
      labels.putScalar(new int[]{i,x1},1.0);
    }
    sparkData=getBasicSparkDataSet(nRows,input,labels);
  }
  @After public void after(){
    sc.close();
    sc=null;
  }
  /** 
 * @return
 */
  public JavaSparkContext getContext(){
    if (sc != null)     return sc;
    SparkConf sparkConf=new SparkConf().setMaster("local[" + numExecutors() + "]").set("spark.driver.host","localhost").setAppName("sparktest");
    sc=new JavaSparkContext(sparkConf);
    return sc;
  }
  protected JavaRDD<DataSet> getBasicSparkDataSet(  int nRows,  INDArray input,  INDArray labels){
    List<DataSet> list=new ArrayList<>();
    for (int i=0; i < nRows; i++) {
      INDArray inRow=input.getRow(i).dup();
      INDArray outRow=labels.getRow(i).dup();
      DataSet ds=new DataSet(inRow,outRow);
      list.add(ds);
    }
    list.iterator();
    data=DataSet.merge(list);
    return sc.parallelize(list);
  }
  protected SparkDl4jMultiLayer getBasicNetwork(){
    return new SparkDl4jMultiLayer(sc,getBasicConf(),new ParameterAveragingTrainingMaster(true,numExecutors(),1,10,1,0));
  }
  protected int numExecutors(){
    int numProc=Runtime.getRuntime().availableProcessors();
    return Math.min(4,numProc);
  }
  protected MultiLayerConfiguration getBasicConf(){
    MultiLayerConfiguration conf=new NeuralNetConfiguration.Builder().seed(123).updater(new Nesterovs(0.1,0.9)).list().layer(0,new org.deeplearning4j.nn.conf.layers.DenseLayer.Builder().nIn(nIn).nOut(3).activation(Activation.TANH).build()).layer(1,new org.deeplearning4j.nn.conf.layers.OutputLayer.Builder(LossFunctions.LossFunction.MCXENT).nIn(3).nOut(nOut).activation(Activation.SOFTMAX).build()).build();
    return conf;
  }
}
