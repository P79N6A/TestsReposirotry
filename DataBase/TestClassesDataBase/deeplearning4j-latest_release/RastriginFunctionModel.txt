/** 
 * Rastrigin function: A much more complex non-NN multi-dimensional optimization problem. Global minimum of 0 at x_i = 0 for all x_i. Very large number of local minima. Can't expect to achieve global minimum with gradient-based (line search) optimizers, but can expect significant improvement in score/cost relative to initial parameters. This implementation has cost function = infinity if any parameters x_i are outside of range [-5.12,5.12] https://en.wikipedia.org/wiki/Rastrigin_function
 */
private static class RastriginFunctionModel extends SimpleOptimizableModel {
  private static final long serialVersionUID=-1772954508787487941L;
  private RastriginFunctionModel(  int nDimensions,  NeuralNetConfiguration conf){
    super(initParams(nDimensions),conf);
  }
  private static INDArray initParams(  int nDimensions){
    Random rng=new DefaultRandom(12345L);
    org.nd4j.linalg.api.rng.distribution.Distribution dist=new org.nd4j.linalg.api.rng.distribution.impl.UniformDistribution(rng,-5.12,5.12);
    return dist.sample(new int[]{1,nDimensions});
  }
  @Override public void computeGradientAndScore(  LayerWorkspaceMgr workspaceMgr){
    INDArray gradient=parameters.mul(2 * Math.PI);
    Nd4j.getExecutioner().exec(new Sin(gradient));
    gradient.muli(20 * Math.PI);
    gradient.addi(parameters.mul(2));
    Gradient g=new DefaultGradient(this.gradientView);
    g.gradientForVariable().put("W",this.gradientView);
    this.gradient=g;
    INDArray paramExceeds512=parameters.cond(new Condition(){
      @Override public int condtionNum(){
        return 0;
      }
      @Override public double getValue(){
        return 0;
      }
      @Override public double epsThreshold(){
        return 0;
      }
      @Override public Boolean apply(      Number input){
        return Math.abs(input.doubleValue()) > 5.12;
      }
    }
);
    int nExceeds512=paramExceeds512.sum(Integer.MAX_VALUE).getInt(0);
    if (nExceeds512 > 0)     this.score=Double.POSITIVE_INFINITY;
    double costFn=10 * parameters.length();
    costFn+=Nd4j.getBlasWrapper().dot(parameters,parameters);
    INDArray temp=parameters.mul(2.0 * Math.PI);
    Nd4j.getExecutioner().exec(new Cos(temp));
    temp.muli(-10.0);
    costFn+=temp.sum(Integer.MAX_VALUE).getDouble(0);
    this.score=costFn;
    this.gradientView.assign(gradient);
  }
  @Override public long numParams(  boolean backwards){
    return 0;
  }
  @Override public void setParamsViewArray(  INDArray params){
    throw new UnsupportedOperationException("Not supported");
  }
  @Override public void setBackpropGradientsViewArray(  INDArray gradients){
    throw new UnsupportedOperationException();
  }
  @Override public void setCacheMode(  CacheMode mode){
    throw new UnsupportedOperationException();
  }
  @Override public void setListeners(  TrainingListener... listeners){
  }
  @Override public int getIndex(){
    return 0;
  }
  @Override public void setInput(  INDArray input,  LayerWorkspaceMgr workspaceMgr){
  }
  @Override public boolean isPretrainLayer(){
    return false;
  }
  @Override public void clearNoiseWeightParams(){
  }
}
