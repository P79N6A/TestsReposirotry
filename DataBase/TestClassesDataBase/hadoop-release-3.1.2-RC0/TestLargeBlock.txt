/** 
 * This class tests that blocks can be larger than 2GB
 */
public class TestLargeBlock {
  /** 
 * { GenericTestUtils.setLogLevel(DataNode.LOG, Level.ALL); GenericTestUtils.setLogLevel(LeaseManager.LOG, Level.ALL); GenericTestUtils.setLogLevel(FSNamesystem.LOG, Level.ALL); GenericTestUtils.setLogLevel(DFSClient.LOG, Level.ALL); GenericTestUtils.setLogLevel(TestLargeBlock.LOG, Level.ALL); }
 */
  private static final Log LOG=LogFactory.getLog(TestLargeBlock.class);
  static final boolean verifyData=true;
  static final byte[] pattern={'D','E','A','D','B','E','E','F'};
  static final int numDatanodes=3;
  static FSDataOutputStream createFile(  FileSystem fileSys,  Path name,  int repl,  final long blockSize) throws IOException {
    FSDataOutputStream stm=fileSys.create(name,true,fileSys.getConf().getInt(CommonConfigurationKeys.IO_FILE_BUFFER_SIZE_KEY,4096),(short)repl,blockSize);
    LOG.info("createFile: Created " + name + " with "+ repl+ " replica.");
    return stm;
  }
  /** 
 * Writes pattern to file
 * @param stm FSDataOutputStream to write the file
 * @param fileSize size of the file to be written
 * @throws IOException in case of errors
 */
  static void writeFile(  FSDataOutputStream stm,  final long fileSize) throws IOException {
    final int writeSize=pattern.length * 8 * 1024* 1024;
    if (writeSize > Integer.MAX_VALUE) {
      throw new IOException("A single write is too large " + writeSize);
    }
    long bytesToWrite=fileSize;
    byte[] b=new byte[writeSize];
    for (int j=0; j < writeSize; j++) {
      b[j]=pattern[j % pattern.length];
    }
    while (bytesToWrite > 0) {
      int thiswrite=(int)Math.min(writeSize,bytesToWrite);
      stm.write(b,0,thiswrite);
      bytesToWrite-=thiswrite;
    }
  }
  /** 
 * Reads from file and makes sure that it matches the pattern
 * @param fs a reference to FileSystem
 * @param name Path of a file
 * @param fileSize size of the file
 * @throws IOException in case of errors
 */
  static void checkFullFile(  FileSystem fs,  Path name,  final long fileSize) throws IOException {
    final int readSize=pattern.length * 16 * 1024* 1024;
    if (readSize > Integer.MAX_VALUE) {
      throw new IOException("A single read is too large " + readSize);
    }
    byte[] b=new byte[readSize];
    long bytesToRead=fileSize;
    byte[] compb=new byte[readSize];
    if (verifyData) {
      for (int j=0; j < readSize; j++) {
        compb[j]=pattern[j % pattern.length];
      }
    }
    FSDataInputStream stm=fs.open(name);
    while (bytesToRead > 0) {
      int thisread=(int)Math.min(readSize,bytesToRead);
      stm.readFully(b,0,thisread);
      if (verifyData) {
        if (thisread == readSize) {
          assertTrue("file is corrupted at or after byte " + (fileSize - bytesToRead),Arrays.equals(b,compb));
        }
 else {
          for (int k=0; k < thisread; k++) {
            assertTrue("file is corrupted at or after byte " + (fileSize - bytesToRead),b[k] == compb[k]);
          }
        }
      }
      LOG.debug("Before update: to read: " + bytesToRead + "; read already: "+ thisread);
      bytesToRead-=thisread;
      LOG.debug("After  update: to read: " + bytesToRead + "; read already: "+ thisread);
    }
    stm.close();
  }
  /** 
 * Test for block size of 2GB + 512B. This test can take a rather long time to complete on Windows (reading the file back can be slow) so we use a larger timeout here.
 * @throws IOException in case of errors
 */
  @Test(timeout=1800000) public void testLargeBlockSize() throws IOException {
    final long blockSize=2L * 1024L * 1024L* 1024L + 512L;
    runTest(blockSize);
  }
  /** 
 * Test that we can write to and read from large blocks
 * @param blockSize size of the block
 * @throws IOException in case of errors
 */
  public void runTest(  final long blockSize) throws IOException {
    final long fileSize=blockSize + 1L;
    Configuration conf=new Configuration();
    MiniDFSCluster cluster=new MiniDFSCluster.Builder(conf).numDataNodes(numDatanodes).build();
    FileSystem fs=cluster.getFileSystem();
    try {
      Path file1=new Path("/tmp/TestLargeBlock",blockSize + ".dat");
      FSDataOutputStream stm=createFile(fs,file1,1,blockSize);
      LOG.info("File " + file1 + " created with file size "+ fileSize+ " blocksize "+ blockSize);
      assertTrue(file1 + " should be a file",fs.getFileStatus(file1).isFile());
      writeFile(stm,fileSize);
      LOG.info("File " + file1 + " written to.");
      stm.close();
      LOG.info("File " + file1 + " closed.");
      checkFullFile(fs,file1,fileSize);
      long len=fs.getFileStatus(file1).getLen();
      assertTrue(file1 + " should be of size " + fileSize+ " but found to be of size "+ len,len == fileSize);
    }
  finally {
      cluster.shutdown();
    }
  }
}
