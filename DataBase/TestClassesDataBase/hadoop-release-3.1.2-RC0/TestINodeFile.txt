public class TestINodeFile {
static {
    FileSystem.enableSymlinks();
  }
  public static final Log LOG=LogFactory.getLog(TestINodeFile.class);
  static final short BLOCKBITS=48;
  static final long BLKSIZE_MAXVALUE=~(0xffffL << BLOCKBITS);
  private static final PermissionStatus perm=new PermissionStatus("userName",null,FsPermission.getDefault());
  private short replication;
  private long preferredBlockSize=1024;
  static public INodeFile createINodeFile(  long id){
    return new INodeFile(id,("file" + id).getBytes(),perm,0L,0L,null,(short)3,1024L);
  }
  static void toCompleteFile(  INodeFile file){
    file.toCompleteFile(Time.now(),0,(short)1);
  }
  INodeFile createINodeFile(  short replication,  long preferredBlockSize){
    return new INodeFile(HdfsConstants.GRANDFATHER_INODE_ID,null,perm,0L,0L,null,replication,preferredBlockSize);
  }
  INodeFile createStripedINodeFile(  long preferredBlockSize){
    return new INodeFile(HdfsConstants.GRANDFATHER_INODE_ID,null,perm,0L,0L,null,null,StripedFileTestUtil.getDefaultECPolicy().getId(),preferredBlockSize,HdfsConstants.WARM_STORAGE_POLICY_ID,STRIPED);
  }
  private static INodeFile createINodeFile(  byte storagePolicyID){
    return new INodeFile(HdfsConstants.GRANDFATHER_INODE_ID,null,perm,0L,0L,null,(short)3,null,1024L,storagePolicyID,CONTIGUOUS);
  }
  @Test public void testStoragePolicyID(){
    for (byte i=0; i < 16; i++) {
      final INodeFile f=createINodeFile(i);
      assertEquals(i,f.getStoragePolicyID());
    }
  }
  @Test(expected=IllegalArgumentException.class) public void testStoragePolicyIdBelowLowerBound() throws IllegalArgumentException {
    createINodeFile((byte)-1);
  }
  @Test(expected=IllegalArgumentException.class) public void testStoragePolicyIdAboveUpperBound() throws IllegalArgumentException {
    createINodeFile((byte)16);
  }
  @Test public void testContiguousLayoutRedundancy(){
    INodeFile inodeFile;
    try {
      new INodeFile(HdfsConstants.GRANDFATHER_INODE_ID,null,perm,0L,0L,null,new Short((short)3),StripedFileTestUtil.getDefaultECPolicy().getId(),preferredBlockSize,HdfsConstants.WARM_STORAGE_POLICY_ID,CONTIGUOUS);
      fail("INodeFile construction should fail when both replication and " + "ECPolicy requested!");
    }
 catch (    IllegalArgumentException iae) {
      LOG.info("Expected exception: ",iae);
    }
    try {
      new INodeFile(HdfsConstants.GRANDFATHER_INODE_ID,null,perm,0L,0L,null,null,null,preferredBlockSize,HdfsConstants.WARM_STORAGE_POLICY_ID,CONTIGUOUS);
      fail("INodeFile construction should fail when replication param not " + "provided for contiguous layout!");
    }
 catch (    IllegalArgumentException iae) {
      LOG.info("Expected exception: ",iae);
    }
    try {
      new INodeFile(HdfsConstants.GRANDFATHER_INODE_ID,null,perm,0L,0L,null,Short.MAX_VALUE,null,preferredBlockSize,HdfsConstants.WARM_STORAGE_POLICY_ID,CONTIGUOUS);
      fail("INodeFile construction should fail when replication param is " + "beyond the range supported!");
    }
 catch (    IllegalArgumentException iae) {
      LOG.info("Expected exception: ",iae);
    }
    final Short replication=new Short((short)3);
    try {
      new INodeFile(HdfsConstants.GRANDFATHER_INODE_ID,null,perm,0L,0L,null,replication,null,preferredBlockSize,HdfsConstants.WARM_STORAGE_POLICY_ID,STRIPED);
      fail("INodeFile construction should fail when replication param is " + "provided for striped layout!");
    }
 catch (    IllegalArgumentException iae) {
      LOG.info("Expected exception: ",iae);
    }
    inodeFile=new INodeFile(HdfsConstants.GRANDFATHER_INODE_ID,null,perm,0L,0L,null,replication,null,preferredBlockSize,HdfsConstants.WARM_STORAGE_POLICY_ID,CONTIGUOUS);
    Assert.assertTrue(!inodeFile.isStriped());
    Assert.assertEquals(replication.shortValue(),inodeFile.getFileReplication());
  }
  /** 
 * Test for the Replication value. Sets a value and checks if it was set correct.
 */
  @Test public void testReplication(){
    replication=3;
    preferredBlockSize=128 * 1024 * 1024;
    INodeFile inf=createINodeFile(replication,preferredBlockSize);
    assertEquals("True has to be returned in this case",replication,inf.getFileReplication());
  }
  /** 
 * IllegalArgumentException is expected for setting below lower bound for Replication.
 * @throws IllegalArgumentException as the result
 */
  @Test(expected=IllegalArgumentException.class) public void testReplicationBelowLowerBound() throws IllegalArgumentException {
    replication=-1;
    preferredBlockSize=128 * 1024 * 1024;
    createINodeFile(replication,preferredBlockSize);
  }
  /** 
 * Test for the PreferredBlockSize value. Sets a value and checks if it was set correct.
 */
  @Test public void testPreferredBlockSize(){
    replication=3;
    preferredBlockSize=128 * 1024 * 1024;
    INodeFile inf=createINodeFile(replication,preferredBlockSize);
    assertEquals("True has to be returned in this case",preferredBlockSize,inf.getPreferredBlockSize());
  }
  @Test public void testPreferredBlockSizeUpperBound(){
    replication=3;
    preferredBlockSize=BLKSIZE_MAXVALUE;
    INodeFile inf=createINodeFile(replication,preferredBlockSize);
    assertEquals("True has to be returned in this case",BLKSIZE_MAXVALUE,inf.getPreferredBlockSize());
  }
  /** 
 * IllegalArgumentException is expected for setting below lower bound for PreferredBlockSize.
 * @throws IllegalArgumentException as the result
 */
  @Test(expected=IllegalArgumentException.class) public void testPreferredBlockSizeBelowLowerBound() throws IllegalArgumentException {
    replication=3;
    preferredBlockSize=-1;
    createINodeFile(replication,preferredBlockSize);
  }
  /** 
 * IllegalArgumentException is expected for setting above upper bound for PreferredBlockSize.
 * @throws IllegalArgumentException as the result
 */
  @Test(expected=IllegalArgumentException.class) public void testPreferredBlockSizeAboveUpperBound() throws IllegalArgumentException {
    replication=3;
    preferredBlockSize=BLKSIZE_MAXVALUE + 1;
    createINodeFile(replication,preferredBlockSize);
  }
  @Test public void testGetFullPathName(){
    replication=3;
    preferredBlockSize=128 * 1024 * 1024;
    INodeFile inf=createINodeFile(replication,preferredBlockSize);
    inf.setLocalName(DFSUtil.string2Bytes("f"));
    INodeDirectory root=new INodeDirectory(HdfsConstants.GRANDFATHER_INODE_ID,INodeDirectory.ROOT_NAME,perm,0L);
    INodeDirectory dir=new INodeDirectory(HdfsConstants.GRANDFATHER_INODE_ID,DFSUtil.string2Bytes("d"),perm,0L);
    assertEquals("f",inf.getFullPathName());
    dir.addChild(inf);
    assertEquals("d" + Path.SEPARATOR + "f",inf.getFullPathName());
    root.addChild(dir);
    assertEquals(Path.SEPARATOR + "d" + Path.SEPARATOR+ "f",inf.getFullPathName());
    assertEquals(Path.SEPARATOR + "d",dir.getFullPathName());
    assertEquals(Path.SEPARATOR,root.getFullPathName());
  }
  @Test public void testGetBlockType(){
    replication=3;
    preferredBlockSize=128 * 1024 * 1024;
    INodeFile inf=createINodeFile(replication,preferredBlockSize);
    assertEquals(inf.getBlockType(),CONTIGUOUS);
    INodeFile striped=createStripedINodeFile(preferredBlockSize);
    assertEquals(striped.getBlockType(),STRIPED);
  }
  /** 
 * FSDirectory#unprotectedSetQuota creates a new INodeDirectoryWithQuota to replace the original INodeDirectory. Before HDFS-4243, the parent field of all the children INodes of the target INodeDirectory is not changed to point to the new INodeDirectoryWithQuota. This testcase tests this scenario.
 */
  @Test public void testGetFullPathNameAfterSetQuota() throws Exception {
    long fileLen=1024;
    replication=3;
    Configuration conf=new Configuration();
    MiniDFSCluster cluster=null;
    try {
      cluster=new MiniDFSCluster.Builder(conf).numDataNodes(replication).build();
      cluster.waitActive();
      FSNamesystem fsn=cluster.getNamesystem();
      FSDirectory fsdir=fsn.getFSDirectory();
      DistributedFileSystem dfs=cluster.getFileSystem();
      final Path dir=new Path("/dir");
      final Path file=new Path(dir,"file");
      DFSTestUtil.createFile(dfs,file,fileLen,replication,0L);
      INode fnode=fsdir.getINode(file.toString());
      assertEquals(file.toString(),fnode.getFullPathName());
      dfs.setQuota(dir,Long.MAX_VALUE - 1,replication * fileLen * 10);
      INodeDirectory dirNode=getDir(fsdir,dir);
      assertEquals(dir.toString(),dirNode.getFullPathName());
      assertTrue(dirNode.isWithQuota());
      final Path newDir=new Path("/newdir");
      final Path newFile=new Path(newDir,"file");
      dfs.rename(dir,newDir,Options.Rename.OVERWRITE);
      fnode=fsdir.getINode(newFile.toString());
      assertEquals(newFile.toString(),fnode.getFullPathName());
    }
  finally {
      if (cluster != null) {
        cluster.shutdown();
      }
    }
  }
  @Test public void testConcatBlocks(){
    INodeFile origFile=createINodeFiles(1,"origfile")[0];
    assertEquals("Number of blocks didn't match",origFile.numBlocks(),1L);
    INodeFile[] appendFiles=createINodeFiles(4,"appendfile");
    BlockManager bm=Mockito.mock(BlockManager.class);
    origFile.concatBlocks(appendFiles,bm);
    assertEquals("Number of blocks didn't match",origFile.numBlocks(),5L);
  }
  /** 
 * Creates the required number of files with one block each
 * @param nCount Number of INodes to create
 * @return Array of INode files
 */
  private INodeFile[] createINodeFiles(  int nCount,  String fileNamePrefix){
    if (nCount <= 0)     return new INodeFile[1];
    replication=3;
    preferredBlockSize=128 * 1024 * 1024;
    INodeFile[] iNodes=new INodeFile[nCount];
    for (int i=0; i < nCount; i++) {
      iNodes[i]=new INodeFile(i,null,perm,0L,0L,null,replication,preferredBlockSize);
      iNodes[i].setLocalName(DFSUtil.string2Bytes(fileNamePrefix + i));
      BlockInfo newblock=new BlockInfoContiguous(replication);
      iNodes[i].addBlock(newblock);
    }
    return iNodes;
  }
  /** 
 * Test for the static  {@link INodeFile#valueOf(INode,String)}and  {@link INodeFileUnderConstruction#valueOf(INode,String)} methods.
 * @throws IOException 
 */
  @Test public void testValueOf() throws IOException {
    final String path="/testValueOf";
    final short replication=3;
{
      final INode from=null;
      try {
        INodeFile.valueOf(from,path);
        fail();
      }
 catch (      FileNotFoundException fnfe) {
        assertTrue(fnfe.getMessage().contains("File does not exist"));
      }
      try {
        INodeDirectory.valueOf(from,path);
        fail();
      }
 catch (      FileNotFoundException e) {
        assertTrue(e.getMessage().contains("Directory does not exist"));
      }
    }
{
      final INode from=createINodeFile(replication,preferredBlockSize);
      final INodeFile f=INodeFile.valueOf(from,path);
      assertTrue(f == from);
      try {
        INodeDirectory.valueOf(from,path);
        fail();
      }
 catch (      PathIsNotDirectoryException e) {
      }
    }
{
      final INode from=new INodeFile(HdfsConstants.GRANDFATHER_INODE_ID,null,perm,0L,0L,null,replication,1024L);
      from.asFile().toUnderConstruction("client","machine");
      final INodeFile f=INodeFile.valueOf(from,path);
      assertTrue(f == from);
      try {
        INodeDirectory.valueOf(from,path);
        fail();
      }
 catch (      PathIsNotDirectoryException expected) {
      }
    }
{
      final INode from=new INodeDirectory(HdfsConstants.GRANDFATHER_INODE_ID,null,perm,0L);
      try {
        INodeFile.valueOf(from,path);
        fail();
      }
 catch (      FileNotFoundException fnfe) {
        assertTrue(fnfe.getMessage().contains("Path is not a file"));
      }
      final INodeDirectory d=INodeDirectory.valueOf(from,path);
      assertTrue(d == from);
    }
  }
  /** 
 * This test verifies inode ID counter and inode map functionality.
 */
  @Test public void testInodeId() throws IOException {
    Configuration conf=new Configuration();
    conf.setInt(DFSConfigKeys.DFS_BLOCK_SIZE_KEY,DFSConfigKeys.DFS_BYTES_PER_CHECKSUM_DEFAULT);
    MiniDFSCluster cluster=null;
    try {
      cluster=new MiniDFSCluster.Builder(conf).numDataNodes(1).build();
      cluster.waitActive();
      FSNamesystem fsn=cluster.getNamesystem();
      long lastId=fsn.dir.getLastInodeId();
      int inodeCount=1;
      long expectedLastInodeId=INodeId.ROOT_INODE_ID;
      assertEquals(fsn.dir.rootDir.getId(),INodeId.ROOT_INODE_ID);
      assertEquals(expectedLastInodeId,lastId);
      assertEquals(inodeCount,fsn.dir.getInodeMapSize());
      FileSystem fs=cluster.getFileSystem();
      Path path=new Path("/test1");
      assertTrue(fs.mkdirs(path));
      assertEquals(++expectedLastInodeId,fsn.dir.getLastInodeId());
      assertEquals(++inodeCount,fsn.dir.getInodeMapSize());
      NamenodeProtocols nnrpc=cluster.getNameNodeRpc();
      DFSTestUtil.createFile(fs,new Path("/test1/file"),1024,(short)1,0);
      assertEquals(++expectedLastInodeId,fsn.dir.getLastInodeId());
      assertEquals(++inodeCount,fsn.dir.getInodeMapSize());
      HdfsFileStatus fileStatus=nnrpc.getFileInfo("/test1/file");
      assertEquals(expectedLastInodeId,fileStatus.getFileId());
      Path renamedPath=new Path("/test2");
      assertTrue(fs.rename(path,renamedPath));
      assertEquals(expectedLastInodeId,fsn.dir.getLastInodeId());
      assertEquals(inodeCount,fsn.dir.getInodeMapSize());
      assertTrue(fs.delete(renamedPath,true));
      inodeCount-=2;
      assertEquals(inodeCount,fsn.dir.getInodeMapSize());
      String file1="/test1/file1";
      String file2="/test1/file2";
      DFSTestUtil.createFile(fs,new Path(file1),512,(short)1,0);
      DFSTestUtil.createFile(fs,new Path(file2),512,(short)1,0);
      inodeCount+=3;
      expectedLastInodeId+=3;
      assertEquals(inodeCount,fsn.dir.getInodeMapSize());
      assertEquals(expectedLastInodeId,fsn.dir.getLastInodeId());
      nnrpc.concat(file2,new String[]{file1});
      inodeCount--;
      assertEquals(inodeCount,fsn.dir.getInodeMapSize());
      assertEquals(expectedLastInodeId,fsn.dir.getLastInodeId());
      assertTrue(fs.delete(new Path("/test1"),true));
      inodeCount-=2;
      assertEquals(inodeCount,fsn.dir.getInodeMapSize());
      cluster.restartNameNode();
      cluster.waitActive();
      fsn=cluster.getNamesystem();
      assertEquals(expectedLastInodeId,fsn.dir.getLastInodeId());
      assertEquals(inodeCount,fsn.dir.getInodeMapSize());
      DFSTestUtil.createFile(fs,new Path("/test2/file2"),1024,(short)1,0);
      expectedLastInodeId+=2;
      inodeCount+=2;
      assertEquals(expectedLastInodeId,fsn.dir.getLastInodeId());
      assertEquals(inodeCount,fsn.dir.getInodeMapSize());
      FSDataOutputStream outStream=fs.create(new Path("/test3/file"));
      assertTrue(outStream != null);
      expectedLastInodeId+=2;
      inodeCount+=2;
      assertEquals(expectedLastInodeId,fsn.dir.getLastInodeId());
      assertEquals(inodeCount,fsn.dir.getInodeMapSize());
      fsn.enterSafeMode(false);
      fsn.saveNamespace(0,0);
      fsn.leaveSafeMode(false);
      outStream.close();
      cluster.restartNameNode();
      cluster.waitActive();
      fsn=cluster.getNamesystem();
      assertEquals(expectedLastInodeId,fsn.dir.getLastInodeId());
      assertEquals(inodeCount,fsn.dir.getInodeMapSize());
    }
  finally {
      if (cluster != null) {
        cluster.shutdown();
      }
    }
  }
  @Test(timeout=120000) public void testWriteToDeletedFile() throws IOException {
    Configuration conf=new Configuration();
    MiniDFSCluster cluster=new MiniDFSCluster.Builder(conf).numDataNodes(1).build();
    cluster.waitActive();
    FileSystem fs=cluster.getFileSystem();
    Path path=new Path("/test1");
    assertTrue(fs.mkdirs(path));
    int size=conf.getInt(DFSConfigKeys.DFS_BYTES_PER_CHECKSUM_KEY,512);
    byte[] data=new byte[size];
    Path filePath=new Path("/test1/file");
    FSDataOutputStream fos=fs.create(filePath);
    fs.delete(filePath,false);
    try {
      fos.write(data,0,data.length);
      fos.hflush();
      fail("Write should fail after delete");
    }
 catch (    Exception e) {
    }
 finally {
      cluster.shutdown();
    }
  }
  private Path getInodePath(  long inodeId,  String remainingPath){
    StringBuilder b=new StringBuilder();
    b.append(Path.SEPARATOR).append(FSDirectory.DOT_RESERVED_STRING).append(Path.SEPARATOR).append(FSDirectory.DOT_INODES_STRING).append(Path.SEPARATOR).append(inodeId).append(Path.SEPARATOR).append(remainingPath);
    Path p=new Path(b.toString());
    LOG.info("Inode path is " + p);
    return p;
  }
  /** 
 * Tests for addressing files using /.reserved/.inodes/<inodeID> in file system operations.
 */
  @Test public void testInodeIdBasedPaths() throws Exception {
    Configuration conf=new Configuration();
    conf.setInt(DFSConfigKeys.DFS_BLOCK_SIZE_KEY,DFSConfigKeys.DFS_BYTES_PER_CHECKSUM_DEFAULT);
    conf.setBoolean(DFSConfigKeys.DFS_NAMENODE_ACLS_ENABLED_KEY,true);
    MiniDFSCluster cluster=null;
    try {
      cluster=new MiniDFSCluster.Builder(conf).numDataNodes(1).build();
      cluster.waitActive();
      DistributedFileSystem fs=cluster.getFileSystem();
      NamenodeProtocols nnRpc=cluster.getNameNodeRpc();
      Path baseDir=getInodePath(INodeId.ROOT_INODE_ID,"testInodeIdBasedPaths");
      Path baseDirRegPath=new Path("/testInodeIdBasedPaths");
      fs.mkdirs(baseDir);
      fs.exists(baseDir);
      long baseDirFileId=nnRpc.getFileInfo(baseDir.toString()).getFileId();
      Path testFileInodePath=getInodePath(baseDirFileId,"test1");
      Path testFileRegularPath=new Path(baseDir,"test1");
      final int testFileBlockSize=1024;
      FileSystemTestHelper.createFile(fs,testFileInodePath,1,testFileBlockSize);
      assertTrue(fs.exists(testFileInodePath));
      FsPermission perm=new FsPermission((short)0666);
      fs.setPermission(testFileInodePath,perm);
      FileStatus fileStatus=fs.getFileStatus(testFileInodePath);
      assertEquals(perm,fileStatus.getPermission());
      fs.setOwner(testFileInodePath,fileStatus.getOwner(),fileStatus.getGroup());
      fs.setTimes(testFileInodePath,0,0);
      fileStatus=fs.getFileStatus(testFileInodePath);
      assertEquals(0,fileStatus.getModificationTime());
      assertEquals(0,fileStatus.getAccessTime());
      fs.setReplication(testFileInodePath,(short)3);
      fileStatus=fs.getFileStatus(testFileInodePath);
      assertEquals(3,fileStatus.getReplication());
      fs.setReplication(testFileInodePath,(short)1);
      assertEquals(testFileBlockSize,nnRpc.getPreferredBlockSize(testFileInodePath.toString()));
{
        fs.isFileClosed(testFileInodePath);
        fs.getAclStatus(testFileInodePath);
        fs.getXAttrs(testFileInodePath);
        fs.listXAttrs(testFileInodePath);
        fs.access(testFileInodePath,FsAction.READ_WRITE);
      }
      String invalidTarget=new Path(baseDir,"invalidTarget").toString();
      String link=new Path(baseDir,"link").toString();
      testInvalidSymlinkTarget(nnRpc,invalidTarget,link);
      String validTarget="/validtarget";
      testValidSymlinkTarget(nnRpc,validTarget,link);
      fs.append(testFileInodePath);
      fs.recoverLease(testFileInodePath);
      LocatedBlocks l1=nnRpc.getBlockLocations(testFileInodePath.toString(),0,Long.MAX_VALUE);
      LocatedBlocks l2=nnRpc.getBlockLocations(testFileRegularPath.toString(),0,Long.MAX_VALUE);
      checkEquals(l1,l2);
      Path renameDst=getInodePath(baseDirFileId,"test2");
      fileStatus=fs.getFileStatus(testFileInodePath);
      fs.rename(testFileInodePath,renameDst);
      fs.rename(renameDst,testFileInodePath);
      assertEquals(fileStatus,fs.getFileStatus(testFileInodePath));
      fs.rename(testFileInodePath,renameDst,Rename.OVERWRITE);
      fs.rename(renameDst,testFileInodePath,Rename.OVERWRITE);
      assertEquals(fileStatus,fs.getFileStatus(testFileInodePath));
      assertEquals(fs.getContentSummary(testFileRegularPath).toString(),fs.getContentSummary(testFileInodePath).toString());
      checkEquals(fs.listFiles(baseDirRegPath,false),fs.listFiles(baseDir,false));
      fs.delete(testFileInodePath,true);
      assertFalse(fs.exists(testFileInodePath));
    }
  finally {
      if (cluster != null) {
        cluster.shutdown();
      }
    }
  }
  private void testInvalidSymlinkTarget(  NamenodeProtocols nnRpc,  String invalidTarget,  String link) throws IOException {
    try {
      FsPermission perm=FsPermission.createImmutable((short)0755);
      nnRpc.createSymlink(invalidTarget,link,perm,false);
      fail("Symbolic link creation of target " + invalidTarget + " should fail");
    }
 catch (    InvalidPathException expected) {
    }
  }
  private void testValidSymlinkTarget(  NamenodeProtocols nnRpc,  String target,  String link) throws IOException {
    FsPermission perm=FsPermission.createImmutable((short)0755);
    nnRpc.createSymlink(target,link,perm,false);
    assertEquals(target,nnRpc.getLinkTarget(link));
  }
  private static void checkEquals(  LocatedBlocks l1,  LocatedBlocks l2){
    List<LocatedBlock> list1=l1.getLocatedBlocks();
    List<LocatedBlock> list2=l2.getLocatedBlocks();
    assertEquals(list1.size(),list2.size());
    for (int i=0; i < list1.size(); i++) {
      LocatedBlock b1=list1.get(i);
      LocatedBlock b2=list2.get(i);
      assertEquals(b1.getBlock(),b2.getBlock());
      assertEquals(b1.getBlockSize(),b2.getBlockSize());
    }
  }
  private static void checkEquals(  RemoteIterator<LocatedFileStatus> i1,  RemoteIterator<LocatedFileStatus> i2) throws IOException {
    while (i1.hasNext()) {
      assertTrue(i2.hasNext());
      LocatedFileStatus l1=i1.next();
      LocatedFileStatus l2=i2.next();
      assertEquals(l1.getAccessTime(),l2.getAccessTime());
      assertEquals(l1.getBlockSize(),l2.getBlockSize());
      assertEquals(l1.getGroup(),l2.getGroup());
      assertEquals(l1.getLen(),l2.getLen());
      assertEquals(l1.getModificationTime(),l2.getModificationTime());
      assertEquals(l1.getOwner(),l2.getOwner());
      assertEquals(l1.getPermission(),l2.getPermission());
      assertEquals(l1.getReplication(),l2.getReplication());
    }
    assertFalse(i2.hasNext());
  }
  /** 
 * Check /.reserved path is reserved and cannot be created.
 */
  @Test public void testReservedFileNames() throws IOException {
    Configuration conf=new Configuration();
    MiniDFSCluster cluster=null;
    try {
      cluster=new MiniDFSCluster.Builder(conf).numDataNodes(1).build();
      cluster.waitActive();
      FileSystem fs=cluster.getFileSystem();
      ensureReservedFileNamesCannotBeCreated(fs,"/.reserved",false);
      ensureReservedFileNamesCannotBeCreated(fs,"/.reserved",false);
      Path reservedPath=new Path("/.reserved");
      FSDirectory.CHECK_RESERVED_FILE_NAMES=false;
      fs.mkdirs(reservedPath);
      assertTrue(fs.isDirectory(reservedPath));
      ensureReservedFileNamesCannotBeLoaded(cluster);
      FSDirectory.CHECK_RESERVED_FILE_NAMES=false;
      ensureClusterRestartSucceeds(cluster);
      fs.delete(reservedPath,true);
      DFSTestUtil.createFile(fs,reservedPath,10,(short)1,0L);
      assertTrue(!fs.isDirectory(reservedPath));
      ensureReservedFileNamesCannotBeLoaded(cluster);
    }
  finally {
      if (cluster != null) {
        cluster.shutdown();
      }
    }
  }
  private void ensureReservedFileNamesCannotBeCreated(  FileSystem fs,  String name,  boolean isDir){
    Path reservedPath=new Path(name);
    try {
      if (isDir) {
        fs.mkdirs(reservedPath);
      }
 else {
        DFSTestUtil.createFile(fs,reservedPath,10,(short)1,0L);
      }
      fail((isDir ? "mkdir" : "create file") + " should be disallowed");
    }
 catch (    Exception expected) {
    }
  }
  private void ensureReservedFileNamesCannotBeLoaded(  MiniDFSCluster cluster) throws IOException {
    FSDirectory.CHECK_RESERVED_FILE_NAMES=true;
    ensureClusterRestartFails(cluster);
    FSDirectory.CHECK_RESERVED_FILE_NAMES=false;
    ensureClusterRestartSucceeds(cluster);
    FSDirectory.CHECK_RESERVED_FILE_NAMES=true;
    ensureClusterRestartFails(cluster);
  }
  private void ensureClusterRestartFails(  MiniDFSCluster cluster){
    try {
      cluster.restartNameNode();
      fail("Cluster should not have successfully started");
    }
 catch (    Exception expected) {
      LOG.info("Expected exception thrown " + expected);
    }
    assertFalse(cluster.isClusterUp());
  }
  private void ensureClusterRestartSucceeds(  MiniDFSCluster cluster) throws IOException {
    cluster.restartNameNode();
    cluster.waitActive();
    assertTrue(cluster.isClusterUp());
  }
  /** 
 * For a given path, build a tree of INodes and return the leaf node.
 */
  private INode createTreeOfInodes(  String path) throws QuotaExceededException {
    byte[][] components=INode.getPathComponents(path);
    FsPermission perm=FsPermission.createImmutable((short)0755);
    PermissionStatus permstatus=PermissionStatus.createImmutable("","",perm);
    long id=0;
    INodeDirectory prev=new INodeDirectory(++id,new byte[0],permstatus,0);
    INodeDirectory dir=null;
    for (    byte[] component : components) {
      if (component.length == 0) {
        continue;
      }
      System.out.println("Adding component " + DFSUtil.bytes2String(component));
      dir=new INodeDirectory(++id,component,permstatus,0);
      prev.addChild(dir,false,Snapshot.CURRENT_STATE_ID);
      prev=dir;
    }
    return dir;
  }
  /** 
 * Test for  {@link FSDirectory#getPathComponents(INode)}
 */
  @Test public void testGetPathFromInode() throws QuotaExceededException {
    String path="/a/b/c";
    INode inode=createTreeOfInodes(path);
    byte[][] expected=INode.getPathComponents(path);
    byte[][] actual=FSDirectory.getPathComponents(inode);
    DFSTestUtil.checkComponentsEquals(expected,actual);
  }
  /** 
 * Tests for  {@link FSDirectory#resolvePath(String,FSDirectory)}
 */
  @Test public void testInodePath() throws IOException {
    String path="/a/b/c";
    INode inode=createTreeOfInodes(path);
    FSDirectory fsd=Mockito.mock(FSDirectory.class);
    Mockito.doReturn(inode).when(fsd).getInode(Mockito.anyLong());
    String resolvedPath=FSDirectory.resolvePath(path,fsd);
    assertEquals(path,resolvedPath);
    String testPath="/.reserved/.inodes/1";
    resolvedPath=FSDirectory.resolvePath(testPath,fsd);
    assertEquals(path,resolvedPath);
    testPath="/.reserved/.inodes/1/";
    resolvedPath=FSDirectory.resolvePath(testPath,fsd);
    assertEquals(path,resolvedPath);
    testPath="/.reserved/.inodes/1/d/e/f";
    resolvedPath=FSDirectory.resolvePath(testPath,fsd);
    assertEquals("/a/b/c/d/e/f",resolvedPath);
    testPath="/.reserved/.inodes";
    resolvedPath=FSDirectory.resolvePath(testPath,fsd);
    assertEquals(testPath,resolvedPath);
    testPath="/.reserved/.inodes/" + INodeId.ROOT_INODE_ID;
    resolvedPath=FSDirectory.resolvePath(testPath,fsd);
    assertEquals("/",resolvedPath);
    testPath="/.invalid/.inodes/1";
    resolvedPath=FSDirectory.resolvePath(testPath,fsd);
    assertEquals(testPath,resolvedPath);
    Mockito.doReturn(null).when(fsd).getInode(Mockito.anyLong());
    testPath="/.reserved/.inodes/1234";
    try {
      String realPath=FSDirectory.resolvePath(testPath,fsd);
      fail("Path should not be resolved:" + realPath);
    }
 catch (    IOException e) {
      assertTrue(e instanceof FileNotFoundException);
    }
  }
  private static INodeDirectory getDir(  final FSDirectory fsdir,  final Path dir) throws IOException {
    final String dirStr=dir.toString();
    return INodeDirectory.valueOf(fsdir.getINode(dirStr),dirStr);
  }
  /** 
 * Test whether the inode in inodeMap has been replaced after regular inode replacement
 */
  @Test public void testInodeReplacement() throws Exception {
    final Configuration conf=new Configuration();
    MiniDFSCluster cluster=null;
    try {
      cluster=new MiniDFSCluster.Builder(conf).numDataNodes(1).build();
      cluster.waitActive();
      final DistributedFileSystem hdfs=cluster.getFileSystem();
      final FSDirectory fsdir=cluster.getNamesystem().getFSDirectory();
      final Path dir=new Path("/dir");
      hdfs.mkdirs(dir);
      INodeDirectory dirNode=getDir(fsdir,dir);
      INode dirNodeFromNode=fsdir.getInode(dirNode.getId());
      assertSame(dirNode,dirNodeFromNode);
      hdfs.setQuota(dir,Long.MAX_VALUE - 1,Long.MAX_VALUE - 1);
      dirNode=getDir(fsdir,dir);
      assertTrue(dirNode.isWithQuota());
      dirNodeFromNode=fsdir.getInode(dirNode.getId());
      assertSame(dirNode,dirNodeFromNode);
      hdfs.setQuota(dir,-1,-1);
      dirNode=getDir(fsdir,dir);
      dirNodeFromNode=fsdir.getInode(dirNode.getId());
      assertSame(dirNode,dirNodeFromNode);
    }
  finally {
      if (cluster != null) {
        cluster.shutdown();
      }
    }
  }
  @Test public void testDotdotInodePath() throws Exception {
    final Configuration conf=new Configuration();
    MiniDFSCluster cluster=null;
    DFSClient client=null;
    try {
      cluster=new MiniDFSCluster.Builder(conf).numDataNodes(1).build();
      cluster.waitActive();
      final DistributedFileSystem hdfs=cluster.getFileSystem();
      final FSDirectory fsdir=cluster.getNamesystem().getFSDirectory();
      final Path dir=new Path("/dir");
      hdfs.mkdirs(dir);
      long dirId=fsdir.getINode(dir.toString()).getId();
      long parentId=fsdir.getINode("/").getId();
      String testPath="/.reserved/.inodes/" + dirId + "/..";
      client=new DFSClient(DFSUtilClient.getNNAddress(conf),conf);
      HdfsFileStatus status=client.getFileInfo(testPath);
      assertTrue(parentId == status.getFileId());
      testPath="/.reserved/.inodes/" + parentId + "/..";
      status=client.getFileInfo(testPath);
      assertTrue(parentId == status.getFileId());
    }
  finally {
      IOUtils.cleanup(LOG,client);
      if (cluster != null) {
        cluster.shutdown();
      }
    }
  }
  @Test public void testLocationLimitInListingOps() throws Exception {
    final Configuration conf=new Configuration();
    conf.setInt(DFSConfigKeys.DFS_LIST_LIMIT,9);
    MiniDFSCluster cluster=null;
    try {
      cluster=new MiniDFSCluster.Builder(conf).numDataNodes(3).build();
      cluster.waitActive();
      final DistributedFileSystem hdfs=cluster.getFileSystem();
      ArrayList<String> source=new ArrayList<String>();
      hdfs.mkdirs(new Path("/tmp1"));
      hdfs.mkdirs(new Path("/tmp2"));
      source.add("f1");
      source.add("f2");
      int numEntries=source.size();
      for (int j=0; j < numEntries; j++) {
        DFSTestUtil.createFile(hdfs,new Path("/tmp1/" + source.get(j)),4096,3 * 1024 - 100,1024,(short)3,0);
      }
      byte[] start=HdfsFileStatus.EMPTY_NAME;
      for (int j=0; j < numEntries; j++) {
        DirectoryListing dl=cluster.getNameNodeRpc().getListing("/tmp1",start,true);
        assertTrue(dl.getPartialListing().length == 1);
        for (int i=0; i < dl.getPartialListing().length; i++) {
          source.remove(dl.getPartialListing()[i].getLocalName());
        }
        start=dl.getLastName();
      }
      assertTrue(source.size() == 0);
      source.add("f1");
      source.add("f2");
      source.add("f3");
      source.add("f4");
      source.add("f5");
      source.add("f6");
      numEntries=source.size();
      for (int j=0; j < numEntries; j++) {
        DFSTestUtil.createFile(hdfs,new Path("/tmp2/" + source.get(j)),4096,3 * 1024 - 100,1024,(short)1,0);
      }
      start=HdfsFileStatus.EMPTY_NAME;
      for (int j=0; j < numEntries / 3; j++) {
        DirectoryListing dl=cluster.getNameNodeRpc().getListing("/tmp2",start,true);
        assertTrue(dl.getPartialListing().length == 3);
        for (int i=0; i < dl.getPartialListing().length; i++) {
          source.remove(dl.getPartialListing()[i].getLocalName());
        }
        start=dl.getLastName();
      }
      assertTrue(source.size() == 0);
    }
  finally {
      if (cluster != null) {
        cluster.shutdown();
      }
    }
  }
  @Test public void testFilesInGetListingOps() throws Exception {
    final Configuration conf=new Configuration();
    MiniDFSCluster cluster=null;
    try {
      cluster=new MiniDFSCluster.Builder(conf).numDataNodes(1).build();
      cluster.waitActive();
      final DistributedFileSystem hdfs=cluster.getFileSystem();
      final FSDirectory fsdir=cluster.getNamesystem().getFSDirectory();
      hdfs.mkdirs(new Path("/tmp"));
      DFSTestUtil.createFile(hdfs,new Path("/tmp/f1"),0,(short)1,0);
      DFSTestUtil.createFile(hdfs,new Path("/tmp/f2"),0,(short)1,0);
      DFSTestUtil.createFile(hdfs,new Path("/tmp/f3"),0,(short)1,0);
      DirectoryListing dl=cluster.getNameNodeRpc().getListing("/tmp",HdfsFileStatus.EMPTY_NAME,false);
      assertTrue(dl.getPartialListing().length == 3);
      String f2=new String("f2");
      dl=cluster.getNameNodeRpc().getListing("/tmp",f2.getBytes(),false);
      assertTrue(dl.getPartialListing().length == 1);
      INode f2INode=fsdir.getINode("/tmp/f2");
      String f2InodePath="/.reserved/.inodes/" + f2INode.getId();
      dl=cluster.getNameNodeRpc().getListing("/tmp",f2InodePath.getBytes(),false);
      assertTrue(dl.getPartialListing().length == 1);
      hdfs.delete(new Path("/tmp/f2"),false);
      try {
        dl=cluster.getNameNodeRpc().getListing("/tmp",f2InodePath.getBytes(),false);
        fail("Didn't get exception for the deleted startAfter token.");
      }
 catch (      IOException e) {
        assertTrue(e instanceof DirectoryListingStartAfterNotFoundException);
      }
    }
  finally {
      if (cluster != null) {
        cluster.shutdown();
      }
    }
  }
  @Test public void testFileUnderConstruction(){
    replication=3;
    final INodeFile file=new INodeFile(HdfsConstants.GRANDFATHER_INODE_ID,null,perm,0L,0L,null,replication,1024L);
    assertFalse(file.isUnderConstruction());
    final String clientName="client";
    final String clientMachine="machine";
    file.toUnderConstruction(clientName,clientMachine);
    assertTrue(file.isUnderConstruction());
    FileUnderConstructionFeature uc=file.getFileUnderConstructionFeature();
    assertEquals(clientName,uc.getClientName());
    assertEquals(clientMachine,uc.getClientMachine());
    toCompleteFile(file);
    assertFalse(file.isUnderConstruction());
  }
  @Test public void testXAttrFeature(){
    replication=3;
    preferredBlockSize=128 * 1024 * 1024;
    INodeFile inf=createINodeFile(replication,preferredBlockSize);
    ImmutableList.Builder<XAttr> builder=new ImmutableList.Builder<XAttr>();
    XAttr xAttr=new XAttr.Builder().setNameSpace(XAttr.NameSpace.USER).setName("a1").setValue(new byte[]{0x31,0x32,0x33}).build();
    builder.add(xAttr);
    XAttrFeature f=new XAttrFeature(builder.build());
    inf.addXAttrFeature(f);
    XAttrFeature f1=inf.getXAttrFeature();
    assertEquals(xAttr,f1.getXAttrs().get(0));
    inf.removeXAttrFeature();
    f1=inf.getXAttrFeature();
    assertEquals(f1,null);
  }
  @Test public void testClearBlocks(){
    INodeFile toBeCleared=createINodeFiles(1,"toBeCleared")[0];
    assertEquals(1,toBeCleared.getBlocks().length);
    toBeCleared.clearBlocks();
    assertTrue(toBeCleared.getBlocks().length == 0);
  }
}
