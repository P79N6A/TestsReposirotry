public class TestHAFsck {
static {
    GenericTestUtils.setLogLevel(DFSUtil.LOG,Level.ALL);
  }
  /** 
 * Test that fsck still works with HA enabled.
 */
  @Test public void testHaFsck() throws Exception {
    Configuration conf=new Configuration();
    MiniDFSNNTopology topology=new MiniDFSNNTopology().addNameservice(new MiniDFSNNTopology.NSConf("ha-nn-uri-0").addNN(new MiniDFSNNTopology.NNConf("nn1").setHttpPort(10051)).addNN(new MiniDFSNNTopology.NNConf("nn2").setHttpPort(10052)));
    MiniDFSCluster cluster=new MiniDFSCluster.Builder(conf).nnTopology(topology).numDataNodes(0).build();
    FileSystem fs=null;
    try {
      cluster.waitActive();
      cluster.transitionToActive(0);
      HATestUtil.setFailoverConfigurations(cluster,conf,"ha-nn-uri-0",0);
      fs=HATestUtil.configureFailoverFs(cluster,conf);
      fs.mkdirs(new Path("/test1"));
      fs.mkdirs(new Path("/test2"));
      runFsck(conf);
      cluster.transitionToStandby(0);
      cluster.transitionToActive(1);
      runFsck(conf);
    }
  finally {
      if (fs != null) {
        fs.close();
      }
      if (cluster != null) {
        cluster.shutdown();
      }
    }
  }
  static void runFsck(  Configuration conf) throws Exception {
    ByteArrayOutputStream bStream=new ByteArrayOutputStream();
    PrintStream out=new PrintStream(bStream,true);
    int errCode=ToolRunner.run(new DFSck(conf,out),new String[]{"/","-files"});
    String result=bStream.toString();
    System.out.println("output from fsck:\n" + result);
    assertEquals(0,errCode);
    assertTrue(result.contains("/test1"));
    assertTrue(result.contains("/test2"));
  }
}
