@RunWith(Parameterized.class) public class TestEditLogTailer {
static {
    GenericTestUtils.setLogLevel(FSEditLog.LOG,org.slf4j.event.Level.DEBUG);
  }
  @Parameters public static Collection<Object[]> data(){
    Collection<Object[]> params=new ArrayList<Object[]>();
    params.add(new Object[]{Boolean.FALSE});
    params.add(new Object[]{Boolean.TRUE});
    return params;
  }
  private static boolean useAsyncEditLog;
  public TestEditLogTailer(  Boolean async){
    useAsyncEditLog=async;
  }
  private static final String DIR_PREFIX="/dir";
  private static final int DIRS_TO_MAKE=20;
  static final long SLEEP_TIME=1000;
  static final long NN_LAG_TIMEOUT=10 * 1000;
static {
    GenericTestUtils.setLogLevel(FSImage.LOG,Level.DEBUG);
    GenericTestUtils.setLogLevel(FSEditLog.LOG,org.slf4j.event.Level.DEBUG);
    GenericTestUtils.setLogLevel(EditLogTailer.LOG,Level.DEBUG);
  }
  private static Configuration getConf(){
    Configuration conf=new HdfsConfiguration();
    conf.setBoolean(DFSConfigKeys.DFS_NAMENODE_EDITS_ASYNC_LOGGING,useAsyncEditLog);
    return conf;
  }
  @Test public void testTailer() throws IOException, InterruptedException, ServiceFailedException {
    Configuration conf=getConf();
    conf.setInt(DFSConfigKeys.DFS_HA_TAILEDITS_PERIOD_KEY,0);
    conf.setInt(DFSConfigKeys.DFS_HA_TAILEDITS_ALL_NAMESNODES_RETRY_KEY,100);
    conf.setLong(EditLogTailer.DFS_HA_TAILEDITS_MAX_TXNS_PER_LOCK_KEY,3);
    HAUtil.setAllowStandbyReads(conf,true);
    MiniDFSCluster cluster=new MiniDFSCluster.Builder(conf).nnTopology(MiniDFSNNTopology.simpleHATopology()).numDataNodes(0).build();
    cluster.waitActive();
    cluster.transitionToActive(0);
    NameNode nn1=cluster.getNameNode(0);
    NameNode nn2=cluster.getNameNode(1);
    try {
      for (int i=0; i < DIRS_TO_MAKE / 2; i++) {
        NameNodeAdapter.mkdirs(nn1,getDirPath(i),new PermissionStatus("test","test",new FsPermission((short)00755)),true);
      }
      HATestUtil.waitForStandbyToCatchUp(nn1,nn2);
      assertEquals("Inconsistent number of applied txns on Standby",nn1.getNamesystem().getEditLog().getLastWrittenTxId(),nn2.getNamesystem().getFSImage().getLastAppliedTxId() + 1);
      for (int i=0; i < DIRS_TO_MAKE / 2; i++) {
        assertTrue(NameNodeAdapter.getFileInfo(nn2,getDirPath(i),false,false,false).isDirectory());
      }
      for (int i=DIRS_TO_MAKE / 2; i < DIRS_TO_MAKE; i++) {
        NameNodeAdapter.mkdirs(nn1,getDirPath(i),new PermissionStatus("test","test",new FsPermission((short)00755)),true);
      }
      HATestUtil.waitForStandbyToCatchUp(nn1,nn2);
      assertEquals("Inconsistent number of applied txns on Standby",nn1.getNamesystem().getEditLog().getLastWrittenTxId(),nn2.getNamesystem().getFSImage().getLastAppliedTxId() + 1);
      for (int i=DIRS_TO_MAKE / 2; i < DIRS_TO_MAKE; i++) {
        assertTrue(NameNodeAdapter.getFileInfo(nn2,getDirPath(i),false,false,false).isDirectory());
      }
    }
  finally {
      cluster.shutdown();
    }
  }
  @Test public void testNN0TriggersLogRolls() throws Exception {
    testStandbyTriggersLogRolls(0);
  }
  @Test public void testNN1TriggersLogRolls() throws Exception {
    testStandbyTriggersLogRolls(1);
  }
  @Test public void testNN2TriggersLogRolls() throws Exception {
    testStandbyTriggersLogRolls(2);
  }
  private static void testStandbyTriggersLogRolls(  int activeIndex) throws Exception {
    Configuration conf=getConf();
    conf.setInt(DFSConfigKeys.DFS_HA_LOGROLL_PERIOD_KEY,1);
    conf.setInt(DFSConfigKeys.DFS_HA_TAILEDITS_PERIOD_KEY,1);
    conf.setInt(DFSConfigKeys.DFS_HA_TAILEDITS_ALL_NAMESNODES_RETRY_KEY,100);
    MiniDFSCluster cluster=null;
    for (int i=0; i < 5; i++) {
      try {
        cluster=createMiniDFSCluster(conf,3);
        break;
      }
 catch (      BindException e) {
        continue;
      }
    }
    if (cluster == null) {
      fail("failed to start mini cluster.");
    }
    try {
      cluster.transitionToActive(activeIndex);
      waitForLogRollInSharedDir(cluster,3);
    }
  finally {
      cluster.shutdown();
    }
  }
  @Test public void testTriggersLogRollsForAllStandbyNN() throws Exception {
    Configuration conf=getConf();
    conf.setInt(DFSConfigKeys.DFS_HA_LOGROLL_PERIOD_KEY,1);
    conf.setInt(DFSConfigKeys.DFS_HA_TAILEDITS_PERIOD_KEY,1);
    conf.setInt(DFSConfigKeys.DFS_HA_TAILEDITS_ALL_NAMESNODES_RETRY_KEY,100);
    MiniDFSCluster cluster=null;
    try {
      cluster=createMiniDFSCluster(conf,3);
      cluster.transitionToStandby(0);
      cluster.transitionToStandby(1);
      cluster.transitionToStandby(2);
      try {
        waitForLogRollInSharedDir(cluster,3);
        fail("After all NN become Standby state, Standby NN should roll log, " + "but it will be failed");
      }
 catch (      TimeoutException ignore) {
      }
      cluster.transitionToActive(0);
      waitForLogRollInSharedDir(cluster,3);
    }
  finally {
      if (cluster != null) {
        cluster.shutdown();
      }
    }
  }
  private static String getDirPath(  int suffix){
    return DIR_PREFIX + suffix;
  }
  private static void waitForLogRollInSharedDir(  MiniDFSCluster cluster,  long startTxId) throws Exception {
    URI sharedUri=cluster.getSharedEditsDir(0,2);
    File sharedDir=new File(sharedUri.getPath(),"current");
    final File expectedInProgressLog=new File(sharedDir,NNStorage.getInProgressEditsFileName(startTxId));
    final File expectedFinalizedLog=new File(sharedDir,NNStorage.getFinalizedEditsFileName(startTxId,startTxId + 1));
    GenericTestUtils.waitFor(new Supplier<Boolean>(){
      @Override public Boolean get(){
        return expectedInProgressLog.exists() || expectedFinalizedLog.exists();
      }
    }
,100,10000);
  }
  @Test(timeout=20000) public void testRollEditTimeoutForActiveNN() throws IOException {
    Configuration conf=getConf();
    conf.setInt(DFSConfigKeys.DFS_HA_TAILEDITS_ROLLEDITS_TIMEOUT_KEY,5);
    conf.setInt(DFSConfigKeys.DFS_HA_TAILEDITS_PERIOD_KEY,1);
    conf.setInt(DFSConfigKeys.DFS_HA_TAILEDITS_ALL_NAMESNODES_RETRY_KEY,100);
    HAUtil.setAllowStandbyReads(conf,true);
    MiniDFSCluster cluster=new MiniDFSCluster.Builder(conf).nnTopology(MiniDFSNNTopology.simpleHATopology()).numDataNodes(0).build();
    cluster.waitActive();
    cluster.transitionToActive(0);
    try {
      EditLogTailer tailer=Mockito.spy(cluster.getNamesystem(1).getEditLogTailer());
      AtomicInteger flag=new AtomicInteger(0);
      when(tailer.getNameNodeProxy()).thenReturn(new Callable<Void>(){
        @Override public Void call() throws Exception {
          Thread.sleep(30000);
          assertTrue(Thread.currentThread().isInterrupted());
          flag.addAndGet(1);
          return null;
        }
      }
);
      tailer.triggerActiveLogRoll();
      assertEquals(0,flag.get());
    }
  finally {
      cluster.shutdown();
    }
  }
  @Test public void testRollEditLogIOExceptionForRemoteNN() throws IOException {
    Configuration conf=getConf();
    conf.setInt(DFSConfigKeys.DFS_HA_LOGROLL_PERIOD_KEY,1);
    conf.setInt(DFSConfigKeys.DFS_HA_TAILEDITS_PERIOD_KEY,1);
    MiniDFSCluster cluster=null;
    try {
      cluster=createMiniDFSCluster(conf,3);
      cluster.transitionToActive(0);
      EditLogTailer tailer=Mockito.spy(cluster.getNamesystem(1).getEditLogTailer());
      final AtomicInteger invokedTimes=new AtomicInteger(0);
      when(tailer.getNameNodeProxy()).thenReturn(tailer.new MultipleNameNodeProxy<Void>(){
        @Override protected Void doWork() throws IOException {
          invokedTimes.getAndIncrement();
          throw new IOException("It is an IO Exception.");
        }
      }
);
      tailer.triggerActiveLogRoll();
      assertEquals(6,invokedTimes.get());
    }
  finally {
      if (cluster != null) {
        cluster.shutdown();
      }
    }
  }
  private static MiniDFSCluster createMiniDFSCluster(  Configuration conf,  int nnCount) throws IOException {
    int basePort=10060 + new Random().nextInt(100) * 2;
    MiniDFSNNTopology topology=MiniDFSNNTopology.simpleHATopology(nnCount,basePort);
    MiniDFSCluster cluster=new MiniDFSCluster.Builder(conf).nnTopology(topology).numDataNodes(0).build();
    return cluster;
  }
}
