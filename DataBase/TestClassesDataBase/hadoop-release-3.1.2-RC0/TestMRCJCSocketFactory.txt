/** 
 * This class checks that RPCs can use specialized socket factories.
 */
public class TestMRCJCSocketFactory {
  /** 
 * Check that we can reach a NameNode or Resource Manager using a specific socket factory
 */
  @Test public void testSocketFactory() throws IOException {
    Configuration sconf=new Configuration();
    MiniDFSCluster cluster=new MiniDFSCluster.Builder(sconf).numDataNodes(1).build();
    final int nameNodePort=cluster.getNameNodePort();
    FileSystem fs=cluster.getFileSystem();
    Assert.assertTrue(fs instanceof DistributedFileSystem);
    DistributedFileSystem directDfs=(DistributedFileSystem)fs;
    Configuration cconf=getCustomSocketConfigs(nameNodePort);
    fs=FileSystem.get(cconf);
    Assert.assertTrue(fs instanceof DistributedFileSystem);
    DistributedFileSystem dfs=(DistributedFileSystem)fs;
    JobClient client=null;
    MiniMRYarnCluster miniMRYarnCluster=null;
    try {
      Path filePath=new Path("/dir");
      Assert.assertFalse(directDfs.exists(filePath));
      Assert.assertFalse(dfs.exists(filePath));
      directDfs.mkdirs(filePath);
      Assert.assertTrue(directDfs.exists(filePath));
      Assert.assertTrue(dfs.exists(filePath));
      fs=FileSystem.get(sconf);
      JobConf jobConf=new JobConf();
      FileSystem.setDefaultUri(jobConf,fs.getUri().toString());
      miniMRYarnCluster=initAndStartMiniMRYarnCluster(jobConf);
      JobConf jconf=new JobConf(miniMRYarnCluster.getConfig());
      jconf.set("hadoop.rpc.socket.factory.class.default","org.apache.hadoop.ipc.DummySocketFactory");
      jconf.set(MRConfig.FRAMEWORK_NAME,MRConfig.YARN_FRAMEWORK_NAME);
      String rmAddress=jconf.get(YarnConfiguration.RM_ADDRESS);
      String[] split=rmAddress.split(":");
      jconf.set(YarnConfiguration.RM_ADDRESS,split[0] + ':' + (Integer.parseInt(split[1]) + 10));
      client=new JobClient(jconf);
      JobStatus[] jobs=client.jobsToComplete();
      Assert.assertTrue(jobs.length == 0);
    }
  finally {
      closeClient(client);
      closeDfs(dfs);
      closeDfs(directDfs);
      stopMiniMRYarnCluster(miniMRYarnCluster);
      shutdownDFSCluster(cluster);
    }
  }
  private MiniMRYarnCluster initAndStartMiniMRYarnCluster(  JobConf jobConf){
    MiniMRYarnCluster miniMRYarnCluster;
    miniMRYarnCluster=new MiniMRYarnCluster(this.getClass().getName(),1);
    miniMRYarnCluster.init(jobConf);
    miniMRYarnCluster.start();
    return miniMRYarnCluster;
  }
  private Configuration getCustomSocketConfigs(  final int nameNodePort){
    Configuration cconf=new Configuration();
    FileSystem.setDefaultUri(cconf,String.format("hdfs://localhost:%s/",nameNodePort + 10));
    cconf.set("hadoop.rpc.socket.factory.class.default","org.apache.hadoop.ipc.DummySocketFactory");
    cconf.set("hadoop.rpc.socket.factory.class.ClientProtocol","org.apache.hadoop.ipc.DummySocketFactory");
    cconf.set("hadoop.rpc.socket.factory.class.JobSubmissionProtocol","org.apache.hadoop.ipc.DummySocketFactory");
    return cconf;
  }
  private void shutdownDFSCluster(  MiniDFSCluster cluster){
    try {
      if (cluster != null)       cluster.shutdown();
    }
 catch (    Exception ignored) {
      ignored.printStackTrace();
    }
  }
  private void stopMiniMRYarnCluster(  MiniMRYarnCluster miniMRYarnCluster){
    try {
      if (miniMRYarnCluster != null)       miniMRYarnCluster.stop();
    }
 catch (    Exception ignored) {
      ignored.printStackTrace();
    }
  }
  private void closeDfs(  DistributedFileSystem dfs){
    try {
      if (dfs != null)       dfs.close();
    }
 catch (    Exception ignored) {
      ignored.printStackTrace();
    }
  }
  private void closeClient(  JobClient client){
    try {
      if (client != null)       client.close();
    }
 catch (    Exception ignored) {
      ignored.printStackTrace();
    }
  }
}
