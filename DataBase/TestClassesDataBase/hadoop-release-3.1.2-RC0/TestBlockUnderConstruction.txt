public class TestBlockUnderConstruction {
  static final String BASE_DIR="/test/TestBlockUnderConstruction";
  static final int BLOCK_SIZE=8192;
  static final int NUM_BLOCKS=5;
  private static MiniDFSCluster cluster;
  private static DistributedFileSystem hdfs;
  @BeforeClass public static void setUp() throws Exception {
    Configuration conf=new HdfsConfiguration();
    cluster=new MiniDFSCluster.Builder(conf).numDataNodes(3).build();
    cluster.waitActive();
    hdfs=cluster.getFileSystem();
  }
  @AfterClass public static void tearDown() throws Exception {
    if (hdfs != null)     hdfs.close();
    if (cluster != null)     cluster.shutdown();
  }
  void writeFile(  Path file,  FSDataOutputStream stm,  int size) throws IOException {
    long blocksBefore=stm.getPos() / BLOCK_SIZE;
    TestFileCreation.writeFile(stm,BLOCK_SIZE);
    stm.flush();
    int blocksAfter=0;
    BlockLocation[] locatedBlocks;
    while (blocksAfter <= blocksBefore) {
      locatedBlocks=DFSClientAdapter.getDFSClient(hdfs).getBlockLocations(file.toString(),0L,BLOCK_SIZE * NUM_BLOCKS);
      blocksAfter=locatedBlocks == null ? 0 : locatedBlocks.length;
    }
  }
  private void verifyFileBlocks(  String file,  boolean isFileOpen) throws IOException {
    FSNamesystem ns=cluster.getNamesystem();
    final INodeFile inode=INodeFile.valueOf(ns.dir.getINode(file),file);
    assertTrue("File " + inode.toString() + " isUnderConstruction = "+ inode.isUnderConstruction()+ " expected to be "+ isFileOpen,inode.isUnderConstruction() == isFileOpen);
    BlockInfo[] blocks=inode.getBlocks();
    assertTrue("File does not have blocks: " + inode.toString(),blocks != null && blocks.length > 0);
    int idx=0;
    BlockInfo curBlock;
    for (; idx < blocks.length - 2; idx++) {
      curBlock=blocks[idx];
      assertTrue("Block is not complete: " + curBlock,curBlock.isComplete());
      assertTrue("Block is not in BlocksMap: " + curBlock,ns.getBlockManager().getStoredBlock(curBlock) == curBlock);
    }
    if (idx > 0) {
      curBlock=blocks[idx - 1];
      assertTrue("Block " + curBlock + " isUnderConstruction = "+ inode.isUnderConstruction()+ " expected to be "+ isFileOpen,(isFileOpen && curBlock.isComplete()) || (!isFileOpen && !curBlock.isComplete() == (curBlock.getBlockUCState() == BlockUCState.COMMITTED)));
      assertTrue("Block is not in BlocksMap: " + curBlock,ns.getBlockManager().getStoredBlock(curBlock) == curBlock);
    }
    curBlock=blocks[idx];
    if (!isFileOpen) {
      assertTrue("Block " + curBlock + ", isFileOpen = "+ isFileOpen,curBlock.isComplete());
    }
    assertTrue("Block is not in BlocksMap: " + curBlock,ns.getBlockManager().getStoredBlock(curBlock) == curBlock);
  }
  @Test public void testBlockCreation() throws IOException {
    Path file1=new Path(BASE_DIR,"file1.dat");
    FSDataOutputStream out=TestFileCreation.createFile(hdfs,file1,3);
    for (int idx=0; idx < NUM_BLOCKS; idx++) {
      writeFile(file1,out,BLOCK_SIZE);
      verifyFileBlocks(file1.toString(),true);
    }
    out.close();
    verifyFileBlocks(file1.toString(),false);
  }
  /** 
 * Test NameNode.getBlockLocations(..) on reading un-closed files.
 */
  @Test public void testGetBlockLocations() throws IOException {
    final NamenodeProtocols namenode=cluster.getNameNodeRpc();
    final BlockManager blockManager=cluster.getNamesystem().getBlockManager();
    final Path p=new Path(BASE_DIR,"file2.dat");
    final String src=p.toString();
    final FSDataOutputStream out=TestFileCreation.createFile(hdfs,p,3);
    int len=BLOCK_SIZE >>> 1;
    writeFile(p,out,len);
    for (int i=1; i < NUM_BLOCKS; ) {
      final LocatedBlocks lb=namenode.getBlockLocations(src,0,len);
      final List<LocatedBlock> blocks=lb.getLocatedBlocks();
      assertEquals(i,blocks.size());
      final Block b=blocks.get(blocks.size() - 1).getBlock().getLocalBlock();
      assertFalse(blockManager.getStoredBlock(b).isComplete());
      if (++i < NUM_BLOCKS) {
        writeFile(p,out,BLOCK_SIZE);
        len+=BLOCK_SIZE;
      }
    }
    out.close();
  }
  /** 
 * A storage ID can be invalid if the storage failed or the node reregisters. When the node heart-beats, the storage report in it causes storage volumes to be added back. An invalid storage ID should not cause an NPE.
 */
  @Test public void testEmptyExpectedLocations() throws Exception {
    final NamenodeProtocols namenode=cluster.getNameNodeRpc();
    final FSNamesystem fsn=cluster.getNamesystem();
    final BlockManager bm=fsn.getBlockManager();
    final Path p=new Path(BASE_DIR,"file2.dat");
    final String src=p.toString();
    final FSDataOutputStream out=TestFileCreation.createFile(hdfs,p,1);
    writeFile(p,out,256);
    out.hflush();
    LocatedBlocks lbs=namenode.getBlockLocations(src,0,256);
    LocatedBlock lastLB=lbs.getLocatedBlocks().get(0);
    final Block b=lastLB.getBlock().getLocalBlock();
    long blockRecoveryId=bm.nextGenerationStamp(false);
    BlockUnderConstructionFeature uc=bm.getStoredBlock(b).getUnderConstructionFeature();
    uc.initializeBlockRecovery(null,blockRecoveryId,false);
    try {
      String[] storages={"invalid-storage-id1"};
      fsn.commitBlockSynchronization(lastLB.getBlock(),blockRecoveryId,256L,true,false,lastLB.getLocations(),storages);
    }
 catch (    java.lang.IllegalStateException ise) {
    }
    lbs=namenode.getBlockLocations(src,0,256);
  }
}
