public class TestReconstructStripedBlocks {
  public static final Logger LOG=LoggerFactory.getLogger(TestReconstructStripedBlocks.class);
  private final ErasureCodingPolicy ecPolicy=StripedFileTestUtil.getDefaultECPolicy();
  private final int cellSize=ecPolicy.getCellSize();
  private final short dataBlocks=(short)ecPolicy.getNumDataUnits();
  private final short parityBlocks=(short)ecPolicy.getNumParityUnits();
  private final short groupSize=(short)(dataBlocks + parityBlocks);
  private final int blockSize=4 * cellSize;
  private MiniDFSCluster cluster;
  private final Path dirPath=new Path("/dir");
  private Path filePath=new Path(dirPath,"file");
  private int maxReplicationStreams=DFSConfigKeys.DFS_NAMENODE_REPLICATION_MAX_STREAMS_DEFAULT;
  private void initConf(  Configuration conf){
    conf.setInt(DFSConfigKeys.DFS_HEARTBEAT_INTERVAL_KEY,100);
    conf.setInt(DFSConfigKeys.DFS_NAMENODE_REPLICATION_WORK_MULTIPLIER_PER_ITERATION,5);
  }
  @Test public void testMissingStripedBlock() throws Exception {
    doTestMissingStripedBlock(1,0);
  }
  @Test public void testMissingStripedBlockWithBusyNode() throws Exception {
    for (int i=1; i <= parityBlocks; i++) {
      doTestMissingStripedBlock(i,1);
    }
  }
  /** 
 * Start GROUP_SIZE + 1 datanodes. Inject striped blocks to first GROUP_SIZE datanodes. Then make numOfBusy datanodes busy, make numOfMissed datanodes missed. Then trigger BlockManager to compute reconstruction works. (so all reconstruction work will be scheduled to the last datanode) Finally, verify the reconstruction work of the last datanode.
 */
  private void doTestMissingStripedBlock(  int numOfMissed,  int numOfBusy) throws Exception {
    Configuration conf=new HdfsConfiguration();
    initConf(conf);
    cluster=new MiniDFSCluster.Builder(conf).numDataNodes(groupSize + 1).build();
    try {
      cluster.waitActive();
      cluster.getFileSystem().enableErasureCodingPolicy(StripedFileTestUtil.getDefaultECPolicy().getName());
      final int numBlocks=4;
      DFSTestUtil.createStripedFile(cluster,filePath,dirPath,numBlocks,1,true);
      final INodeFile fileNode=cluster.getNamesystem().getFSDirectory().getINode4Write(filePath.toString()).asFile();
      assertFalse(fileNode.isUnderConstruction());
      assertTrue(fileNode.isStriped());
      BlockInfo[] blocks=fileNode.getBlocks();
      assertEquals(numBlocks,blocks.length);
      for (      BlockInfo blk : blocks) {
        assertTrue(blk.isStriped());
        assertTrue(blk.isComplete());
        assertEquals(cellSize * dataBlocks,blk.getNumBytes());
        final BlockInfoStriped sb=(BlockInfoStriped)blk;
        assertEquals(groupSize,sb.numNodes());
      }
      final BlockManager bm=cluster.getNamesystem().getBlockManager();
      BlockInfo firstBlock=fileNode.getBlocks()[0];
      DatanodeStorageInfo[] storageInfos=bm.getStorages(firstBlock);
      int i=0;
      for (; i < numOfBusy; i++) {
        DatanodeDescriptor busyNode=storageInfos[i].getDatanodeDescriptor();
        for (int j=0; j < maxReplicationStreams + 1; j++) {
          BlockManagerTestUtil.addBlockToBeReplicated(busyNode,new Block(j),new DatanodeStorageInfo[]{storageInfos[0]});
        }
      }
      for (; i < numOfBusy + numOfMissed; i++) {
        DatanodeDescriptor missedNode=storageInfos[i].getDatanodeDescriptor();
        assertEquals(numBlocks,missedNode.numBlocks());
        bm.getDatanodeManager().removeDatanode(missedNode);
      }
      BlockManagerTestUtil.updateState(bm);
      DFSTestUtil.verifyClientStats(conf,cluster);
      BlockManagerTestUtil.getComputedDatanodeWork(bm);
      DataNode lastDn=cluster.getDataNodes().get(groupSize);
      DatanodeDescriptor last=bm.getDatanodeManager().getDatanode(lastDn.getDatanodeId());
      assertEquals("Counting the number of outstanding EC tasks",numBlocks,last.getNumberOfBlocksToBeErasureCoded());
      List<BlockECReconstructionInfo> reconstruction=last.getErasureCodeCommand(numBlocks);
      for (      BlockECReconstructionInfo info : reconstruction) {
        assertEquals(1,info.getTargetDnInfos().length);
        assertEquals(last,info.getTargetDnInfos()[0]);
        assertEquals(info.getSourceDnInfos().length,info.getLiveBlockIndices().length);
        if (groupSize - numOfMissed == dataBlocks) {
          assertEquals(dataBlocks,info.getSourceDnInfos().length);
        }
 else {
          assertEquals(groupSize - numOfMissed - numOfBusy,info.getSourceDnInfos().length);
        }
      }
      BlockManagerTestUtil.updateState(bm);
      DFSTestUtil.verifyClientStats(conf,cluster);
    }
  finally {
      cluster.shutdown();
    }
  }
  @Test public void test2RecoveryTasksForSameBlockGroup() throws Exception {
    Configuration conf=new HdfsConfiguration();
    conf.setInt(DFSConfigKeys.DFS_HEARTBEAT_INTERVAL_KEY,1000);
    conf.setInt(DFSConfigKeys.DFS_NAMENODE_REDUNDANCY_INTERVAL_SECONDS_KEY,1000);
    conf.setLong(DFSConfigKeys.DFS_BLOCK_SIZE_KEY,blockSize);
    cluster=new MiniDFSCluster.Builder(conf).numDataNodes(groupSize + 2).build();
    try {
      cluster.waitActive();
      DistributedFileSystem fs=cluster.getFileSystem();
      BlockManager bm=cluster.getNamesystem().getBlockManager();
      fs.enableErasureCodingPolicy(StripedFileTestUtil.getDefaultECPolicy().getName());
      fs.getClient().setErasureCodingPolicy("/",StripedFileTestUtil.getDefaultECPolicy().getName());
      int fileLen=dataBlocks * blockSize;
      Path p=new Path("/test2RecoveryTasksForSameBlockGroup");
      final byte[] data=new byte[fileLen];
      DFSTestUtil.writeFile(fs,p,data);
      DFSTestUtil.waitForReplication(fs,p,groupSize,5000);
      BlockManagerTestUtil.updateState(bm);
      DFSTestUtil.verifyClientStats(conf,cluster);
      LocatedStripedBlock lb=(LocatedStripedBlock)fs.getClient().getLocatedBlocks(p.toString(),0).get(0);
      LocatedBlock[] lbs=StripedBlockUtil.parseStripedBlockGroup(lb,cellSize,dataBlocks,parityBlocks);
      BlockManagerTestUtil.getComputedDatanodeWork(bm);
      BlockManagerTestUtil.updateState(bm);
      assertEquals(0,getNumberOfBlocksToBeErasureCoded(cluster));
      assertEquals(0,bm.getPendingReconstructionBlocksCount());
      DFSTestUtil.verifyClientStats(conf,cluster);
      DatanodeInfo dn0=lbs[0].getLocations()[0];
      cluster.stopDataNode(dn0.getName());
      cluster.setDataNodeDead(dn0);
      BlockManagerTestUtil.getComputedDatanodeWork(bm);
      BlockManagerTestUtil.updateState(bm);
      assertEquals(1,getNumberOfBlocksToBeErasureCoded(cluster));
      assertEquals(1,bm.getPendingReconstructionBlocksCount());
      DFSTestUtil.verifyClientStats(conf,cluster);
      DatanodeInfo dn1=lbs[1].getLocations()[0];
      cluster.stopDataNode(dn1.getName());
      cluster.setDataNodeDead(dn1);
      BlockManagerTestUtil.getComputedDatanodeWork(bm);
      BlockManagerTestUtil.updateState(bm);
      assertEquals(1,getNumberOfBlocksToBeErasureCoded(cluster));
      assertEquals(1,bm.getPendingReconstructionBlocksCount());
      DFSTestUtil.verifyClientStats(conf,cluster);
    }
  finally {
      cluster.shutdown();
    }
  }
  private static int getNumberOfBlocksToBeErasureCoded(  MiniDFSCluster cluster) throws Exception {
    DatanodeManager dm=cluster.getNamesystem().getBlockManager().getDatanodeManager();
    int count=0;
    for (    DataNode dn : cluster.getDataNodes()) {
      DatanodeDescriptor dd=dm.getDatanode(dn.getDatanodeId());
      count+=dd.getNumberOfBlocksToBeErasureCoded();
    }
    return count;
  }
  /** 
 * make sure the NN can detect the scenario where there are enough number of internal blocks (>=9 by default) but there is still missing data/parity block.
 */
  @Test public void testCountLiveReplicas() throws Exception {
    final HdfsConfiguration conf=new HdfsConfiguration();
    conf.setInt(DFSConfigKeys.DFS_NAMENODE_REDUNDANCY_INTERVAL_SECONDS_KEY,1);
    conf.setBoolean(DFSConfigKeys.DFS_NAMENODE_REDUNDANCY_CONSIDERLOAD_KEY,false);
    cluster=new MiniDFSCluster.Builder(conf).numDataNodes(groupSize + 2).build();
    cluster.waitActive();
    DistributedFileSystem fs=cluster.getFileSystem();
    fs.enableErasureCodingPolicy(StripedFileTestUtil.getDefaultECPolicy().getName());
    try {
      fs.mkdirs(dirPath);
      fs.setErasureCodingPolicy(dirPath,StripedFileTestUtil.getDefaultECPolicy().getName());
      DFSTestUtil.createFile(fs,filePath,cellSize * dataBlocks * 2,(short)1,0L);
      LocatedBlocks blks=fs.getClient().getLocatedBlocks(filePath.toString(),0);
      LocatedStripedBlock block=(LocatedStripedBlock)blks.getLastLocatedBlock();
      DatanodeInfo dnToStop=block.getLocations()[0];
      MiniDFSCluster.DataNodeProperties dnProp=cluster.stopDataNode(dnToStop.getXferAddr());
      cluster.setDataNodeDead(dnToStop);
      DFSTestUtil.waitForReplication(fs,filePath,groupSize,15 * 1000);
      cluster.restartDataNode(dnProp);
      cluster.waitActive();
      DFSTestUtil.verifyClientStats(conf,cluster);
      dnToStop=block.getLocations()[1];
      cluster.stopDataNode(dnToStop.getXferAddr());
      cluster.setDataNodeDead(dnToStop);
      cluster.restartNameNode(true);
      for (      DataNode dn : cluster.getDataNodes()) {
        DataNodeTestUtils.triggerBlockReport(dn);
      }
      FSNamesystem fsn=cluster.getNamesystem();
      BlockManager bm=fsn.getBlockManager();
      Thread.sleep(3000);
      for (      DataNode dn : cluster.getDataNodes()) {
        DataNodeTestUtils.triggerHeartbeat(dn);
      }
      StripedFileTestUtil.waitForReconstructionFinished(filePath,fs,groupSize);
      boolean reconstructed=false;
      for (int i=0; i < 5; i++) {
        NumberReplicas num=null;
        fsn.readLock();
        try {
          BlockInfo blockInfo=cluster.getNamesystem().getFSDirectory().getINode4Write(filePath.toString()).asFile().getLastBlock();
          num=bm.countNodes(blockInfo);
        }
  finally {
          fsn.readUnlock();
        }
        if (num.liveReplicas() >= groupSize) {
          reconstructed=true;
          break;
        }
 else {
          Thread.sleep(1000);
        }
      }
      Assert.assertTrue(reconstructed);
      blks=fs.getClient().getLocatedBlocks(filePath.toString(),0);
      block=(LocatedStripedBlock)blks.getLastLocatedBlock();
      BitSet bitSet=new BitSet(groupSize);
      for (      byte index : block.getBlockIndices()) {
        bitSet.set(index);
      }
      for (int i=0; i < groupSize; i++) {
        Assert.assertTrue(bitSet.get(i));
      }
    }
  finally {
      cluster.shutdown();
    }
  }
  @Test(timeout=120000) public void testReconstructionWork() throws Exception {
    Configuration conf=new HdfsConfiguration();
    conf.setLong(DFSConfigKeys.DFS_NAMENODE_MIN_BLOCK_SIZE_KEY,0);
    conf.setLong(DFSConfigKeys.DFS_BLOCK_SIZE_KEY,1);
    conf.setInt(DFSConfigKeys.DFS_BYTES_PER_CHECKSUM_KEY,1);
    conf.setInt(DFSConfigKeys.DFS_HEARTBEAT_INTERVAL_KEY,1000);
    conf.setInt(DFSConfigKeys.DFS_NAMENODE_REDUNDANCY_INTERVAL_SECONDS_KEY,1000);
    conf.setInt(DFSConfigKeys.DFS_NAMENODE_REPLICATION_WORK_MULTIPLIER_PER_ITERATION,5);
    ErasureCodingPolicy policy=SystemErasureCodingPolicies.getByID(SystemErasureCodingPolicies.XOR_2_1_POLICY_ID);
    Path ecDir=new Path("/ec");
    Path ecFilePath=new Path(ecDir,"ec-file");
    int blockGroups=2;
    int totalDataNodes=policy.getNumDataUnits() + policy.getNumParityUnits() + 1;
    MiniDFSCluster dfsCluster=new MiniDFSCluster.Builder(conf).numDataNodes(totalDataNodes).build();
    try {
      final DistributedFileSystem fs=dfsCluster.getFileSystem();
      fs.enableErasureCodingPolicy(policy.getName());
      fs.mkdirs(ecDir);
      fs.setErasureCodingPolicy(ecDir,policy.getName());
      DFSTestUtil.createStripedFile(dfsCluster,ecFilePath,ecDir,blockGroups,2,false,policy);
      final BlockManager bm=dfsCluster.getNamesystem().getBlockManager();
      LocatedBlocks lbs=fs.getClient().getNamenode().getBlockLocations(ecFilePath.toString(),0,blockGroups);
      assert lbs.get(0) instanceof LocatedStripedBlock;
      LocatedStripedBlock bg=(LocatedStripedBlock)(lbs.get(0));
      Iterator<DatanodeStorageInfo> storageInfos=bm.getStorages(bg.getBlock().getLocalBlock()).iterator();
      DatanodeDescriptor firstDn=storageInfos.next().getDatanodeDescriptor();
      BlockManagerTestUtil.updateState(bm);
      DFSTestUtil.verifyClientStats(conf,dfsCluster);
      bm.getDatanodeManager().removeDatanode(firstDn);
      BlockManagerTestUtil.updateState(bm);
      assertEquals(blockGroups,bm.getLowRedundancyECBlockGroups());
      DFSTestUtil.verifyClientStats(conf,dfsCluster);
      BlockManagerTestUtil.getComputedDatanodeWork(bm);
      BlockManagerTestUtil.updateState(bm);
      assertEquals(blockGroups,getNumberOfBlocksToBeErasureCoded(dfsCluster));
      assertEquals(0,bm.getLowRedundancyECBlockGroups());
      DFSTestUtil.verifyClientStats(conf,dfsCluster);
    }
  finally {
      dfsCluster.shutdown();
    }
  }
}
