/** 
 * Tests context api and  {@link StatusReporter#getProgress()} via {@link TaskAttemptContext#getProgress()} API . 
 */
@Ignore public class TestTaskContext extends HadoopTestCase {
  private static final Path rootTempDir=new Path(System.getProperty("test.build.data","/tmp"));
  private static final Path testRootTempDir=new Path(rootTempDir,"TestTaskContext");
  private static FileSystem fs=null;
  @BeforeClass public static void setup() throws Exception {
    fs=FileSystem.getLocal(new Configuration());
    fs.delete(testRootTempDir,true);
    fs.mkdirs(testRootTempDir);
  }
  @AfterClass public static void cleanup() throws Exception {
    fs.delete(testRootTempDir,true);
  }
  public TestTaskContext() throws IOException {
    super(HadoopTestCase.CLUSTER_MR,HadoopTestCase.LOCAL_FS,1,1);
  }
  static String myStatus="my status";
static class MyMapper extends Mapper<LongWritable,Text,LongWritable,Text> {
    @Override protected void setup(    Context context) throws IOException {
      context.setStatus(myStatus);
      assertEquals(myStatus,context.getStatus());
    }
  }
  /** 
 * Tests context.setStatus method. TODO fix testcase
 * @throws IOException
 * @throws InterruptedException
 * @throws ClassNotFoundException
 */
  @Test @Ignore public void testContextStatus() throws IOException, InterruptedException, ClassNotFoundException {
    Path test=new Path(testRootTempDir,"testContextStatus");
    int numMaps=1;
    Job job=MapReduceTestUtil.createJob(createJobConf(),new Path(test,"in"),new Path(test,"out"),numMaps,0);
    job.setMapperClass(MyMapper.class);
    job.waitForCompletion(true);
    assertTrue("Job failed",job.isSuccessful());
    TaskReport[] reports=job.getTaskReports(TaskType.MAP);
    assertEquals(numMaps,reports.length);
    assertEquals(myStatus,reports[0].getState());
    int numReduces=1;
    job=MapReduceTestUtil.createJob(createJobConf(),new Path(test,"in"),new Path(test,"out"),numMaps,numReduces);
    job.setMapperClass(DataCopyMapper.class);
    job.setReducerClass(DataCopyReducer.class);
    job.setMapOutputKeyClass(Text.class);
    job.setMapOutputValueClass(Text.class);
    job.setOutputKeyClass(Text.class);
    job.setOutputValueClass(Text.class);
    job.setMaxMapAttempts(1);
    job.setMaxReduceAttempts(0);
    job.waitForCompletion(true);
    assertTrue("Job failed",job.isSuccessful());
  }
  private static final String INPUT="Hi\nHi\nHi\nHi\n";
  private static final int INPUT_LINES=INPUT.split("\n").length;
@SuppressWarnings("unchecked") static class ProgressCheckerMapper extends Mapper<LongWritable,Text,Text,Text> {
    private int recordCount=0;
    private float progressRange=0;
    @Override protected void setup(    Context context) throws IOException {
      assertEquals("Invalid progress in map setup",0.0f,context.getProgress(),0f);
      if (context.getNumReduceTasks() == 0) {
        progressRange=1f;
      }
 else {
        progressRange=0.667f;
      }
    }
    @Override protected void map(    LongWritable key,    Text value,    org.apache.hadoop.mapreduce.Mapper.Context context) throws IOException, InterruptedException {
      float mapPhaseProgress=((float)++recordCount) / INPUT_LINES;
      float weightedMapProgress=progressRange * mapPhaseProgress;
      assertEquals("Invalid progress in map",weightedMapProgress,context.getProgress(),0f);
      context.write(new Text(value.toString() + recordCount),value);
    }
    protected void cleanup(    Mapper.Context context) throws IOException, InterruptedException {
      assertEquals("Invalid progress in map cleanup",progressRange,context.getProgress(),0f);
    }
  }
  /** 
 * Tests new MapReduce map task's context.getProgress() method.
 * @throws IOException
 * @throws InterruptedException
 * @throws ClassNotFoundException
 */
  public void testMapContextProgress() throws IOException, InterruptedException, ClassNotFoundException {
    int numMaps=1;
    Path test=new Path(testRootTempDir,"testMapContextProgress");
    Job job=MapReduceTestUtil.createJob(createJobConf(),new Path(test,"in"),new Path(test,"out"),numMaps,0,INPUT);
    job.setMapperClass(ProgressCheckerMapper.class);
    job.setMapOutputKeyClass(Text.class);
    job.setMaxMapAttempts(1);
    job.waitForCompletion(true);
    assertTrue("Job failed",job.isSuccessful());
  }
@SuppressWarnings("unchecked") static class ProgressCheckerReducer extends Reducer<Text,Text,Text,Text> {
    private int recordCount=0;
    private final float REDUCE_PROGRESS_RANGE=1.0f / 3;
    private final float SHUFFLE_PROGRESS_RANGE=1 - REDUCE_PROGRESS_RANGE;
    protected void setup(    final Reducer.Context context) throws IOException, InterruptedException {
      float reducePhaseProgress=((float)++recordCount) / INPUT_LINES;
      float weightedReducePhaseProgress=REDUCE_PROGRESS_RANGE * reducePhaseProgress;
      assertEquals("Invalid progress in reduce setup",SHUFFLE_PROGRESS_RANGE + weightedReducePhaseProgress,context.getProgress(),0.01f);
    }
    public void reduce(    Text key,    Iterator<Text> values,    Context context) throws IOException, InterruptedException {
      float reducePhaseProgress=((float)++recordCount) / INPUT_LINES;
      float weightedReducePhaseProgress=REDUCE_PROGRESS_RANGE * reducePhaseProgress;
      assertEquals("Invalid progress in reduce",SHUFFLE_PROGRESS_RANGE + weightedReducePhaseProgress,context.getProgress(),0.01f);
    }
    protected void cleanup(    Reducer.Context context) throws IOException, InterruptedException {
      assertEquals("Invalid progress in reduce cleanup",1.0f,context.getProgress(),0f);
    }
  }
  /** 
 * Tests new MapReduce reduce task's context.getProgress() method.
 * @throws IOException
 * @throws InterruptedException
 * @throws ClassNotFoundException
 */
  @Test public void testReduceContextProgress() throws IOException, InterruptedException, ClassNotFoundException {
    int numTasks=1;
    Path test=new Path(testRootTempDir,"testReduceContextProgress");
    Job job=MapReduceTestUtil.createJob(createJobConf(),new Path(test,"in"),new Path(test,"out"),numTasks,numTasks,INPUT);
    job.setMapperClass(ProgressCheckerMapper.class);
    job.setReducerClass(ProgressCheckerReducer.class);
    job.setMapOutputKeyClass(Text.class);
    job.setMaxMapAttempts(1);
    job.setMaxReduceAttempts(1);
    job.waitForCompletion(true);
    assertTrue("Job failed",job.isSuccessful());
  }
}
