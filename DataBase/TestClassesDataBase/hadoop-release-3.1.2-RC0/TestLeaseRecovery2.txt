public class TestLeaseRecovery2 {
  public static final Log LOG=LogFactory.getLog(TestLeaseRecovery2.class);
{
    GenericTestUtils.setLogLevel(DataNode.LOG,Level.TRACE);
    GenericTestUtils.setLogLevel(LeaseManager.LOG,Level.TRACE);
    GenericTestUtils.setLogLevel(FSNamesystem.LOG,Level.TRACE);
  }
  static final private long BLOCK_SIZE=1024;
  static final private int FILE_SIZE=(int)BLOCK_SIZE * 2;
  static final short REPLICATION_NUM=(short)3;
  static final byte[] buffer=new byte[FILE_SIZE];
  static private final String fakeUsername="fakeUser1";
  static private final String fakeGroup="supergroup";
  static private MiniDFSCluster cluster;
  static private DistributedFileSystem dfs;
  final static private Configuration conf=new HdfsConfiguration();
  final static private int BUF_SIZE=conf.getInt(CommonConfigurationKeys.IO_FILE_BUFFER_SIZE_KEY,4096);
  final static private long SHORT_LEASE_PERIOD=1000L;
  final static private long LONG_LEASE_PERIOD=60 * 60 * SHORT_LEASE_PERIOD;
  /** 
 * start a dfs cluster
 * @throws IOException
 */
  @Before public void startUp() throws IOException {
    conf.setLong(DFSConfigKeys.DFS_BLOCK_SIZE_KEY,BLOCK_SIZE);
    conf.setInt(DFSConfigKeys.DFS_HEARTBEAT_INTERVAL_KEY,1);
    cluster=new MiniDFSCluster.Builder(conf).numDataNodes(5).checkExitOnShutdown(false).build();
    cluster.waitActive();
    dfs=cluster.getFileSystem();
  }
  /** 
 * stop the cluster
 * @throws IOException
 */
  @After public void tearDown() throws IOException {
    if (cluster != null) {
      IOUtils.closeStream(dfs);
      cluster.shutdown();
    }
  }
  /** 
 * Test the NameNode's revoke lease on current lease holder function.
 * @throws Exception
 */
  @Test public void testImmediateRecoveryOfLease() throws Exception {
    byte[] actual=new byte[FILE_SIZE];
    int size=AppendTestUtil.nextInt(FILE_SIZE);
    Path filepath=createFile("/immediateRecoverLease-shortlease",size,true);
    cluster.setLeasePeriod(SHORT_LEASE_PERIOD,LONG_LEASE_PERIOD);
    recoverLeaseUsingCreate(filepath);
    verifyFile(dfs,filepath,actual,size);
    cluster.setLeasePeriod(LONG_LEASE_PERIOD,LONG_LEASE_PERIOD);
    size=AppendTestUtil.nextInt(FILE_SIZE);
    filepath=createFile("/immediateRecoverLease-longlease",size,false);
    recoverLease(filepath,null);
    verifyFile(dfs,filepath,actual,size);
    size=AppendTestUtil.nextInt(FILE_SIZE);
    filepath=createFile("/immediateRecoverLease-sameclient",size,false);
    Path filepath1=new Path(filepath.toString() + AppendTestUtil.nextInt());
    FSDataOutputStream stm=dfs.create(filepath1,true,BUF_SIZE,REPLICATION_NUM,BLOCK_SIZE);
    recoverLease(filepath,dfs);
    verifyFile(dfs,filepath,actual,size);
    stm.write(buffer,0,size);
    stm.close();
    verifyFile(dfs,filepath1,actual,size);
  }
  @Test public void testCloseWhileRecoverLease() throws Exception {
    cluster.setLeasePeriod(LONG_LEASE_PERIOD,LONG_LEASE_PERIOD);
    int size=AppendTestUtil.nextInt(FILE_SIZE);
    String filestr="/testCloseWhileRecoverLease";
    AppendTestUtil.LOG.info("filestr=" + filestr);
    Path filepath=new Path(filestr);
    FSDataOutputStream stm=dfs.create(filepath,true,BUF_SIZE,REPLICATION_NUM,BLOCK_SIZE);
    assertTrue(dfs.dfs.exists(filestr));
    AppendTestUtil.LOG.info("hflush");
    stm.hflush();
    ArrayList<DataNode> dataNodes=cluster.getDataNodes();
    for (    DataNode dn : dataNodes) {
      DataNodeTestUtils.setHeartbeatsDisabledForTests(dn,false);
    }
    LOG.info("pause IBR");
    for (    DataNode dn : dataNodes) {
      DataNodeTestUtils.pauseIBR(dn);
    }
    AppendTestUtil.LOG.info("size=" + size);
    stm.write(buffer,0,size);
    AppendTestUtil.LOG.info("hflush");
    stm.hflush();
    LOG.info("recover lease");
    dfs.recoverLease(filepath);
    try {
      stm.close();
      fail("close() should fail because the file is under recovery.");
    }
 catch (    IOException ioe) {
      GenericTestUtils.assertExceptionContains("whereas it is under recovery",ioe);
    }
    for (    DataNode dn : dataNodes) {
      DataNodeTestUtils.setHeartbeatsDisabledForTests(dn,false);
    }
    LOG.info("trigger heartbeats");
    for (    DataNode dn : dataNodes) {
      DataNodeTestUtils.triggerHeartbeat(dn);
    }
    stm.close();
    assertEquals(cluster.getNamesystem().getBlockManager().getMissingBlocksCount(),0);
  }
  @Test public void testLeaseRecoverByAnotherUser() throws Exception {
    byte[] actual=new byte[FILE_SIZE];
    cluster.setLeasePeriod(SHORT_LEASE_PERIOD,LONG_LEASE_PERIOD);
    Path filepath=createFile("/immediateRecoverLease-x",0,true);
    recoverLeaseUsingCreate2(filepath);
    verifyFile(dfs,filepath,actual,0);
  }
  private Path createFile(  final String filestr,  final int size,  final boolean triggerLeaseRenewerInterrupt) throws IOException, InterruptedException {
    AppendTestUtil.LOG.info("filestr=" + filestr);
    Path filepath=new Path(filestr);
    FSDataOutputStream stm=dfs.create(filepath,true,BUF_SIZE,REPLICATION_NUM,BLOCK_SIZE);
    assertTrue(dfs.dfs.exists(filestr));
    AppendTestUtil.LOG.info("size=" + size);
    stm.write(buffer,0,size);
    AppendTestUtil.LOG.info("hflush");
    stm.hflush();
    if (triggerLeaseRenewerInterrupt) {
      AppendTestUtil.LOG.info("leasechecker.interruptAndJoin()");
      dfs.dfs.getLeaseRenewer().interruptAndJoin();
    }
    return filepath;
  }
  private void recoverLease(  Path filepath,  DistributedFileSystem dfs) throws Exception {
    if (dfs == null) {
      dfs=(DistributedFileSystem)getFSAsAnotherUser(conf);
    }
    while (!dfs.recoverLease(filepath)) {
      AppendTestUtil.LOG.info("sleep " + 5000 + "ms");
      Thread.sleep(5000);
    }
  }
  private FileSystem getFSAsAnotherUser(  final Configuration c) throws IOException, InterruptedException {
    return FileSystem.get(FileSystem.getDefaultUri(c),c,UserGroupInformation.createUserForTesting(fakeUsername,new String[]{fakeGroup}).getUserName());
  }
  private void recoverLeaseUsingCreate(  Path filepath) throws IOException, InterruptedException {
    FileSystem dfs2=getFSAsAnotherUser(conf);
    for (int i=0; i < 10; i++) {
      AppendTestUtil.LOG.info("i=" + i);
      try {
        dfs2.create(filepath,false,BUF_SIZE,(short)1,BLOCK_SIZE);
        fail("Creation of an existing file should never succeed.");
      }
 catch (      FileAlreadyExistsException e) {
        return;
      }
catch (      AlreadyBeingCreatedException e) {
        return;
      }
catch (      IOException ioe) {
        AppendTestUtil.LOG.warn("UNEXPECTED ",ioe);
        AppendTestUtil.LOG.info("sleep " + 5000 + "ms");
        try {
          Thread.sleep(5000);
        }
 catch (        InterruptedException e) {
        }
      }
    }
    fail("recoverLeaseUsingCreate failed");
  }
  private void recoverLeaseUsingCreate2(  Path filepath) throws Exception {
    FileSystem dfs2=getFSAsAnotherUser(conf);
    int size=AppendTestUtil.nextInt(FILE_SIZE);
    DistributedFileSystem dfsx=(DistributedFileSystem)dfs2;
    Path filepath2=new Path("/immediateRecoverLease-x2");
    FSDataOutputStream stm=dfsx.create(filepath2,true,BUF_SIZE,REPLICATION_NUM,BLOCK_SIZE);
    assertTrue(dfsx.dfs.exists("/immediateRecoverLease-x2"));
    try {
      Thread.sleep(10000);
    }
 catch (    InterruptedException e) {
    }
    dfsx.append(filepath);
  }
  private void verifyFile(  FileSystem dfs,  Path filepath,  byte[] actual,  int size) throws IOException {
    AppendTestUtil.LOG.info("Lease for file " + filepath + " is recovered. "+ "Validating its contents now...");
    assertTrue("File should be " + size + " bytes, but is actually "+ " found to be "+ dfs.getFileStatus(filepath).getLen()+ " bytes",dfs.getFileStatus(filepath).getLen() == size);
    System.out.println("File size is good. Now validating sizes from datanodes...");
    FSDataInputStream stmin=dfs.open(filepath);
    stmin.readFully(0,actual,0,size);
    stmin.close();
  }
  /** 
 * This test makes the client does not renew its lease and also set the hard lease expiration period to be short 1s. Thus triggering lease expiration to happen while the client is still alive. The test makes sure that the lease recovery completes and the client fails if it continues to write to the file.
 * @throws Exception
 */
  @Test public void testHardLeaseRecovery() throws Exception {
    String filestr="/hardLeaseRecovery";
    AppendTestUtil.LOG.info("filestr=" + filestr);
    Path filepath=new Path(filestr);
    FSDataOutputStream stm=dfs.create(filepath,true,BUF_SIZE,REPLICATION_NUM,BLOCK_SIZE);
    assertTrue(dfs.dfs.exists(filestr));
    int size=AppendTestUtil.nextInt(FILE_SIZE);
    AppendTestUtil.LOG.info("size=" + size);
    stm.write(buffer,0,size);
    AppendTestUtil.LOG.info("hflush");
    stm.hflush();
    AppendTestUtil.LOG.info("leasechecker.interruptAndJoin()");
    dfs.dfs.getLeaseRenewer().interruptAndJoin();
    cluster.setLeasePeriod(LONG_LEASE_PERIOD,SHORT_LEASE_PERIOD);
    LocatedBlocks locatedBlocks;
    do {
      Thread.sleep(SHORT_LEASE_PERIOD);
      locatedBlocks=dfs.dfs.getLocatedBlocks(filestr,0L,size);
    }
 while (locatedBlocks.isUnderConstruction());
    assertEquals(size,locatedBlocks.getFileLength());
    try {
      stm.write('b');
      stm.close();
      fail("Writer thread should have been killed");
    }
 catch (    IOException e) {
      e.printStackTrace();
    }
    AppendTestUtil.LOG.info("File size is good. Now validating sizes from datanodes...");
    AppendTestUtil.checkFullFile(dfs,filepath,size,buffer,filestr);
  }
  /** 
 * This test makes the client does not renew its lease and also set the soft lease expiration period to be short 1s. Thus triggering soft lease expiration to happen immediately by having another client trying to create the same file. The test makes sure that the lease recovery completes.
 * @throws Exception
 */
  @Test public void testSoftLeaseRecovery() throws Exception {
    Map<String,String[]> u2g_map=new HashMap<String,String[]>(1);
    u2g_map.put(fakeUsername,new String[]{fakeGroup});
    DFSTestUtil.updateConfWithFakeGroupMapping(conf,u2g_map);
    cluster.setLeasePeriod(HdfsConstants.LEASE_SOFTLIMIT_PERIOD,HdfsConstants.LEASE_HARDLIMIT_PERIOD);
    String filestr="/foo" + AppendTestUtil.nextInt();
    AppendTestUtil.LOG.info("filestr=" + filestr);
    Path filepath=new Path(filestr);
    FSDataOutputStream stm=dfs.create(filepath,true,BUF_SIZE,REPLICATION_NUM,BLOCK_SIZE);
    assertTrue(dfs.dfs.exists(filestr));
    int size=AppendTestUtil.nextInt(FILE_SIZE);
    AppendTestUtil.LOG.info("size=" + size);
    stm.write(buffer,0,size);
    AppendTestUtil.LOG.info("hflush");
    stm.hflush();
    AppendTestUtil.LOG.info("leasechecker.interruptAndJoin()");
    dfs.dfs.getLeaseRenewer().interruptAndJoin();
    cluster.setLeasePeriod(SHORT_LEASE_PERIOD,LONG_LEASE_PERIOD);
{
      UserGroupInformation ugi=UserGroupInformation.createUserForTesting(fakeUsername,new String[]{fakeGroup});
      FileSystem dfs2=DFSTestUtil.getFileSystemAs(ugi,conf);
      boolean done=false;
      for (int i=0; i < 10 && !done; i++) {
        AppendTestUtil.LOG.info("i=" + i);
        try {
          dfs2.create(filepath,false,BUF_SIZE,REPLICATION_NUM,BLOCK_SIZE);
          fail("Creation of an existing file should never succeed.");
        }
 catch (        FileAlreadyExistsException ex) {
          done=true;
        }
catch (        AlreadyBeingCreatedException ex) {
          AppendTestUtil.LOG.info("GOOD! got " + ex.getMessage());
        }
catch (        IOException ioe) {
          AppendTestUtil.LOG.warn("UNEXPECTED IOException",ioe);
        }
        if (!done) {
          AppendTestUtil.LOG.info("sleep " + 5000 + "ms");
          try {
            Thread.sleep(5000);
          }
 catch (          InterruptedException e) {
          }
        }
      }
      assertTrue(done);
    }
    AppendTestUtil.LOG.info("Lease for file " + filepath + " is recovered. "+ "Validating its contents now...");
    long fileSize=dfs.getFileStatus(filepath).getLen();
    assertTrue("File should be " + size + " bytes, but is actually "+ " found to be "+ fileSize+ " bytes",fileSize == size);
    AppendTestUtil.LOG.info("File size is good. " + "Now validating data and sizes from datanodes...");
    AppendTestUtil.checkFullFile(dfs,filepath,size,buffer,filestr);
  }
  /** 
 * This test makes it so the client does not renew its lease and also set the hard lease expiration period to be short, thus triggering lease expiration to happen while the client is still alive. The test also causes the NN to restart after lease recovery has begun, but before the DNs have completed the blocks. This test verifies that when the NN comes back up, the client no longer holds the lease. The test makes sure that the lease recovery completes and the client fails if it continues to write to the file, even after NN restart.
 * @throws Exception
 */
  @Test(timeout=30000) public void testHardLeaseRecoveryAfterNameNodeRestart() throws Exception {
    hardLeaseRecoveryRestartHelper(false,-1);
  }
  @Test(timeout=30000) public void testHardLeaseRecoveryAfterNameNodeRestart2() throws Exception {
    hardLeaseRecoveryRestartHelper(false,1535);
  }
  @Test(timeout=30000) public void testHardLeaseRecoveryWithRenameAfterNameNodeRestart() throws Exception {
    hardLeaseRecoveryRestartHelper(true,-1);
  }
  public void hardLeaseRecoveryRestartHelper(  boolean doRename,  int size) throws Exception {
    if (size < 0) {
      size=AppendTestUtil.nextInt(FILE_SIZE + 1);
    }
    String fileStr="/hardLeaseRecovery";
    AppendTestUtil.LOG.info("filestr=" + fileStr);
    Path filePath=new Path(fileStr);
    FSDataOutputStream stm=dfs.create(filePath,true,BUF_SIZE,REPLICATION_NUM,BLOCK_SIZE);
    assertTrue(dfs.dfs.exists(fileStr));
    AppendTestUtil.LOG.info("size=" + size);
    stm.write(buffer,0,size);
    String originalLeaseHolder=NameNodeAdapter.getLeaseHolderForPath(cluster.getNameNode(),fileStr);
    assertFalse("original lease holder should not be the NN",originalLeaseHolder.startsWith(HdfsServerConstants.NAMENODE_LEASE_HOLDER));
    AppendTestUtil.LOG.info("hflush");
    stm.hflush();
    final HdfsDataInputStream in=(HdfsDataInputStream)dfs.open(filePath);
    Assert.assertEquals(size,in.getVisibleLength());
    in.close();
    if (doRename) {
      fileStr+=".renamed";
      Path renamedPath=new Path(fileStr);
      assertTrue(dfs.rename(filePath,renamedPath));
      filePath=renamedPath;
    }
    AppendTestUtil.LOG.info("leasechecker.interruptAndJoin()");
    dfs.dfs.getLeaseRenewer().interruptAndJoin();
    for (    DataNode dn : cluster.getDataNodes()) {
      DataNodeTestUtils.setHeartbeatsDisabledForTests(dn,true);
    }
    cluster.setLeasePeriod(LONG_LEASE_PERIOD,SHORT_LEASE_PERIOD);
    final String path=fileStr;
    GenericTestUtils.waitFor(new Supplier<Boolean>(){
      @Override public Boolean get(){
        String holder=NameNodeAdapter.getLeaseHolderForPath(cluster.getNameNode(),path);
        return holder.startsWith(HdfsServerConstants.NAMENODE_LEASE_HOLDER);
      }
    }
,(int)SHORT_LEASE_PERIOD,(int)SHORT_LEASE_PERIOD * 10);
    FSEditLog spyLog=spy(cluster.getNameNode().getFSImage().getEditLog());
    doNothing().when(spyLog).endCurrentLogSegment(Mockito.anyBoolean());
    DFSTestUtil.setEditLogForTesting(cluster.getNamesystem(),spyLog);
    cluster.restartNameNode(false);
    checkLease(fileStr,size);
    for (    DataNode dn : cluster.getDataNodes()) {
      DataNodeTestUtils.setHeartbeatsDisabledForTests(dn,false);
    }
    cluster.waitActive();
    cluster.setLeasePeriod(LONG_LEASE_PERIOD,SHORT_LEASE_PERIOD);
    LocatedBlocks locatedBlocks;
    do {
      Thread.sleep(SHORT_LEASE_PERIOD);
      locatedBlocks=dfs.dfs.getLocatedBlocks(fileStr,0L,size);
    }
 while (locatedBlocks.isUnderConstruction());
    assertEquals(size,locatedBlocks.getFileLength());
    try {
      stm.write('b');
      stm.hflush();
      fail("Should not be able to flush after we've lost the lease");
    }
 catch (    IOException e) {
      LOG.info("Expceted exception on write/hflush",e);
    }
    try {
      stm.close();
      fail("Should not be able to close after we've lost the lease");
    }
 catch (    IOException e) {
      LOG.info("Expected exception on close",e);
    }
    AppendTestUtil.LOG.info("File size is good. Now validating sizes from datanodes...");
    AppendTestUtil.checkFullFile(dfs,filePath,size,buffer,fileStr);
  }
  static void checkLease(  String f,  int size){
    final String holder=NameNodeAdapter.getLeaseHolderForPath(cluster.getNameNode(),f);
    if (size == 0) {
      assertEquals("lease holder should null, file is closed",null,holder);
    }
 else {
      assertTrue("lease holder should now be the NN",holder.startsWith(HdfsServerConstants.NAMENODE_LEASE_HOLDER));
    }
  }
}
