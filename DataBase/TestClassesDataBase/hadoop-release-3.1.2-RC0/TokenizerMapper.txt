/** 
 * Test mapper.
 */
public static class TokenizerMapper extends org.apache.hadoop.mapreduce.Mapper<Object,Text,Text,IntWritable> {
  private final static IntWritable ONE=new IntWritable(1);
  private Text word=new Text();
  public void map(  Object key,  Text value,  Context context) throws IOException, InterruptedException {
    StringTokenizer itr=new StringTokenizer(value.toString());
    while (itr.hasMoreTokens()) {
      word.set(itr.nextToken());
      context.write(word,ONE);
    }
  }
}
