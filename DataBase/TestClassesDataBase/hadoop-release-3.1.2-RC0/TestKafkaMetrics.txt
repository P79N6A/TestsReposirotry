/** 
 * This tests that the KafkaSink properly formats the Kafka message.
 */
public class TestKafkaMetrics {
  private static final Logger LOG=LoggerFactory.getLogger(TestKafkaMetrics.class);
  private KafkaSink kafkaSink;
  enum KafkaMetricsInfo implements MetricsInfo {  KafkaMetrics("Kafka related metrics etc."),   KafkaCounter("Kafka counter."),   KafkaTag("Kafka tag.");   private final String desc;
  KafkaMetricsInfo(  String desc){
    this.desc=desc;
  }
  @Override public String description(){
    return desc;
  }
  @Override public String toString(){
    return new StringJoiner(", ",this.getClass().getSimpleName() + "{","}").add("name=" + name()).add("description=" + desc).toString();
  }
}
  @Test @SuppressWarnings({"unchecked","rawtypes"}) public void testPutMetrics() throws Exception {
    MetricsRecord record=mock(MetricsRecord.class);
    when(record.tags()).thenReturn(Lists.newArrayList(new MetricsTag(KafkaMetricsInfo.KafkaTag,"test_tag")));
    when(record.timestamp()).thenReturn(System.currentTimeMillis());
    AbstractMetric metric=new AbstractMetric(KafkaMetricsInfo.KafkaCounter){
      @Override public Number value(){
        return new Integer(123);
      }
      @Override public MetricType type(){
        return null;
      }
      @Override public void visit(      MetricsVisitor visitor){
      }
    }
;
    Iterable<AbstractMetric> metrics=Lists.newArrayList(metric);
    when(record.name()).thenReturn("Kafka record name");
    when(record.metrics()).thenReturn(metrics);
    SubsetConfiguration conf=mock(SubsetConfiguration.class);
    when(conf.getString(KafkaSink.BROKER_LIST)).thenReturn("localhost:9092");
    String topic="myTestKafkaTopic";
    when(conf.getString(KafkaSink.TOPIC)).thenReturn(topic);
    kafkaSink=new KafkaSink();
    kafkaSink.init(conf);
    Producer<Integer,byte[]> mockProducer=mock(KafkaProducer.class);
    kafkaSink.setProducer(mockProducer);
    StringBuilder jsonLines=recordToJson(record);
    if (LOG.isDebugEnabled()) {
      LOG.debug("kafka message: " + jsonLines.toString());
    }
    Future<RecordMetadata> f=mock(Future.class);
    when(mockProducer.send((ProducerRecord)anyObject())).thenReturn(f);
    kafkaSink.putMetrics(record);
    ArgumentCaptor<ProducerRecord> argument=ArgumentCaptor.forClass(ProducerRecord.class);
    verify(mockProducer).send(argument.capture());
    ProducerRecord<Integer,byte[]> data=(argument.getValue());
    String jsonResult=new String(data.value());
    if (LOG.isDebugEnabled()) {
      LOG.debug("kafka result: " + jsonResult);
    }
    assertEquals(jsonLines.toString(),jsonResult);
  }
  StringBuilder recordToJson(  MetricsRecord record){
    StringBuilder jsonLines=new StringBuilder();
    Long timestamp=record.timestamp();
    Date currDate=new Date(timestamp);
    SimpleDateFormat dateFormat=new SimpleDateFormat("yyyy-MM-dd");
    String date=dateFormat.format(currDate);
    SimpleDateFormat timeFormat=new SimpleDateFormat("HH:mm:ss");
    String time=timeFormat.format(currDate);
    String hostname=new String("null");
    try {
      hostname=InetAddress.getLocalHost().getHostName();
    }
 catch (    Exception e) {
      LOG.warn("Error getting Hostname, going to continue");
    }
    jsonLines.append("{\"hostname\": \"" + hostname);
    jsonLines.append("\", \"timestamp\": " + timestamp);
    jsonLines.append(", \"date\": \"" + date);
    jsonLines.append("\",\"time\": \"" + time);
    jsonLines.append("\",\"name\": \"" + record.name() + "\" ");
    for (    MetricsTag tag : record.tags()) {
      jsonLines.append(", \"" + tag.name().toString().replaceAll("[\\p{Cc}]","") + "\": ");
      jsonLines.append(" \"" + tag.value().toString() + "\"");
    }
    for (    AbstractMetric m : record.metrics()) {
      jsonLines.append(", \"" + m.name().toString().replaceAll("[\\p{Cc}]","") + "\": ");
      jsonLines.append(" \"" + m.value().toString() + "\"");
    }
    jsonLines.append("}");
    return jsonLines;
  }
}
