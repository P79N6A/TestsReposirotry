/** 
 * This class tests the correctness of storage type info stored in DFSNetworkTopology.
 */
public class TestDFSNetworkTopology {
  private static final Log LOG=LogFactory.getLog(TestDFSNetworkTopology.class);
  private final static DFSNetworkTopology CLUSTER=DFSNetworkTopology.getInstance(new Configuration());
  private DatanodeDescriptor[] dataNodes;
  @Rule public Timeout testTimeout=new Timeout(30000);
  @Before public void setupDatanodes(){
    final String[] racks={"/l1/d1/r1","/l1/d1/r1","/l1/d1/r2","/l1/d1/r2","/l1/d1/r2","/l1/d2/r3","/l1/d2/r3","/l1/d2/r3","/l2/d3/r1","/l2/d3/r2","/l2/d3/r3","/l2/d3/r4","/l2/d3/r5","/l2/d4/r1","/l2/d4/r1","/l2/d4/r1","/l2/d4/r1","/l2/d4/r1","/l2/d4/r1","/l2/d4/r1"};
    final String[] hosts={"host1","host2","host3","host4","host5","host6","host7","host8","host9","host10","host11","host12","host13","host14","host15","host16","host17","host18","host19","host20"};
    final StorageType[] types={StorageType.ARCHIVE,StorageType.DISK,StorageType.ARCHIVE,StorageType.DISK,StorageType.DISK,StorageType.DISK,StorageType.RAM_DISK,StorageType.SSD,StorageType.DISK,StorageType.RAM_DISK,StorageType.DISK,StorageType.ARCHIVE,StorageType.ARCHIVE,StorageType.DISK,StorageType.DISK,StorageType.RAM_DISK,StorageType.RAM_DISK,StorageType.ARCHIVE,StorageType.ARCHIVE,StorageType.SSD};
    final DatanodeStorageInfo[] storages=DFSTestUtil.createDatanodeStorageInfos(20,racks,hosts,types);
    dataNodes=DFSTestUtil.toDatanodeDescriptor(storages);
    for (int i=0; i < dataNodes.length; i++) {
      CLUSTER.add(dataNodes[i]);
    }
    dataNodes[9].setDecommissioned();
    dataNodes[10].setDecommissioned();
  }
  /** 
 * Test getting the storage type info of subtree.
 * @throws Exception
 */
  @Test public void testGetStorageTypeInfo() throws Exception {
    DFSTopologyNodeImpl d1=(DFSTopologyNodeImpl)CLUSTER.getNode("/l1/d1");
    HashMap<String,EnumMap<StorageType,Integer>> d1info=d1.getChildrenStorageInfo();
    assertEquals(2,d1info.keySet().size());
    assertTrue(d1info.get("r1").size() == 2 && d1info.get("r2").size() == 2);
    assertEquals(1,(int)d1info.get("r1").get(StorageType.DISK));
    assertEquals(1,(int)d1info.get("r1").get(StorageType.ARCHIVE));
    assertEquals(2,(int)d1info.get("r2").get(StorageType.DISK));
    assertEquals(1,(int)d1info.get("r2").get(StorageType.ARCHIVE));
    DFSTopologyNodeImpl d2=(DFSTopologyNodeImpl)CLUSTER.getNode("/l1/d2");
    HashMap<String,EnumMap<StorageType,Integer>> d2info=d2.getChildrenStorageInfo();
    assertEquals(1,d2info.keySet().size());
    assertTrue(d2info.get("r3").size() == 3);
    assertEquals(1,(int)d2info.get("r3").get(StorageType.DISK));
    assertEquals(1,(int)d2info.get("r3").get(StorageType.RAM_DISK));
    assertEquals(1,(int)d2info.get("r3").get(StorageType.SSD));
    DFSTopologyNodeImpl d3=(DFSTopologyNodeImpl)CLUSTER.getNode("/l2/d3");
    HashMap<String,EnumMap<StorageType,Integer>> d3info=d3.getChildrenStorageInfo();
    assertEquals(5,d3info.keySet().size());
    assertEquals(1,(int)d3info.get("r1").get(StorageType.DISK));
    assertEquals(1,(int)d3info.get("r2").get(StorageType.RAM_DISK));
    assertEquals(1,(int)d3info.get("r3").get(StorageType.DISK));
    assertEquals(1,(int)d3info.get("r4").get(StorageType.ARCHIVE));
    assertEquals(1,(int)d3info.get("r5").get(StorageType.ARCHIVE));
    DFSTopologyNodeImpl d4=(DFSTopologyNodeImpl)CLUSTER.getNode("/l2/d4");
    HashMap<String,EnumMap<StorageType,Integer>> d4info=d4.getChildrenStorageInfo();
    assertEquals(1,d4info.keySet().size());
    assertEquals(2,(int)d4info.get("r1").get(StorageType.DISK));
    assertEquals(2,(int)d4info.get("r1").get(StorageType.RAM_DISK));
    assertEquals(2,(int)d4info.get("r1").get(StorageType.ARCHIVE));
    assertEquals(1,(int)d4info.get("r1").get(StorageType.SSD));
    DFSTopologyNodeImpl l1=(DFSTopologyNodeImpl)CLUSTER.getNode("/l1");
    HashMap<String,EnumMap<StorageType,Integer>> l1info=l1.getChildrenStorageInfo();
    assertEquals(2,l1info.keySet().size());
    assertTrue(l1info.get("d1").size() == 2 && l1info.get("d2").size() == 3);
    assertEquals(2,(int)l1info.get("d1").get(StorageType.ARCHIVE));
    assertEquals(3,(int)l1info.get("d1").get(StorageType.DISK));
    assertEquals(1,(int)l1info.get("d2").get(StorageType.DISK));
    assertEquals(1,(int)l1info.get("d2").get(StorageType.RAM_DISK));
    assertEquals(1,(int)l1info.get("d2").get(StorageType.SSD));
    DFSTopologyNodeImpl l2=(DFSTopologyNodeImpl)CLUSTER.getNode("/l2");
    HashMap<String,EnumMap<StorageType,Integer>> l2info=l2.getChildrenStorageInfo();
    assertTrue(l2info.get("d3").size() == 3 && l2info.get("d4").size() == 4);
    assertEquals(2,l2info.keySet().size());
    assertEquals(2,(int)l2info.get("d3").get(StorageType.DISK));
    assertEquals(2,(int)l2info.get("d3").get(StorageType.ARCHIVE));
    assertEquals(1,(int)l2info.get("d3").get(StorageType.RAM_DISK));
    assertEquals(2,(int)l2info.get("d4").get(StorageType.DISK));
    assertEquals(2,(int)l2info.get("d4").get(StorageType.ARCHIVE));
    assertEquals(2,(int)l2info.get("d4").get(StorageType.RAM_DISK));
    assertEquals(1,(int)l2info.get("d4").get(StorageType.SSD));
  }
  /** 
 * Test the correctness of storage type info when nodes are added and removed.
 * @throws Exception
 */
  @Test public void testAddAndRemoveTopology() throws Exception {
    String[] newRack={"/l1/d1/r1","/l1/d1/r3","/l1/d3/r3","/l1/d3/r3"};
    String[] newHost={"nhost1","nhost2","nhost3","nhost4"};
    String[] newips={"30.30.30.30","31.31.31.31","32.32.32.32","33.33.33.33"};
    StorageType[] newTypes={StorageType.DISK,StorageType.SSD,StorageType.SSD,StorageType.SSD};
    DatanodeDescriptor[] newDD=new DatanodeDescriptor[4];
    for (int i=0; i < 4; i++) {
      DatanodeStorageInfo dsi=DFSTestUtil.createDatanodeStorageInfo("s" + newHost[i],newips[i],newRack[i],newHost[i],newTypes[i],null);
      newDD[i]=dsi.getDatanodeDescriptor();
      CLUSTER.add(newDD[i]);
    }
    DFSTopologyNodeImpl d1=(DFSTopologyNodeImpl)CLUSTER.getNode("/l1/d1");
    HashMap<String,EnumMap<StorageType,Integer>> d1info=d1.getChildrenStorageInfo();
    assertEquals(3,d1info.keySet().size());
    assertTrue(d1info.get("r1").size() == 2 && d1info.get("r2").size() == 2 && d1info.get("r3").size() == 1);
    assertEquals(2,(int)d1info.get("r1").get(StorageType.DISK));
    assertEquals(1,(int)d1info.get("r1").get(StorageType.ARCHIVE));
    assertEquals(2,(int)d1info.get("r2").get(StorageType.DISK));
    assertEquals(1,(int)d1info.get("r2").get(StorageType.ARCHIVE));
    assertEquals(1,(int)d1info.get("r3").get(StorageType.SSD));
    DFSTopologyNodeImpl d3=(DFSTopologyNodeImpl)CLUSTER.getNode("/l1/d3");
    HashMap<String,EnumMap<StorageType,Integer>> d3info=d3.getChildrenStorageInfo();
    assertEquals(1,d3info.keySet().size());
    assertTrue(d3info.get("r3").size() == 1);
    assertEquals(2,(int)d3info.get("r3").get(StorageType.SSD));
    DFSTopologyNodeImpl l1=(DFSTopologyNodeImpl)CLUSTER.getNode("/l1");
    HashMap<String,EnumMap<StorageType,Integer>> l1info=l1.getChildrenStorageInfo();
    assertEquals(3,l1info.keySet().size());
    assertTrue(l1info.get("d1").size() == 3 && l1info.get("d2").size() == 3 && l1info.get("d3").size() == 1);
    assertEquals(4,(int)l1info.get("d1").get(StorageType.DISK));
    assertEquals(2,(int)l1info.get("d1").get(StorageType.ARCHIVE));
    assertEquals(1,(int)l1info.get("d1").get(StorageType.SSD));
    assertEquals(1,(int)l1info.get("d2").get(StorageType.SSD));
    assertEquals(1,(int)l1info.get("d2").get(StorageType.RAM_DISK));
    assertEquals(1,(int)l1info.get("d2").get(StorageType.DISK));
    assertEquals(2,(int)l1info.get("d3").get(StorageType.SSD));
    for (int i=0; i < 4; i++) {
      CLUSTER.remove(newDD[i]);
    }
    DFSTopologyNodeImpl nd1=(DFSTopologyNodeImpl)CLUSTER.getNode("/l1/d1");
    HashMap<String,EnumMap<StorageType,Integer>> nd1info=nd1.getChildrenStorageInfo();
    assertEquals(2,nd1info.keySet().size());
    assertTrue(nd1info.get("r1").size() == 2 && nd1info.get("r2").size() == 2);
    assertEquals(1,(int)nd1info.get("r1").get(StorageType.DISK));
    assertEquals(1,(int)nd1info.get("r1").get(StorageType.ARCHIVE));
    assertEquals(2,(int)nd1info.get("r2").get(StorageType.DISK));
    assertEquals(1,(int)nd1info.get("r2").get(StorageType.ARCHIVE));
    DFSTopologyNodeImpl nl1=(DFSTopologyNodeImpl)CLUSTER.getNode("/l1");
    HashMap<String,EnumMap<StorageType,Integer>> nl1info=nl1.getChildrenStorageInfo();
    assertEquals(2,nl1info.keySet().size());
    assertTrue(l1info.get("d1").size() == 2 && l1info.get("d2").size() == 3);
    assertEquals(2,(int)nl1info.get("d1").get(StorageType.ARCHIVE));
    assertEquals(3,(int)nl1info.get("d1").get(StorageType.DISK));
    assertEquals(1,(int)l1info.get("d2").get(StorageType.DISK));
    assertEquals(1,(int)l1info.get("d2").get(StorageType.RAM_DISK));
    assertEquals(1,(int)l1info.get("d2").get(StorageType.SSD));
    assertNull(CLUSTER.getNode("/l1/d3"));
  }
  @Test public void testChooseRandomWithStorageType() throws Exception {
    Node n;
    DatanodeDescriptor dd;
    Set<String> diskUnderL1=Sets.newHashSet("host2","host4","host5","host6");
    Set<String> archiveUnderL1=Sets.newHashSet("host1","host3");
    Set<String> ramdiskUnderL1=Sets.newHashSet("host7");
    Set<String> ssdUnderL1=Sets.newHashSet("host8");
    for (int i=0; i < 10; i++) {
      n=CLUSTER.chooseRandomWithStorageType("/l1",null,null,StorageType.DISK);
      assertTrue(n instanceof DatanodeDescriptor);
      dd=(DatanodeDescriptor)n;
      assertTrue(diskUnderL1.contains(dd.getHostName()));
      n=CLUSTER.chooseRandomWithStorageType("/l1",null,null,StorageType.RAM_DISK);
      assertTrue(n instanceof DatanodeDescriptor);
      dd=(DatanodeDescriptor)n;
      assertTrue(ramdiskUnderL1.contains(dd.getHostName()));
      n=CLUSTER.chooseRandomWithStorageType("/l1",null,null,StorageType.ARCHIVE);
      assertTrue(n instanceof DatanodeDescriptor);
      dd=(DatanodeDescriptor)n;
      assertTrue(archiveUnderL1.contains(dd.getHostName()));
      n=CLUSTER.chooseRandomWithStorageType("/l1",null,null,StorageType.SSD);
      assertTrue(n instanceof DatanodeDescriptor);
      dd=(DatanodeDescriptor)n;
      assertTrue(ssdUnderL1.contains(dd.getHostName()));
    }
  }
  @Test public void testChooseRandomWithStorageTypeWithExcluded() throws Exception {
    Node n;
    DatanodeDescriptor dd;
    n=CLUSTER.chooseRandomWithStorageType("/l2/d3/r4",null,null,StorageType.ARCHIVE);
    HashSet<Node> excluded=new HashSet<>();
    excluded.add(n);
    for (int i=0; i < 10; i++) {
      n=CLUSTER.chooseRandomWithStorageType("/l2/d3",null,null,StorageType.ARCHIVE);
      assertTrue(n instanceof DatanodeDescriptor);
      dd=(DatanodeDescriptor)n;
      assertTrue(dd.getHostName().equals("host12") || dd.getHostName().equals("host13"));
    }
    for (int i=0; i < 10; i++) {
      n=CLUSTER.chooseRandomWithStorageType("/l2/d3",null,excluded,StorageType.ARCHIVE);
      assertTrue(n instanceof DatanodeDescriptor);
      dd=(DatanodeDescriptor)n;
      assertTrue(dd.getHostName().equals("host13"));
    }
    for (int i=0; i < 10; i++) {
      n=CLUSTER.chooseRandomWithStorageType("/l2/d3","/l2/d3/r4",null,StorageType.ARCHIVE);
      assertTrue(n instanceof DatanodeDescriptor);
      dd=(DatanodeDescriptor)n;
      assertTrue(dd.getHostName().equals("host13"));
    }
    for (int i=0; i < 10; i++) {
      n=CLUSTER.chooseRandomWithStorageType("/l2/d3","/l2/d3/r5",excluded,StorageType.ARCHIVE);
      assertNull(n);
    }
    n=CLUSTER.chooseRandomWithStorageType("/l1/d2",null,null,StorageType.DISK);
    dd=(DatanodeDescriptor)n;
    assertEquals("host6",dd.getHostName());
    excluded.add(n);
    Set<String> expectedSet=Sets.newHashSet("host4","host5");
    for (int i=0; i < 10; i++) {
      n=CLUSTER.chooseRandomWithStorageType("/l1","/l1/d1/r1",excluded,StorageType.DISK);
      dd=(DatanodeDescriptor)n;
      assertTrue(expectedSet.contains(dd.getHostName()));
    }
  }
  /** 
 * This test tests the wrapper method. The wrapper method only takes one scope where if it starts with a ~, it is an excluded scope, and searching always from root. Otherwise it is a scope.
 * @throws Exception throws exception.
 */
  @Test public void testChooseRandomWithStorageTypeWrapper() throws Exception {
    Node n;
    DatanodeDescriptor dd;
    n=CLUSTER.chooseRandomWithStorageType("/l2/d3/r4",null,null,StorageType.ARCHIVE);
    HashSet<Node> excluded=new HashSet<>();
    excluded.add(n);
    for (int i=0; i < 10; i++) {
      n=CLUSTER.chooseRandomWithStorageType("/l2/d3",null,StorageType.ARCHIVE);
      assertTrue(n instanceof DatanodeDescriptor);
      dd=(DatanodeDescriptor)n;
      assertTrue(dd.getHostName().equals("host12") || dd.getHostName().equals("host13"));
    }
    for (int i=0; i < 10; i++) {
      n=CLUSTER.chooseRandomWithStorageType("/l2/d3",excluded,StorageType.ARCHIVE);
      assertTrue(n instanceof DatanodeDescriptor);
      dd=(DatanodeDescriptor)n;
      assertTrue(dd.getHostName().equals("host13"));
    }
    for (int i=0; i < 10; i++) {
      n=CLUSTER.chooseRandomWithStorageType("~/l2/d4",null,StorageType.RAM_DISK);
      assertTrue(n instanceof DatanodeDescriptor);
      dd=(DatanodeDescriptor)n;
      assertTrue(dd.getHostName().equals("host7") || dd.getHostName().equals("host10"));
    }
    n=CLUSTER.chooseRandomWithStorageType("/l2/d3/r2",null,null,StorageType.RAM_DISK);
    excluded.add(n);
    for (int i=0; i < 10; i++) {
      n=CLUSTER.chooseRandomWithStorageType("~/l2/d4",excluded,StorageType.RAM_DISK);
      assertTrue(n instanceof DatanodeDescriptor);
      dd=(DatanodeDescriptor)n;
      assertTrue(dd.getHostName().equals("host7"));
    }
  }
  @Test public void testNonExistingNode() throws Exception {
    Node n;
    n=CLUSTER.chooseRandomWithStorageType("/l100",null,null,StorageType.DISK);
    assertNull(n);
    n=CLUSTER.chooseRandomWithStorageType("/l100/d100",null,null,StorageType.DISK);
    assertNull(n);
    n=CLUSTER.chooseRandomWithStorageType("/l100/d100/r100",null,null,StorageType.DISK);
    assertNull(n);
  }
  /** 
 * Tests getting subtree storage counts, and see whether it is correct when we update subtree.
 * @throws Exception
 */
  @Test public void testGetSubtreeStorageCount() throws Exception {
    Node l2=CLUSTER.getNode("/l2");
    Node l2d3=CLUSTER.getNode("/l2/d3");
    Node l2d3r1=CLUSTER.getNode("/l2/d3/r1");
    Node l2d3r3=CLUSTER.getNode("/l2/d3/r3");
    assertTrue(l2 instanceof DFSTopologyNodeImpl);
    assertTrue(l2d3 instanceof DFSTopologyNodeImpl);
    assertTrue(l2d3r1 instanceof DFSTopologyNodeImpl);
    assertTrue(l2d3r3 instanceof DFSTopologyNodeImpl);
    DFSTopologyNodeImpl innerl2=(DFSTopologyNodeImpl)l2;
    DFSTopologyNodeImpl innerl2d3=(DFSTopologyNodeImpl)l2d3;
    DFSTopologyNodeImpl innerl2d3r1=(DFSTopologyNodeImpl)l2d3r1;
    DFSTopologyNodeImpl innerl2d3r3=(DFSTopologyNodeImpl)l2d3r3;
    assertEquals(4,innerl2.getSubtreeStorageCount(StorageType.DISK));
    assertEquals(2,innerl2d3.getSubtreeStorageCount(StorageType.DISK));
    assertEquals(1,innerl2d3r1.getSubtreeStorageCount(StorageType.DISK));
    assertEquals(1,innerl2d3r3.getSubtreeStorageCount(StorageType.DISK));
    DatanodeStorageInfo storageInfo=DFSTestUtil.createDatanodeStorageInfo("StorageID","1.2.3.4","/l2/d3/r1","newhost");
    DatanodeDescriptor newNode=storageInfo.getDatanodeDescriptor();
    CLUSTER.add(newNode);
    assertEquals(5,innerl2.getSubtreeStorageCount(StorageType.DISK));
    assertEquals(3,innerl2d3.getSubtreeStorageCount(StorageType.DISK));
    assertEquals(2,innerl2d3r1.getSubtreeStorageCount(StorageType.DISK));
    assertEquals(1,innerl2d3r3.getSubtreeStorageCount(StorageType.DISK));
    CLUSTER.remove(newNode);
    assertEquals(4,innerl2.getSubtreeStorageCount(StorageType.DISK));
    assertEquals(2,innerl2d3.getSubtreeStorageCount(StorageType.DISK));
    assertEquals(1,innerl2d3r1.getSubtreeStorageCount(StorageType.DISK));
    assertEquals(1,innerl2d3r3.getSubtreeStorageCount(StorageType.DISK));
  }
  @Test public void testChooseRandomWithStorageTypeTwoTrial() throws Exception {
    Node n;
    DatanodeDescriptor dd;
    n=CLUSTER.chooseRandomWithStorageType("/l2/d3/r4",null,null,StorageType.ARCHIVE);
    HashSet<Node> excluded=new HashSet<>();
    excluded.add(n);
    for (int i=0; i < 10; i++) {
      n=CLUSTER.chooseRandomWithStorageTypeTwoTrial("/l2/d3",null,StorageType.ARCHIVE);
      assertTrue(n instanceof DatanodeDescriptor);
      dd=(DatanodeDescriptor)n;
      assertTrue(dd.getHostName().equals("host12") || dd.getHostName().equals("host13"));
    }
    for (int i=0; i < 10; i++) {
      n=CLUSTER.chooseRandomWithStorageTypeTwoTrial("/l2/d3",excluded,StorageType.ARCHIVE);
      assertTrue(n instanceof DatanodeDescriptor);
      dd=(DatanodeDescriptor)n;
      assertTrue(dd.getHostName().equals("host13"));
    }
    for (int i=0; i < 10; i++) {
      n=CLUSTER.chooseRandomWithStorageTypeTwoTrial("~/l2/d4",null,StorageType.RAM_DISK);
      assertTrue(n instanceof DatanodeDescriptor);
      dd=(DatanodeDescriptor)n;
      assertTrue(dd.getHostName().equals("host7") || dd.getHostName().equals("host10"));
    }
    n=CLUSTER.chooseRandomWithStorageType("/l2/d3/r2",null,null,StorageType.RAM_DISK);
    excluded.add(n);
    for (int i=0; i < 10; i++) {
      n=CLUSTER.chooseRandomWithStorageTypeTwoTrial("~/l2/d4",excluded,StorageType.RAM_DISK);
      assertTrue(n instanceof DatanodeDescriptor);
      dd=(DatanodeDescriptor)n;
      assertTrue(dd.getHostName().equals("host7"));
    }
  }
}
