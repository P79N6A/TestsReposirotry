public class TestJavaSerialization {
  private static String TEST_ROOT_DIR=new File(System.getProperty("test.build.data","/tmp")).toURI().toString().replace(' ','+');
  private final Path INPUT_DIR=new Path(TEST_ROOT_DIR + "/input");
  private final Path OUTPUT_DIR=new Path(TEST_ROOT_DIR + "/out");
  private final Path INPUT_FILE=new Path(INPUT_DIR,"inp");
static class WordCountMapper extends MapReduceBase implements Mapper<LongWritable,Text,String,Long> {
    public void map(    LongWritable key,    Text value,    OutputCollector<String,Long> output,    Reporter reporter) throws IOException {
      StringTokenizer st=new StringTokenizer(value.toString());
      while (st.hasMoreTokens()) {
        String token=st.nextToken();
        assertTrue("Invalid token; expected 'a' or 'b', got " + token,token.equals("a") || token.equals("b"));
        output.collect(token,1L);
      }
    }
  }
static class SumReducer<K> extends MapReduceBase implements Reducer<K,Long,K,Long> {
    public void reduce(    K key,    Iterator<Long> values,    OutputCollector<K,Long> output,    Reporter reporter) throws IOException {
      long sum=0;
      while (values.hasNext()) {
        sum+=values.next();
      }
      output.collect(key,sum);
    }
  }
  private void cleanAndCreateInput(  FileSystem fs) throws IOException {
    fs.delete(INPUT_DIR,true);
    fs.delete(OUTPUT_DIR,true);
    OutputStream os=fs.create(INPUT_FILE);
    Writer wr=new OutputStreamWriter(os);
    wr.write("b a\n");
    wr.close();
  }
  @SuppressWarnings("deprecation") @Test public void testMapReduceJob() throws Exception {
    JobConf conf=new JobConf(TestJavaSerialization.class);
    conf.setJobName("JavaSerialization");
    FileSystem fs=FileSystem.get(conf);
    cleanAndCreateInput(fs);
    conf.set("io.serializations","org.apache.hadoop.io.serializer.JavaSerialization," + "org.apache.hadoop.io.serializer.WritableSerialization");
    conf.setInputFormat(TextInputFormat.class);
    conf.setOutputKeyClass(String.class);
    conf.setOutputValueClass(Long.class);
    conf.setOutputKeyComparatorClass(JavaSerializationComparator.class);
    conf.setMapperClass(WordCountMapper.class);
    conf.setReducerClass(SumReducer.class);
    conf.set(MRConfig.FRAMEWORK_NAME,MRConfig.LOCAL_FRAMEWORK_NAME);
    FileInputFormat.setInputPaths(conf,INPUT_DIR);
    FileOutputFormat.setOutputPath(conf,OUTPUT_DIR);
    String inputFileContents=FileUtils.readFileToString(new File(INPUT_FILE.toUri().getPath()));
    assertTrue("Input file contents not as expected; contents are '" + inputFileContents + "', expected \"b a\n\" ",inputFileContents.equals("b a\n"));
    JobClient.runJob(conf);
    Path[] outputFiles=FileUtil.stat2Paths(fs.listStatus(OUTPUT_DIR,new Utils.OutputFileUtils.OutputFilesFilter()));
    assertEquals(1,outputFiles.length);
    try (InputStream is=fs.open(outputFiles[0])){
      String reduceOutput=org.apache.commons.io.IOUtils.toString(is);
      String[] lines=reduceOutput.split("\n");
      assertEquals("Unexpected output; received output '" + reduceOutput + "'","a\t1",lines[0]);
      assertEquals("Unexpected output; received output '" + reduceOutput + "'","b\t1",lines[1]);
      assertEquals("Reduce output has extra lines; output is '" + reduceOutput + "'",2,lines.length);
    }
   }
  /** 
 * HADOOP-4466: This test verifies the JavSerialization impl can write to SequenceFiles. by virtue other SequenceFileOutputFormat is not  coupled to Writable types, if so, the job will fail.
 */
  @Test public void testWriteToSequencefile() throws Exception {
    JobConf conf=new JobConf(TestJavaSerialization.class);
    conf.setJobName("JavaSerialization");
    FileSystem fs=FileSystem.get(conf);
    cleanAndCreateInput(fs);
    conf.set("io.serializations","org.apache.hadoop.io.serializer.JavaSerialization," + "org.apache.hadoop.io.serializer.WritableSerialization");
    conf.setInputFormat(TextInputFormat.class);
    conf.setOutputFormat(SequenceFileOutputFormat.class);
    conf.setOutputKeyClass(String.class);
    conf.setOutputValueClass(Long.class);
    conf.setOutputKeyComparatorClass(JavaSerializationComparator.class);
    conf.setMapperClass(WordCountMapper.class);
    conf.setReducerClass(SumReducer.class);
    conf.set(MRConfig.FRAMEWORK_NAME,MRConfig.LOCAL_FRAMEWORK_NAME);
    FileInputFormat.setInputPaths(conf,INPUT_DIR);
    FileOutputFormat.setOutputPath(conf,OUTPUT_DIR);
    JobClient.runJob(conf);
    Path[] outputFiles=FileUtil.stat2Paths(fs.listStatus(OUTPUT_DIR,new Utils.OutputFileUtils.OutputFilesFilter()));
    assertEquals(1,outputFiles.length);
  }
}
