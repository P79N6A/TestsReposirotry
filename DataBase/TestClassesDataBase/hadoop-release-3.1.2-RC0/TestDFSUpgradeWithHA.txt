/** 
 * Tests for upgrading with HA enabled.
 */
public class TestDFSUpgradeWithHA {
  private static final Log LOG=LogFactory.getLog(TestDFSUpgradeWithHA.class);
  private Configuration conf;
  @Before public void createConfiguration(){
    conf=new HdfsConfiguration();
    conf.setInt(CommonConfigurationKeysPublic.IPC_CLIENT_CONNECTION_MAXIDLETIME_KEY,0);
  }
  private static void assertCTimesEqual(  MiniDFSCluster cluster){
    long nn1CTime=cluster.getNamesystem(0).getFSImage().getStorage().getCTime();
    long nn2CTime=cluster.getNamesystem(1).getFSImage().getStorage().getCTime();
    assertEquals(nn1CTime,nn2CTime);
  }
  private static void checkClusterPreviousDirExistence(  MiniDFSCluster cluster,  boolean shouldExist){
    for (int i=0; i < 2; i++) {
      checkNnPreviousDirExistence(cluster,i,shouldExist);
    }
  }
  private static void checkNnPreviousDirExistence(  MiniDFSCluster cluster,  int index,  boolean shouldExist){
    Collection<URI> nameDirs=cluster.getNameDirs(index);
    for (    URI nnDir : nameDirs) {
      checkPreviousDirExistence(new File(nnDir),shouldExist);
    }
  }
  private static void checkJnPreviousDirExistence(  MiniQJMHACluster jnCluster,  boolean shouldExist) throws IOException {
    for (int i=0; i < 3; i++) {
      checkPreviousDirExistence(jnCluster.getJournalCluster().getJournalDir(i,"ns1"),shouldExist);
    }
    if (shouldExist) {
      assertEpochFilesCopied(jnCluster);
    }
  }
  private static void assertEpochFilesCopied(  MiniQJMHACluster jnCluster) throws IOException {
    for (int i=0; i < 3; i++) {
      File journalDir=jnCluster.getJournalCluster().getJournalDir(i,"ns1");
      File currDir=new File(journalDir,"current");
      File prevDir=new File(journalDir,"previous");
      for (      String fileName : new String[]{Journal.LAST_PROMISED_FILENAME,Journal.LAST_WRITER_EPOCH}) {
        File prevFile=new File(prevDir,fileName);
        if (prevFile.exists()) {
          PersistentLongFile prevLongFile=new PersistentLongFile(prevFile,-10);
          PersistentLongFile currLongFile=new PersistentLongFile(new File(currDir,fileName),-11);
          assertTrue("Value in " + fileName + " has decreased on upgrade in "+ journalDir,prevLongFile.get() <= currLongFile.get());
        }
      }
    }
  }
  private static void checkPreviousDirExistence(  File rootDir,  boolean shouldExist){
    File previousDir=new File(rootDir,"previous");
    if (shouldExist) {
      assertTrue(previousDir + " does not exist",previousDir.exists());
    }
 else {
      assertFalse(previousDir + " does exist",previousDir.exists());
    }
  }
  private void runFinalizeCommand(  MiniDFSCluster cluster) throws IOException {
    HATestUtil.setFailoverConfigurations(cluster,conf);
    new DFSAdmin(conf).finalizeUpgrade();
  }
  /** 
 * Ensure that an admin cannot finalize an HA upgrade without at least one NN being active.
 */
  @Test public void testCannotFinalizeIfNoActive() throws IOException, URISyntaxException {
    MiniDFSCluster cluster=null;
    FileSystem fs=null;
    try {
      cluster=new MiniDFSCluster.Builder(conf).nnTopology(MiniDFSNNTopology.simpleHATopology()).numDataNodes(0).build();
      File sharedDir=new File(cluster.getSharedEditsDir(0,1));
      checkClusterPreviousDirExistence(cluster,false);
      assertCTimesEqual(cluster);
      checkPreviousDirExistence(sharedDir,false);
      cluster.transitionToActive(0);
      fs=HATestUtil.configureFailoverFs(cluster,conf);
      assertTrue(fs.mkdirs(new Path("/foo1")));
      cluster.shutdownNameNode(1);
      cluster.getNameNodeInfos()[0].setStartOpt(StartupOption.UPGRADE);
      cluster.restartNameNode(0,false);
      checkNnPreviousDirExistence(cluster,0,true);
      checkNnPreviousDirExistence(cluster,1,false);
      checkPreviousDirExistence(sharedDir,true);
      assertTrue(fs.mkdirs(new Path("/foo2")));
      cluster.getNameNodeInfos()[0].setStartOpt(StartupOption.REGULAR);
      cluster.restartNameNode(0,false);
      cluster.transitionToActive(0);
      assertTrue(fs.mkdirs(new Path("/foo3")));
      int rc=BootstrapStandby.run(new String[]{"-force"},cluster.getConfiguration(1));
      assertEquals(0,rc);
      cluster.restartNameNode(1);
      cluster.transitionToStandby(0);
      cluster.transitionToActive(1);
      assertTrue(fs.mkdirs(new Path("/foo4")));
      assertCTimesEqual(cluster);
      cluster.transitionToStandby(1);
      try {
        runFinalizeCommand(cluster);
        fail("Should not have been able to finalize upgrade with no NN active");
      }
 catch (      IOException ioe) {
        GenericTestUtils.assertExceptionContains("Cannot finalize with no NameNode active",ioe);
      }
    }
  finally {
      if (fs != null) {
        fs.close();
      }
      if (cluster != null) {
        cluster.shutdown();
      }
    }
  }
  /** 
 * Make sure that an HA NN with NFS-based HA can successfully start and upgrade.
 */
  @Test public void testNfsUpgrade() throws IOException, URISyntaxException {
    MiniDFSCluster cluster=null;
    FileSystem fs=null;
    try {
      cluster=new MiniDFSCluster.Builder(conf).nnTopology(MiniDFSNNTopology.simpleHATopology()).numDataNodes(0).build();
      File sharedDir=new File(cluster.getSharedEditsDir(0,1));
      checkClusterPreviousDirExistence(cluster,false);
      assertCTimesEqual(cluster);
      checkPreviousDirExistence(sharedDir,false);
      cluster.transitionToActive(0);
      fs=HATestUtil.configureFailoverFs(cluster,conf);
      assertTrue(fs.mkdirs(new Path("/foo1")));
      cluster.shutdownNameNode(1);
      cluster.getNameNodeInfos()[0].setStartOpt(StartupOption.UPGRADE);
      cluster.restartNameNode(0,false);
      checkNnPreviousDirExistence(cluster,0,true);
      checkNnPreviousDirExistence(cluster,1,false);
      checkPreviousDirExistence(sharedDir,true);
      assertTrue(fs.mkdirs(new Path("/foo2")));
      cluster.getNameNodeInfos()[0].setStartOpt(StartupOption.REGULAR);
      cluster.restartNameNode(0,false);
      cluster.transitionToActive(0);
      assertTrue(fs.mkdirs(new Path("/foo3")));
      int rc=BootstrapStandby.run(new String[]{"-force"},cluster.getConfiguration(1));
      assertEquals(0,rc);
      cluster.restartNameNode(1);
      cluster.transitionToStandby(0);
      cluster.transitionToActive(1);
      assertTrue(fs.mkdirs(new Path("/foo4")));
      assertCTimesEqual(cluster);
    }
  finally {
      if (fs != null) {
        fs.close();
      }
      if (cluster != null) {
        cluster.shutdown();
      }
    }
  }
  private long getCommittedTxnIdValue(  MiniQJMHACluster qjCluster) throws IOException {
    Journal journal1=qjCluster.getJournalCluster().getJournalNode(0).getOrCreateJournal(MiniQJMHACluster.NAMESERVICE);
    BestEffortLongFile committedTxnId=(BestEffortLongFile)Whitebox.getInternalState(journal1,"committedTxnId");
    return committedTxnId != null ? committedTxnId.get() : HdfsServerConstants.INVALID_TXID;
  }
  /** 
 * Make sure that an HA NN can successfully upgrade when configured using JournalNodes.
 */
  @Test public void testUpgradeWithJournalNodes() throws IOException, URISyntaxException {
    MiniQJMHACluster qjCluster=null;
    FileSystem fs=null;
    try {
      Builder builder=new MiniQJMHACluster.Builder(conf);
      builder.getDfsBuilder().numDataNodes(0);
      qjCluster=builder.build();
      MiniDFSCluster cluster=qjCluster.getDfsCluster();
      checkJnPreviousDirExistence(qjCluster,false);
      checkClusterPreviousDirExistence(cluster,false);
      assertCTimesEqual(cluster);
      cluster.transitionToActive(0);
      fs=HATestUtil.configureFailoverFs(cluster,conf);
      assertTrue(fs.mkdirs(new Path("/foo1")));
      final long cidBeforeUpgrade=getCommittedTxnIdValue(qjCluster);
      cluster.shutdownNameNode(1);
      cluster.getNameNodeInfos()[0].setStartOpt(StartupOption.UPGRADE);
      cluster.restartNameNode(0,false);
      checkNnPreviousDirExistence(cluster,0,true);
      checkNnPreviousDirExistence(cluster,1,false);
      checkJnPreviousDirExistence(qjCluster,true);
      assertTrue(cidBeforeUpgrade <= getCommittedTxnIdValue(qjCluster));
      assertTrue(fs.mkdirs(new Path("/foo2")));
      cluster.getNameNodeInfos()[0].setStartOpt(StartupOption.REGULAR);
      cluster.restartNameNode(0,false);
      cluster.transitionToActive(0);
      assertTrue(fs.mkdirs(new Path("/foo3")));
      assertTrue(getCommittedTxnIdValue(qjCluster) > cidBeforeUpgrade);
      int rc=BootstrapStandby.run(new String[]{"-force"},cluster.getConfiguration(1));
      assertEquals(0,rc);
      cluster.restartNameNode(1);
      cluster.transitionToStandby(0);
      cluster.transitionToActive(1);
      assertTrue(fs.mkdirs(new Path("/foo4")));
      assertCTimesEqual(cluster);
    }
  finally {
      if (fs != null) {
        fs.close();
      }
      if (qjCluster != null) {
        qjCluster.shutdown();
      }
    }
  }
  @Test public void testFinalizeWithJournalNodes() throws IOException, URISyntaxException {
    MiniQJMHACluster qjCluster=null;
    FileSystem fs=null;
    try {
      Builder builder=new MiniQJMHACluster.Builder(conf);
      builder.getDfsBuilder().numDataNodes(0);
      qjCluster=builder.build();
      MiniDFSCluster cluster=qjCluster.getDfsCluster();
      checkJnPreviousDirExistence(qjCluster,false);
      checkClusterPreviousDirExistence(cluster,false);
      assertCTimesEqual(cluster);
      cluster.transitionToActive(0);
      fs=HATestUtil.configureFailoverFs(cluster,conf);
      assertTrue(fs.mkdirs(new Path("/foo1")));
      final long cidBeforeUpgrade=getCommittedTxnIdValue(qjCluster);
      cluster.shutdownNameNode(1);
      cluster.getNameNodeInfos()[0].setStartOpt(StartupOption.UPGRADE);
      cluster.restartNameNode(0,false);
      assertTrue(cidBeforeUpgrade <= getCommittedTxnIdValue(qjCluster));
      assertTrue(fs.mkdirs(new Path("/foo2")));
      checkNnPreviousDirExistence(cluster,0,true);
      checkNnPreviousDirExistence(cluster,1,false);
      checkJnPreviousDirExistence(qjCluster,true);
      int rc=BootstrapStandby.run(new String[]{"-force"},cluster.getConfiguration(1));
      assertEquals(0,rc);
      cluster.restartNameNode(1);
      final long cidDuringUpgrade=getCommittedTxnIdValue(qjCluster);
      assertTrue(cidDuringUpgrade > cidBeforeUpgrade);
      runFinalizeCommand(cluster);
      assertEquals(cidDuringUpgrade,getCommittedTxnIdValue(qjCluster));
      checkClusterPreviousDirExistence(cluster,false);
      checkJnPreviousDirExistence(qjCluster,false);
      assertCTimesEqual(cluster);
    }
  finally {
      if (fs != null) {
        fs.close();
      }
      if (qjCluster != null) {
        qjCluster.shutdown();
      }
    }
  }
  /** 
 * Make sure that even if the NN which initiated the upgrade is in the standby state that we're allowed to finalize.
 */
  @Test public void testFinalizeFromSecondNameNodeWithJournalNodes() throws IOException, URISyntaxException {
    MiniQJMHACluster qjCluster=null;
    FileSystem fs=null;
    try {
      Builder builder=new MiniQJMHACluster.Builder(conf);
      builder.getDfsBuilder().numDataNodes(0);
      qjCluster=builder.build();
      MiniDFSCluster cluster=qjCluster.getDfsCluster();
      checkJnPreviousDirExistence(qjCluster,false);
      checkClusterPreviousDirExistence(cluster,false);
      assertCTimesEqual(cluster);
      cluster.transitionToActive(0);
      fs=HATestUtil.configureFailoverFs(cluster,conf);
      assertTrue(fs.mkdirs(new Path("/foo1")));
      cluster.shutdownNameNode(1);
      cluster.getNameNodeInfos()[0].setStartOpt(StartupOption.UPGRADE);
      cluster.restartNameNode(0,false);
      checkNnPreviousDirExistence(cluster,0,true);
      checkNnPreviousDirExistence(cluster,1,false);
      checkJnPreviousDirExistence(qjCluster,true);
      int rc=BootstrapStandby.run(new String[]{"-force"},cluster.getConfiguration(1));
      assertEquals(0,rc);
      cluster.restartNameNode(1);
      cluster.transitionToStandby(0);
      cluster.transitionToActive(1);
      runFinalizeCommand(cluster);
      checkClusterPreviousDirExistence(cluster,false);
      checkJnPreviousDirExistence(qjCluster,false);
      assertCTimesEqual(cluster);
    }
  finally {
      if (fs != null) {
        fs.close();
      }
      if (qjCluster != null) {
        qjCluster.shutdown();
      }
    }
  }
  /** 
 * Make sure that an HA NN will start if a previous upgrade was in progress.
 */
  @Test public void testStartingWithUpgradeInProgressSucceeds() throws Exception {
    MiniDFSCluster cluster=null;
    try {
      cluster=new MiniDFSCluster.Builder(conf).nnTopology(MiniDFSNNTopology.simpleHATopology()).numDataNodes(0).build();
      for (int i=0; i < 2; i++) {
        for (        URI uri : cluster.getNameDirs(i)) {
          File prevTmp=new File(new File(uri),Storage.STORAGE_TMP_PREVIOUS);
          LOG.info("creating previous tmp dir: " + prevTmp);
          assertTrue(prevTmp.mkdirs());
        }
      }
      cluster.restartNameNodes();
    }
  finally {
      if (cluster != null) {
        cluster.shutdown();
      }
    }
  }
  /** 
 * Test rollback with NFS shared dir.
 */
  @Test public void testRollbackWithNfs() throws Exception {
    MiniDFSCluster cluster=null;
    FileSystem fs=null;
    try {
      cluster=new MiniDFSCluster.Builder(conf).nnTopology(MiniDFSNNTopology.simpleHATopology()).numDataNodes(0).build();
      File sharedDir=new File(cluster.getSharedEditsDir(0,1));
      checkClusterPreviousDirExistence(cluster,false);
      assertCTimesEqual(cluster);
      checkPreviousDirExistence(sharedDir,false);
      cluster.transitionToActive(0);
      fs=HATestUtil.configureFailoverFs(cluster,conf);
      assertTrue(fs.mkdirs(new Path("/foo1")));
      cluster.shutdownNameNode(1);
      cluster.getNameNodeInfos()[0].setStartOpt(StartupOption.UPGRADE);
      cluster.restartNameNode(0,false);
      checkNnPreviousDirExistence(cluster,0,true);
      checkNnPreviousDirExistence(cluster,1,false);
      checkPreviousDirExistence(sharedDir,true);
      assertTrue(fs.mkdirs(new Path("/foo2")));
      int rc=BootstrapStandby.run(new String[]{"-force"},cluster.getConfiguration(1));
      assertEquals(0,rc);
      cluster.restartNameNode(1);
      checkNnPreviousDirExistence(cluster,0,true);
      checkNnPreviousDirExistence(cluster,1,true);
      checkPreviousDirExistence(sharedDir,true);
      assertCTimesEqual(cluster);
      Collection<URI> nn1NameDirs=cluster.getNameDirs(0);
      cluster.shutdown();
      conf.setStrings(DFSConfigKeys.DFS_NAMENODE_NAME_DIR_KEY,Joiner.on(",").join(nn1NameDirs));
      NameNode.doRollback(conf,false);
      checkNnPreviousDirExistence(cluster,0,false);
      checkPreviousDirExistence(sharedDir,false);
    }
  finally {
      if (fs != null) {
        fs.close();
      }
      if (cluster != null) {
        cluster.shutdown();
      }
    }
  }
  @Test public void testRollbackWithJournalNodes() throws IOException, URISyntaxException {
    MiniQJMHACluster qjCluster=null;
    FileSystem fs=null;
    try {
      Builder builder=new MiniQJMHACluster.Builder(conf);
      builder.getDfsBuilder().numDataNodes(0);
      qjCluster=builder.build();
      MiniDFSCluster cluster=qjCluster.getDfsCluster();
      checkClusterPreviousDirExistence(cluster,false);
      assertCTimesEqual(cluster);
      checkJnPreviousDirExistence(qjCluster,false);
      cluster.transitionToActive(0);
      fs=HATestUtil.configureFailoverFs(cluster,conf);
      assertTrue(fs.mkdirs(new Path("/foo1")));
      final long cidBeforeUpgrade=getCommittedTxnIdValue(qjCluster);
      cluster.shutdownNameNode(1);
      cluster.getNameNodeInfos()[0].setStartOpt(StartupOption.UPGRADE);
      cluster.restartNameNode(0,false);
      checkNnPreviousDirExistence(cluster,0,true);
      checkNnPreviousDirExistence(cluster,1,false);
      checkJnPreviousDirExistence(qjCluster,true);
      assertTrue(fs.mkdirs(new Path("/foo2")));
      final long cidDuringUpgrade=getCommittedTxnIdValue(qjCluster);
      assertTrue(cidDuringUpgrade > cidBeforeUpgrade);
      int rc=BootstrapStandby.run(new String[]{"-force"},cluster.getConfiguration(1));
      assertEquals(0,rc);
      cluster.restartNameNode(1);
      checkNnPreviousDirExistence(cluster,0,true);
      checkNnPreviousDirExistence(cluster,1,true);
      checkJnPreviousDirExistence(qjCluster,true);
      assertCTimesEqual(cluster);
      Collection<URI> nn1NameDirs=cluster.getNameDirs(0);
      cluster.shutdown();
      conf.setStrings(DFSConfigKeys.DFS_NAMENODE_NAME_DIR_KEY,Joiner.on(",").join(nn1NameDirs));
      NameNode.doRollback(conf,false);
      final long cidAfterRollback=getCommittedTxnIdValue(qjCluster);
      assertTrue(cidBeforeUpgrade < cidAfterRollback);
      assertTrue(cidDuringUpgrade > cidAfterRollback);
      checkNnPreviousDirExistence(cluster,0,false);
      checkJnPreviousDirExistence(qjCluster,false);
    }
  finally {
      if (fs != null) {
        fs.close();
      }
      if (qjCluster != null) {
        qjCluster.shutdown();
      }
    }
  }
  /** 
 * Make sure that starting a second NN with the -upgrade flag fails if the other NN has already done that.
 */
  @Test public void testCannotUpgradeSecondNameNode() throws IOException, URISyntaxException {
    MiniDFSCluster cluster=null;
    FileSystem fs=null;
    try {
      cluster=new MiniDFSCluster.Builder(conf).nnTopology(MiniDFSNNTopology.simpleHATopology()).numDataNodes(0).build();
      File sharedDir=new File(cluster.getSharedEditsDir(0,1));
      checkClusterPreviousDirExistence(cluster,false);
      assertCTimesEqual(cluster);
      checkPreviousDirExistence(sharedDir,false);
      cluster.transitionToActive(0);
      fs=HATestUtil.configureFailoverFs(cluster,conf);
      assertTrue(fs.mkdirs(new Path("/foo1")));
      cluster.shutdownNameNode(1);
      cluster.getNameNodeInfos()[0].setStartOpt(StartupOption.UPGRADE);
      cluster.restartNameNode(0,false);
      checkNnPreviousDirExistence(cluster,0,true);
      checkNnPreviousDirExistence(cluster,1,false);
      checkPreviousDirExistence(sharedDir,true);
      assertTrue(fs.mkdirs(new Path("/foo2")));
      cluster.getNameNodeInfos()[0].setStartOpt(StartupOption.REGULAR);
      cluster.restartNameNode(0,false);
      cluster.transitionToActive(0);
      assertTrue(fs.mkdirs(new Path("/foo3")));
      cluster.getNameNodeInfos()[1].setStartOpt(StartupOption.UPGRADE);
      try {
        cluster.restartNameNode(1,false);
        fail("Should not have been able to start second NN with -upgrade");
      }
 catch (      IOException ioe) {
        GenericTestUtils.assertExceptionContains("It looks like the shared log is already being upgraded",ioe);
      }
    }
  finally {
      if (fs != null) {
        fs.close();
      }
      if (cluster != null) {
        cluster.shutdown();
      }
    }
  }
}
