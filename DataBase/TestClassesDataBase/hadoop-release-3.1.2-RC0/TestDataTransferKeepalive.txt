public class TestDataTransferKeepalive {
  final Configuration conf=new HdfsConfiguration();
  private MiniDFSCluster cluster;
  private DataNode dn;
  private static final Path TEST_FILE=new Path("/test");
  private static final int KEEPALIVE_TIMEOUT=1000;
  private static final int WRITE_TIMEOUT=3000;
  @Before public void setup() throws Exception {
    conf.setInt(DFS_DATANODE_SOCKET_REUSE_KEEPALIVE_KEY,KEEPALIVE_TIMEOUT);
    conf.setInt(DFS_CLIENT_MAX_BLOCK_ACQUIRE_FAILURES_KEY,0);
    cluster=new MiniDFSCluster.Builder(conf).numDataNodes(1).build();
    dn=cluster.getDataNodes().get(0);
  }
  @After public void teardown(){
    if (cluster != null) {
      cluster.shutdown();
      cluster=null;
    }
  }
  /** 
 * Regression test for HDFS-3357. Check that the datanode is respecting its configured keepalive timeout.
 */
  @Test(timeout=30000) public void testDatanodeRespectsKeepAliveTimeout() throws Exception {
    Configuration clientConf=new Configuration(conf);
    final long CLIENT_EXPIRY_MS=60000L;
    clientConf.setLong(DFS_CLIENT_SOCKET_CACHE_EXPIRY_MSEC_KEY,CLIENT_EXPIRY_MS);
    clientConf.set(DFS_CLIENT_CONTEXT,"testDatanodeRespectsKeepAliveTimeout");
    DistributedFileSystem fs=(DistributedFileSystem)FileSystem.get(cluster.getURI(),clientConf);
    PeerCache peerCache=ClientContext.getFromConf(clientConf).getPeerCache();
    DFSTestUtil.createFile(fs,TEST_FILE,1L,(short)1,0L);
    assertEquals(0,peerCache.size());
    assertXceiverCount(0);
    DFSTestUtil.readFile(fs,TEST_FILE);
    assertEquals(1,peerCache.size());
    assertXceiverCount(1);
    Thread.sleep(DFS_DATANODE_SOCKET_REUSE_KEEPALIVE_DEFAULT + 50);
    assertXceiverCount(0);
    assertEquals(1,peerCache.size());
    Peer peer=peerCache.get(dn.getDatanodeId(),false);
    assertNotNull(peer);
    assertEquals(-1,peer.getInputStream().read());
  }
  /** 
 * Test that the client respects its keepalive timeout.
 */
  @Test(timeout=30000) public void testClientResponsesKeepAliveTimeout() throws Exception {
    Configuration clientConf=new Configuration(conf);
    final long CLIENT_EXPIRY_MS=10L;
    clientConf.setLong(DFS_CLIENT_SOCKET_CACHE_EXPIRY_MSEC_KEY,CLIENT_EXPIRY_MS);
    clientConf.set(DFS_CLIENT_CONTEXT,"testClientResponsesKeepAliveTimeout");
    DistributedFileSystem fs=(DistributedFileSystem)FileSystem.get(cluster.getURI(),clientConf);
    PeerCache peerCache=ClientContext.getFromConf(clientConf).getPeerCache();
    DFSTestUtil.createFile(fs,TEST_FILE,1L,(short)1,0L);
    assertEquals(0,peerCache.size());
    assertXceiverCount(0);
    DFSTestUtil.readFile(fs,TEST_FILE);
    assertEquals(1,peerCache.size());
    assertXceiverCount(1);
    Thread.sleep(CLIENT_EXPIRY_MS + 50);
    Peer peer=peerCache.get(dn.getDatanodeId(),false);
    assertTrue(peer == null);
    assertEquals(0,peerCache.size());
  }
  /** 
 * Test for the case where the client beings to read a long block, but doesn't read bytes off the stream quickly. The datanode should time out sending the chunks and the transceiver should die, even if it has a long keepalive.
 */
  @Test(timeout=300000) public void testSlowReader() throws Exception {
    final long CLIENT_EXPIRY_MS=600000L;
    Configuration clientConf=new Configuration(conf);
    clientConf.setLong(DFS_CLIENT_SOCKET_CACHE_EXPIRY_MSEC_KEY,CLIENT_EXPIRY_MS);
    clientConf.set(DFS_CLIENT_CONTEXT,"testSlowReader");
    DistributedFileSystem fs=(DistributedFileSystem)FileSystem.get(cluster.getURI(),clientConf);
    DataNodeProperties props=cluster.stopDataNode(0);
    props.conf.setInt(DFS_DATANODE_SOCKET_WRITE_TIMEOUT_KEY,WRITE_TIMEOUT);
    props.conf.setInt(DFS_DATANODE_SOCKET_REUSE_KEEPALIVE_KEY,120000);
    assertTrue(cluster.restartDataNode(props,true));
    dn=cluster.getDataNodes().get(0);
    cluster.triggerHeartbeats();
    DFSTestUtil.createFile(fs,TEST_FILE,1024 * 1024 * 8L,(short)1,0L);
    FSDataInputStream stm=fs.open(TEST_FILE);
    stm.read();
    assertXceiverCount(1);
    GenericTestUtils.waitFor(new Supplier<Boolean>(){
      public Boolean get(){
        return getXceiverCountWithoutServer() == 0;
      }
    }
,500,50000);
    IOUtils.closeStream(stm);
  }
  @Test(timeout=30000) public void testManyClosedSocketsInCache() throws Exception {
    Configuration clientConf=new Configuration(conf);
    clientConf.set(DFS_CLIENT_CONTEXT,"testManyClosedSocketsInCache");
    DistributedFileSystem fs=(DistributedFileSystem)FileSystem.get(cluster.getURI(),clientConf);
    PeerCache peerCache=ClientContext.getFromConf(clientConf).getPeerCache();
    DFSTestUtil.createFile(fs,TEST_FILE,1L,(short)1,0L);
    InputStream[] stms=new InputStream[5];
    try {
      for (int i=0; i < stms.length; i++) {
        stms[i]=fs.open(TEST_FILE);
      }
      for (      InputStream stm : stms) {
        IOUtils.copyBytes(stm,new IOUtils.NullOutputStream(),1024);
      }
    }
  finally {
      IOUtils.cleanup(null,stms);
    }
    assertEquals(5,peerCache.size());
    Thread.sleep(1500);
    assertXceiverCount(0);
    assertEquals(5,peerCache.size());
    DFSTestUtil.readFile(fs,TEST_FILE);
  }
  private void assertXceiverCount(  int expected){
    int count=getXceiverCountWithoutServer();
    if (count != expected) {
      ReflectionUtils.printThreadInfo(System.err,"Thread dumps");
      fail("Expected " + expected + " xceivers, found "+ count);
    }
  }
  /** 
 * Returns the datanode's xceiver count, but subtracts 1, since the DataXceiverServer counts as one.
 * @return int xceiver count, not including DataXceiverServer
 */
  private int getXceiverCountWithoutServer(){
    return dn.getXceiverCount() - 1;
  }
}
