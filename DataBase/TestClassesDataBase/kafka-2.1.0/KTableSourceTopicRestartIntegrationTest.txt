@Category({IntegrationTest.class}) public class KTableSourceTopicRestartIntegrationTest {
  private static final int NUM_BROKERS=3;
  private static final String SOURCE_TOPIC="source-topic";
  @ClassRule public static final EmbeddedKafkaCluster CLUSTER=new EmbeddedKafkaCluster(NUM_BROKERS);
  private final Time time=CLUSTER.time;
  private KafkaStreams streamsOne;
  private final StreamsBuilder streamsBuilder=new StreamsBuilder();
  private final Map<String,String> readKeyValues=new ConcurrentHashMap<>();
  private static final Properties PRODUCER_CONFIG=new Properties();
  private static final Properties STREAMS_CONFIG=new Properties();
  private Map<String,String> expectedInitialResultsMap;
  private Map<String,String> expectedResultsWithDataWrittenDuringRestoreMap;
  @BeforeClass public static void setUpBeforeAllTests() throws Exception {
    CLUSTER.createTopic(SOURCE_TOPIC);
    STREAMS_CONFIG.put(StreamsConfig.APPLICATION_ID_CONFIG,"ktable-restore-from-source");
    STREAMS_CONFIG.put(StreamsConfig.BOOTSTRAP_SERVERS_CONFIG,CLUSTER.bootstrapServers());
    STREAMS_CONFIG.put(StreamsConfig.DEFAULT_KEY_SERDE_CLASS_CONFIG,Serdes.String().getClass().getName());
    STREAMS_CONFIG.put(StreamsConfig.DEFAULT_VALUE_SERDE_CLASS_CONFIG,Serdes.String().getClass().getName());
    STREAMS_CONFIG.put(StreamsConfig.STATE_DIR_CONFIG,TestUtils.tempDirectory().getPath());
    STREAMS_CONFIG.put(StreamsConfig.CACHE_MAX_BYTES_BUFFERING_CONFIG,0);
    STREAMS_CONFIG.put(IntegrationTestUtils.INTERNAL_LEAVE_GROUP_ON_CLOSE,true);
    STREAMS_CONFIG.put(StreamsConfig.COMMIT_INTERVAL_MS_CONFIG,5);
    STREAMS_CONFIG.put(StreamsConfig.DEFAULT_TIMESTAMP_EXTRACTOR_CLASS_CONFIG,WallclockTimestampExtractor.class);
    PRODUCER_CONFIG.put(ProducerConfig.BOOTSTRAP_SERVERS_CONFIG,CLUSTER.bootstrapServers());
    PRODUCER_CONFIG.put(ProducerConfig.ACKS_CONFIG,"all");
    PRODUCER_CONFIG.put(ProducerConfig.KEY_SERIALIZER_CLASS_CONFIG,StringSerializer.class);
    PRODUCER_CONFIG.put(ProducerConfig.VALUE_SERIALIZER_CLASS_CONFIG,StringSerializer.class);
  }
  @Before public void before(){
    final KTable<String,String> kTable=streamsBuilder.table(SOURCE_TOPIC);
    kTable.toStream().foreach(new ForeachAction<String,String>(){
      @Override public void apply(      final String key,      final String value){
        readKeyValues.put(key,value);
      }
    }
);
    expectedInitialResultsMap=createExpectedResultsMap("a","b","c");
    expectedResultsWithDataWrittenDuringRestoreMap=createExpectedResultsMap("a","b","c","d","f","g","h");
  }
  @After public void after() throws IOException {
    IntegrationTestUtils.purgeLocalStreamsState(STREAMS_CONFIG);
  }
  @Test public void shouldRestoreAndProgressWhenTopicWrittenToDuringRestorationWithEosDisabled() throws Exception {
    try {
      streamsOne=new KafkaStreams(streamsBuilder.build(),STREAMS_CONFIG);
      streamsOne.start();
      produceKeyValues("a","b","c");
      assertNumberValuesRead(readKeyValues,expectedInitialResultsMap,"Table did not read all values");
      streamsOne.close();
      streamsOne=new KafkaStreams(streamsBuilder.build(),STREAMS_CONFIG);
      streamsOne.setGlobalStateRestoreListener(new UpdatingSourceTopicOnRestoreStartStateRestoreListener());
      streamsOne.start();
      produceKeyValues("f","g","h");
      assertNumberValuesRead(readKeyValues,expectedResultsWithDataWrittenDuringRestoreMap,"Table did not get all values after restart");
    }
  finally {
      streamsOne.close(Duration.ofSeconds(5));
    }
  }
  @Test public void shouldRestoreAndProgressWhenTopicWrittenToDuringRestorationWithEosEnabled() throws Exception {
    try {
      STREAMS_CONFIG.put(StreamsConfig.PROCESSING_GUARANTEE_CONFIG,StreamsConfig.EXACTLY_ONCE);
      streamsOne=new KafkaStreams(streamsBuilder.build(),STREAMS_CONFIG);
      streamsOne.start();
      produceKeyValues("a","b","c");
      assertNumberValuesRead(readKeyValues,expectedInitialResultsMap,"Table did not read all values");
      streamsOne.close();
      streamsOne=new KafkaStreams(streamsBuilder.build(),STREAMS_CONFIG);
      streamsOne.setGlobalStateRestoreListener(new UpdatingSourceTopicOnRestoreStartStateRestoreListener());
      streamsOne.start();
      produceKeyValues("f","g","h");
      assertNumberValuesRead(readKeyValues,expectedResultsWithDataWrittenDuringRestoreMap,"Table did not get all values after restart");
    }
  finally {
      streamsOne.close(Duration.ofSeconds(5));
    }
  }
  @Test public void shouldRestoreAndProgressWhenTopicNotWrittenToDuringRestoration() throws Exception {
    try {
      streamsOne=new KafkaStreams(streamsBuilder.build(),STREAMS_CONFIG);
      streamsOne.start();
      produceKeyValues("a","b","c");
      assertNumberValuesRead(readKeyValues,expectedInitialResultsMap,"Table did not read all values");
      streamsOne.close();
      streamsOne=new KafkaStreams(streamsBuilder.build(),STREAMS_CONFIG);
      streamsOne.start();
      produceKeyValues("f","g","h");
      final Map<String,String> expectedValues=createExpectedResultsMap("a","b","c","f","g","h");
      assertNumberValuesRead(readKeyValues,expectedValues,"Table did not get all values after restart");
    }
  finally {
      streamsOne.close(Duration.ofSeconds(5));
    }
  }
  private void assertNumberValuesRead(  final Map<String,String> valueMap,  final Map<String,String> expectedMap,  final String errorMessage) throws InterruptedException {
    TestUtils.waitForCondition(new TestCondition(){
      @Override public boolean conditionMet(){
        return valueMap.equals(expectedMap);
      }
    }
,30 * 1000L,errorMessage);
  }
  private void produceKeyValues(  final String... keys) throws ExecutionException, InterruptedException {
    final List<KeyValue<String,String>> keyValueList=new ArrayList<>();
    for (    final String key : keys) {
      keyValueList.add(new KeyValue<>(key,key + "1"));
    }
    IntegrationTestUtils.produceKeyValuesSynchronously(SOURCE_TOPIC,keyValueList,PRODUCER_CONFIG,time);
  }
  private Map<String,String> createExpectedResultsMap(  final String... keys){
    final Map<String,String> expectedMap=new HashMap<>();
    for (    final String key : keys) {
      expectedMap.put(key,key + "1");
    }
    return expectedMap;
  }
private class UpdatingSourceTopicOnRestoreStartStateRestoreListener implements StateRestoreListener {
    @Override public void onRestoreStart(    final TopicPartition topicPartition,    final String storeName,    final long startingOffset,    final long endingOffset){
      try {
        produceKeyValues("d");
      }
 catch (      final ExecutionException|InterruptedException e) {
        throw new RuntimeException(e);
      }
    }
    @Override public void onBatchRestored(    final TopicPartition topicPartition,    final String storeName,    final long batchEndOffset,    final long numRestored){
    }
    @Override public void onRestoreEnd(    final TopicPartition topicPartition,    final String storeName,    final long totalRestored){
    }
  }
}
