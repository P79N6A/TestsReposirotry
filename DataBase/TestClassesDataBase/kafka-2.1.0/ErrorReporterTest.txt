@RunWith(PowerMockRunner.class) @PowerMockIgnore("javax.management.*") public class ErrorReporterTest {
  private static final String TOPIC="test-topic";
  private static final String DLQ_TOPIC="test-topic-errors";
  private static final ConnectorTaskId TASK_ID=new ConnectorTaskId("job",0);
  @Mock KafkaProducer<byte[],byte[]> producer;
  @Mock Future<RecordMetadata> metadata;
  @Mock Plugins plugins;
  private ErrorHandlingMetrics errorHandlingMetrics;
  private MockConnectMetrics metrics;
  @Before public void setup(){
    metrics=new MockConnectMetrics();
    errorHandlingMetrics=new ErrorHandlingMetrics(new ConnectorTaskId("connector-",1),metrics);
  }
  @After public void tearDown(){
    if (metrics != null) {
      metrics.stop();
    }
  }
  @Test(expected=NullPointerException.class) public void initializeDLQWithNullMetrics(){
    new DeadLetterQueueReporter(producer,config(emptyMap()),TASK_ID,null);
  }
  @Test public void testDLQConfigWithEmptyTopicName(){
    DeadLetterQueueReporter deadLetterQueueReporter=new DeadLetterQueueReporter(producer,config(emptyMap()),TASK_ID,errorHandlingMetrics);
    ProcessingContext context=processingContext();
    EasyMock.expect(producer.send(EasyMock.anyObject(),EasyMock.anyObject())).andThrow(new RuntimeException());
    replay(producer);
    deadLetterQueueReporter.report(context);
  }
  @Test public void testDLQConfigWithValidTopicName(){
    DeadLetterQueueReporter deadLetterQueueReporter=new DeadLetterQueueReporter(producer,config(singletonMap(SinkConnectorConfig.DLQ_TOPIC_NAME_CONFIG,DLQ_TOPIC)),TASK_ID,errorHandlingMetrics);
    ProcessingContext context=processingContext();
    EasyMock.expect(producer.send(EasyMock.anyObject(),EasyMock.anyObject())).andReturn(metadata);
    replay(producer);
    deadLetterQueueReporter.report(context);
    PowerMock.verifyAll();
  }
  @Test public void testReportDLQTwice(){
    DeadLetterQueueReporter deadLetterQueueReporter=new DeadLetterQueueReporter(producer,config(singletonMap(SinkConnectorConfig.DLQ_TOPIC_NAME_CONFIG,DLQ_TOPIC)),TASK_ID,errorHandlingMetrics);
    ProcessingContext context=processingContext();
    EasyMock.expect(producer.send(EasyMock.anyObject(),EasyMock.anyObject())).andReturn(metadata).times(2);
    replay(producer);
    deadLetterQueueReporter.report(context);
    deadLetterQueueReporter.report(context);
    PowerMock.verifyAll();
  }
  @Test public void testLogOnDisabledLogReporter(){
    LogReporter logReporter=new LogReporter(TASK_ID,config(emptyMap()),errorHandlingMetrics);
    ProcessingContext context=processingContext();
    context.error(new RuntimeException());
    logReporter.report(context);
    assertErrorHandlingMetricValue("total-errors-logged",0.0);
  }
  @Test public void testLogOnEnabledLogReporter(){
    LogReporter logReporter=new LogReporter(TASK_ID,config(singletonMap(ConnectorConfig.ERRORS_LOG_ENABLE_CONFIG,"true")),errorHandlingMetrics);
    ProcessingContext context=processingContext();
    context.error(new RuntimeException());
    logReporter.report(context);
    assertErrorHandlingMetricValue("total-errors-logged",1.0);
  }
  @Test public void testLogMessageWithNoRecords(){
    LogReporter logReporter=new LogReporter(TASK_ID,config(singletonMap(ConnectorConfig.ERRORS_LOG_ENABLE_CONFIG,"true")),errorHandlingMetrics);
    ProcessingContext context=processingContext();
    String msg=logReporter.message(context);
    assertEquals("Error encountered in task job-0. Executing stage 'KEY_CONVERTER' with class " + "'org.apache.kafka.connect.json.JsonConverter'.",msg);
  }
  @Test public void testLogMessageWithSinkRecords(){
    Map<String,String> props=new HashMap<>();
    props.put(ConnectorConfig.ERRORS_LOG_ENABLE_CONFIG,"true");
    props.put(ConnectorConfig.ERRORS_LOG_INCLUDE_MESSAGES_CONFIG,"true");
    LogReporter logReporter=new LogReporter(TASK_ID,config(props),errorHandlingMetrics);
    ProcessingContext context=processingContext();
    String msg=logReporter.message(context);
    assertEquals("Error encountered in task job-0. Executing stage 'KEY_CONVERTER' with class " + "'org.apache.kafka.connect.json.JsonConverter', where consumed record is {topic='test-topic', " + "partition=5, offset=100}.",msg);
  }
  @Test public void testSetDLQConfigs(){
    SinkConnectorConfig configuration=config(singletonMap(SinkConnectorConfig.DLQ_TOPIC_NAME_CONFIG,DLQ_TOPIC));
    assertEquals(configuration.dlqTopicName(),DLQ_TOPIC);
    configuration=config(singletonMap(SinkConnectorConfig.DLQ_TOPIC_REPLICATION_FACTOR_CONFIG,"7"));
    assertEquals(configuration.dlqTopicReplicationFactor(),7);
  }
  @Test public void testDlqHeaderConsumerRecord(){
    Map<String,String> props=new HashMap<>();
    props.put(SinkConnectorConfig.DLQ_TOPIC_NAME_CONFIG,DLQ_TOPIC);
    props.put(SinkConnectorConfig.DLQ_CONTEXT_HEADERS_ENABLE_CONFIG,"true");
    DeadLetterQueueReporter deadLetterQueueReporter=new DeadLetterQueueReporter(producer,config(props),TASK_ID,errorHandlingMetrics);
    ProcessingContext context=new ProcessingContext();
    context.consumerRecord(new ConsumerRecord<>("source-topic",7,10,"source-key".getBytes(),"source-value".getBytes()));
    context.currentContext(Stage.TRANSFORMATION,Transformation.class);
    context.error(new ConnectException("Test Exception"));
    ProducerRecord<byte[],byte[]> producerRecord=new ProducerRecord<>(DLQ_TOPIC,"source-key".getBytes(),"source-value".getBytes());
    deadLetterQueueReporter.populateContextHeaders(producerRecord,context);
    assertEquals("source-topic",headerValue(producerRecord,ERROR_HEADER_ORIG_TOPIC));
    assertEquals("7",headerValue(producerRecord,ERROR_HEADER_ORIG_PARTITION));
    assertEquals("10",headerValue(producerRecord,ERROR_HEADER_ORIG_OFFSET));
    assertEquals(TASK_ID.connector(),headerValue(producerRecord,ERROR_HEADER_CONNECTOR_NAME));
    assertEquals(String.valueOf(TASK_ID.task()),headerValue(producerRecord,ERROR_HEADER_TASK_ID));
    assertEquals(Stage.TRANSFORMATION.name(),headerValue(producerRecord,ERROR_HEADER_STAGE));
    assertEquals(Transformation.class.getName(),headerValue(producerRecord,ERROR_HEADER_EXECUTING_CLASS));
    assertEquals(ConnectException.class.getName(),headerValue(producerRecord,ERROR_HEADER_EXCEPTION));
    assertEquals("Test Exception",headerValue(producerRecord,ERROR_HEADER_EXCEPTION_MESSAGE));
    assertTrue(headerValue(producerRecord,ERROR_HEADER_EXCEPTION_STACK_TRACE).length() > 0);
    assertTrue(headerValue(producerRecord,ERROR_HEADER_EXCEPTION_STACK_TRACE).startsWith("org.apache.kafka.connect.errors.ConnectException: Test Exception"));
  }
  @Test public void testDlqHeaderOnNullExceptionMessage(){
    Map<String,String> props=new HashMap<>();
    props.put(SinkConnectorConfig.DLQ_TOPIC_NAME_CONFIG,DLQ_TOPIC);
    props.put(SinkConnectorConfig.DLQ_CONTEXT_HEADERS_ENABLE_CONFIG,"true");
    DeadLetterQueueReporter deadLetterQueueReporter=new DeadLetterQueueReporter(producer,config(props),TASK_ID,errorHandlingMetrics);
    ProcessingContext context=new ProcessingContext();
    context.consumerRecord(new ConsumerRecord<>("source-topic",7,10,"source-key".getBytes(),"source-value".getBytes()));
    context.currentContext(Stage.TRANSFORMATION,Transformation.class);
    context.error(new NullPointerException());
    ProducerRecord<byte[],byte[]> producerRecord=new ProducerRecord<>(DLQ_TOPIC,"source-key".getBytes(),"source-value".getBytes());
    deadLetterQueueReporter.populateContextHeaders(producerRecord,context);
    assertEquals("source-topic",headerValue(producerRecord,ERROR_HEADER_ORIG_TOPIC));
    assertEquals("7",headerValue(producerRecord,ERROR_HEADER_ORIG_PARTITION));
    assertEquals("10",headerValue(producerRecord,ERROR_HEADER_ORIG_OFFSET));
    assertEquals(TASK_ID.connector(),headerValue(producerRecord,ERROR_HEADER_CONNECTOR_NAME));
    assertEquals(String.valueOf(TASK_ID.task()),headerValue(producerRecord,ERROR_HEADER_TASK_ID));
    assertEquals(Stage.TRANSFORMATION.name(),headerValue(producerRecord,ERROR_HEADER_STAGE));
    assertEquals(Transformation.class.getName(),headerValue(producerRecord,ERROR_HEADER_EXECUTING_CLASS));
    assertEquals(NullPointerException.class.getName(),headerValue(producerRecord,ERROR_HEADER_EXCEPTION));
    assertNull(producerRecord.headers().lastHeader(ERROR_HEADER_EXCEPTION_MESSAGE).value());
    assertTrue(headerValue(producerRecord,ERROR_HEADER_EXCEPTION_STACK_TRACE).length() > 0);
    assertTrue(headerValue(producerRecord,ERROR_HEADER_EXCEPTION_STACK_TRACE).startsWith("java.lang.NullPointerException"));
  }
  @Test public void testDlqHeaderIsAppended(){
    Map<String,String> props=new HashMap<>();
    props.put(SinkConnectorConfig.DLQ_TOPIC_NAME_CONFIG,DLQ_TOPIC);
    props.put(SinkConnectorConfig.DLQ_CONTEXT_HEADERS_ENABLE_CONFIG,"true");
    DeadLetterQueueReporter deadLetterQueueReporter=new DeadLetterQueueReporter(producer,config(props),TASK_ID,errorHandlingMetrics);
    ProcessingContext context=new ProcessingContext();
    context.consumerRecord(new ConsumerRecord<>("source-topic",7,10,"source-key".getBytes(),"source-value".getBytes()));
    context.currentContext(Stage.TRANSFORMATION,Transformation.class);
    context.error(new ConnectException("Test Exception"));
    ProducerRecord<byte[],byte[]> producerRecord=new ProducerRecord<>(DLQ_TOPIC,"source-key".getBytes(),"source-value".getBytes());
    producerRecord.headers().add(ERROR_HEADER_ORIG_TOPIC,"dummy".getBytes());
    deadLetterQueueReporter.populateContextHeaders(producerRecord,context);
    int appearances=0;
    for (    Header header : producerRecord.headers()) {
      if (ERROR_HEADER_ORIG_TOPIC.equalsIgnoreCase(header.key())) {
        appearances++;
      }
    }
    assertEquals("source-topic",headerValue(producerRecord,ERROR_HEADER_ORIG_TOPIC));
    assertEquals(2,appearances);
  }
  private String headerValue(  ProducerRecord<byte[],byte[]> producerRecord,  String headerSuffix){
    return new String(producerRecord.headers().lastHeader(headerSuffix).value());
  }
  private ProcessingContext processingContext(){
    ProcessingContext context=new ProcessingContext();
    context.consumerRecord(new ConsumerRecord<>(TOPIC,5,100,new byte[]{'a','b'},new byte[]{'x'}));
    context.currentContext(Stage.KEY_CONVERTER,JsonConverter.class);
    return context;
  }
  private SinkConnectorConfig config(  Map<String,String> configProps){
    Map<String,String> props=new HashMap<>();
    props.put(ConnectorConfig.NAME_CONFIG,"test");
    props.put(ConnectorConfig.CONNECTOR_CLASS_CONFIG,SinkTask.class.getName());
    props.putAll(configProps);
    return new SinkConnectorConfig(plugins,props);
  }
  private void assertErrorHandlingMetricValue(  String name,  double expected){
    ConnectMetrics.MetricGroup sinkTaskGroup=errorHandlingMetrics.metricGroup();
    double measured=metrics.currentMetricValueAsDouble(sinkTaskGroup,name);
    assertEquals(expected,measured,0.001d);
  }
}
