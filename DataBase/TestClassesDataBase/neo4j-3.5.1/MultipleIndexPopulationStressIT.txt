/** 
 * Idea is to test a  {@link MultipleIndexPopulator} and {@link BatchingMultipleIndexPopulator} with a bunch of indexes,some which can fail randomly. Also updates are randomly streaming in during population. In the end all the indexes should have been populated with correct data.
 */
public class MultipleIndexPopulationStressIT {
  private static final String[] TOKENS=new String[]{"One","Two","Three","Four"};
  private final TestDirectory directory=TestDirectory.testDirectory();
  private final RandomRule random=new RandomRule();
  private final CleanupRule cleanup=new CleanupRule();
  private final RepeatRule repeat=new RepeatRule();
  private final DefaultFileSystemRule fileSystemRule=new DefaultFileSystemRule();
  @Rule public final RuleChain ruleChain=RuleChain.outerRule(random).around(repeat).around(directory).around(cleanup).around(fileSystemRule);
  @Test public void populateMultipleIndexWithSeveralNodesSingleThreaded() throws Exception {
    prepareAndRunTest(false,10,TimeUnit.SECONDS.toMillis(5));
  }
  @Test public void populateMultipleIndexWithSeveralNodesMultiThreaded() throws Exception {
    prepareAndRunTest(true,10,TimeUnit.SECONDS.toMillis(5));
  }
  @Test public void shouldPopulateMultipleIndexPopulatorsUnderStressSingleThreaded() throws Exception {
    readConfigAndRunTest(false);
  }
  @Test public void shouldPopulateMultipleIndexPopulatorsUnderStressMultiThreaded() throws Exception {
    int concurrentUpdatesQueueFlushThreshold=random.nextInt(100,5000);
    FeatureToggles.set(BatchingMultipleIndexPopulator.class,BatchingMultipleIndexPopulator.QUEUE_THRESHOLD_NAME,concurrentUpdatesQueueFlushThreshold);
    try {
      readConfigAndRunTest(true);
    }
  finally {
      FeatureToggles.clear(BatchingMultipleIndexPopulator.class,BatchingMultipleIndexPopulator.QUEUE_THRESHOLD_NAME);
    }
  }
  private void readConfigAndRunTest(  boolean multiThreaded) throws Exception {
    int nodeCount=(int)Settings.parseLongWithUnit(System.getProperty(getClass().getName() + ".nodes","200k"));
    long duration=TimeUtil.parseTimeMillis.apply(System.getProperty(getClass().getName() + ".duration","5s"));
    prepareAndRunTest(multiThreaded,nodeCount,duration);
  }
  private void prepareAndRunTest(  boolean multiThreaded,  int nodeCount,  long durationMillis) throws Exception {
    createRandomData(nodeCount);
    long endTime=currentTimeMillis() + durationMillis;
    for (int i=0; currentTimeMillis() < endTime; i++) {
      runTest(nodeCount,i,multiThreaded);
    }
  }
  private void runTest(  int nodeCount,  int run,  boolean multiThreaded) throws Exception {
    populateDbAndIndexes(nodeCount,multiThreaded);
    ConsistencyCheckService cc=new ConsistencyCheckService();
    Result result=cc.runFullConsistencyCheck(directory.databaseLayout(),Config.defaults(GraphDatabaseSettings.pagecache_memory,"8m"),NONE,NullLogProvider.getInstance(),false);
    assertTrue(result.isSuccessful());
    dropIndexes();
  }
  private void populateDbAndIndexes(  int nodeCount,  boolean multiThreaded) throws InterruptedException {
    final GraphDatabaseService db=new TestGraphDatabaseFactory().newEmbeddedDatabaseBuilder(directory.databaseDir()).setConfig(GraphDatabaseSettings.multi_threaded_schema_index_population_enabled,multiThreaded + "").newGraphDatabase();
    try {
      createIndexes(db);
      final AtomicBoolean end=new AtomicBoolean();
      ExecutorService executor=cleanup.add(Executors.newCachedThreadPool());
      for (int i=0; i < 10; i++) {
        executor.submit(() -> {
          RandomValues randomValues=RandomValues.create();
          while (!end.get()) {
            changeRandomNode(db,nodeCount,randomValues);
          }
        }
);
      }
      while (!indexesAreOnline(db)) {
        Thread.sleep(100);
      }
      end.set(true);
      executor.shutdown();
      executor.awaitTermination(10,SECONDS);
    }
  finally {
      db.shutdown();
    }
  }
  private void dropIndexes(){
    GraphDatabaseService db=new TestGraphDatabaseFactory().newEmbeddedDatabaseBuilder(directory.databaseDir()).setConfig(GraphDatabaseSettings.pagecache_memory,"8m").newGraphDatabase();
    try (Transaction tx=db.beginTx()){
      for (      IndexDefinition index : db.schema().getIndexes()) {
        index.drop();
      }
      tx.success();
    }
  finally {
      db.shutdown();
    }
  }
  private boolean indexesAreOnline(  GraphDatabaseService db){
    try (Transaction tx=db.beginTx()){
      for (      IndexDefinition index : db.schema().getIndexes()) {
switch (db.schema().getIndexState(index)) {
case ONLINE:
          break;
case POPULATING:
        return false;
case FAILED:
      fail(index + " entered failed state: " + db.schema().getIndexFailure(index));
default :
    throw new UnsupportedOperationException();
}
}
tx.success();
}
 return true;
}
/** 
 * Create a bunch of indexes in a single transaction. This will have all the indexes being built using a single store scan... and this is the gist of what we're testing.
 */
private void createIndexes(GraphDatabaseService db){
try (Transaction tx=db.beginTx()){
for (String label : random.selection(TOKENS,3,3,false)) {
for (String propertyKey : random.selection(TOKENS,3,3,false)) {
  db.schema().indexFor(Label.label(label)).on(propertyKey).create();
}
}
tx.success();
}
 }
private void changeRandomNode(GraphDatabaseService db,int nodeCount,RandomValues random){
try (Transaction tx=db.beginTx()){
long nodeId=random.nextInt(nodeCount);
Node node=db.getNodeById(nodeId);
Object[] keys=Iterables.asCollection(node.getPropertyKeys()).toArray();
String key=(String)random.among(keys);
if (random.nextFloat() < 0.1) {
node.removeProperty(key);
}
 else {
node.setProperty(key,random.nextValue().asObject());
}
tx.success();
}
 catch (NotFoundException e) {
}
}
private void createRandomData(int count) throws Exception {
Config config=Config.defaults();
RecordFormats recordFormats=RecordFormatSelector.selectForConfig(config,NullLogProvider.getInstance());
try (RandomDataInput input=new RandomDataInput(count);JobScheduler jobScheduler=new ThreadPoolJobScheduler()){
BatchImporter importer=new ParallelBatchImporter(directory.databaseLayout(),fileSystemRule.get(),null,DEFAULT,NullLogService.getInstance(),ExecutionMonitors.invisible(),EMPTY,config,recordFormats,NO_MONITOR,jobScheduler);
importer.doImport(input);
}
 }
private class RandomNodeGenerator extends GeneratingInputIterator<RandomValues> {
RandomNodeGenerator(int count,Generator<RandomValues> randomsGenerator){
super(count,1_000,new RandomsStates(random.seed()),randomsGenerator,0);
}
}
private class RandomDataInput implements Input, AutoCloseable {
private final int count;
private final BadCollector badCollector;
RandomDataInput(int count){
this.count=count;
this.badCollector=createBadCollector();
}
@Override public InputIterable relationships(){
return EMPTY_ITERABLE;
}
@Override public InputIterable nodes(){
return () -> new RandomNodeGenerator(count,(state,visitor,id) -> {
String[] keys=random.randomValues().selection(TOKENS,1,TOKENS.length,false);
for (String key : keys) {
  visitor.property(key,random.nextValueAsObject());
}
visitor.labels(random.selection(TOKENS,1,TOKENS.length,false));
}
);
}
@Override public IdMapper idMapper(NumberArrayFactory numberArrayFactory){
return IdMappers.actual();
}
@Override public Collector badCollector(){
return badCollector;
}
private BadCollector createBadCollector(){
try {
return new BadCollector(fileSystemRule.get().openAsOutputStream(new File(directory.databaseDir(),"bad"),false),0,0);
}
 catch (IOException e) {
throw new RuntimeException(e);
}
}
@Override public Estimates calculateEstimates(ToIntFunction<Value[]> valueSizeCalculator){
return knownEstimates(count,0,count * TOKENS.length / 2,0,count * TOKENS.length / 2 * Long.BYTES,0,0);
}
@Override public void close(){
badCollector.close();
}
}
}
