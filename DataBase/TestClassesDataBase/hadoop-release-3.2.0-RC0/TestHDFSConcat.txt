public class TestHDFSConcat {
  public static final Logger LOG=LoggerFactory.getLogger(TestHDFSConcat.class);
  private static final short REPL_FACTOR=2;
  private MiniDFSCluster cluster;
  private NamenodeProtocols nn;
  private DistributedFileSystem dfs;
  private static final long blockSize=512;
  private static final Configuration conf;
static {
    conf=new Configuration();
    conf.setLong(DFSConfigKeys.DFS_BLOCK_SIZE_KEY,blockSize);
  }
  @Before public void startUpCluster() throws IOException {
    cluster=new MiniDFSCluster.Builder(conf).numDataNodes(REPL_FACTOR).build();
    assertNotNull("Failed Cluster Creation",cluster);
    cluster.waitClusterUp();
    dfs=cluster.getFileSystem();
    assertNotNull("Failed to get FileSystem",dfs);
    nn=cluster.getNameNodeRpc();
    assertNotNull("Failed to get NameNode",nn);
  }
  @After public void shutDownCluster() throws IOException {
    if (dfs != null) {
      dfs.close();
      dfs=null;
    }
    if (cluster != null) {
      cluster.shutdownDataNodes();
      cluster.shutdown();
      cluster=null;
    }
  }
  /** 
 * Concatenates 10 files into one Verifies the final size, deletion of the file, number of blocks
 * @throws IOException
 */
  @Test public void testConcat() throws IOException, InterruptedException {
    final int numFiles=10;
    long fileLen=blockSize * 3;
    HdfsFileStatus fStatus;
    FSDataInputStream stm;
    String trg="/trg";
    Path trgPath=new Path(trg);
    DFSTestUtil.createFile(dfs,trgPath,fileLen,REPL_FACTOR,1);
    fStatus=nn.getFileInfo(trg);
    long trgLen=fStatus.getLen();
    long trgBlocks=nn.getBlockLocations(trg,0,trgLen).locatedBlockCount();
    Path[] files=new Path[numFiles];
    byte[][] bytes=new byte[numFiles + 1][(int)fileLen];
    LocatedBlocks[] lblocks=new LocatedBlocks[numFiles];
    long[] lens=new long[numFiles];
    stm=dfs.open(trgPath);
    stm.readFully(0,bytes[0]);
    stm.close();
    int i;
    for (i=0; i < files.length; i++) {
      files[i]=new Path("/file" + i);
      Path path=files[i];
      System.out.println("Creating file " + path);
      DFSTestUtil.createFile(dfs,path,fileLen,REPL_FACTOR,i);
      fStatus=nn.getFileInfo(path.toUri().getPath());
      lens[i]=fStatus.getLen();
      assertEquals(trgLen,lens[i]);
      lblocks[i]=nn.getBlockLocations(path.toUri().getPath(),0,lens[i]);
      stm=dfs.open(path);
      stm.readFully(0,bytes[i + 1]);
      stm.close();
    }
    final UserGroupInformation user1=UserGroupInformation.createUserForTesting("theDoctor",new String[]{"tardis"});
    DistributedFileSystem hdfs=(DistributedFileSystem)DFSTestUtil.getFileSystemAs(user1,conf);
    try {
      hdfs.concat(trgPath,files);
      fail("Permission exception expected");
    }
 catch (    IOException ie) {
      System.out.println("Got expected exception for permissions:" + ie.getLocalizedMessage());
    }
    ContentSummary cBefore=dfs.getContentSummary(trgPath.getParent());
    for (int j=0; j < files.length / 2; j++) {
      Path tempPath=files[j];
      files[j]=files[files.length - 1 - j];
      files[files.length - 1 - j]=tempPath;
      byte[] tempBytes=bytes[1 + j];
      bytes[1 + j]=bytes[files.length - 1 - j + 1];
      bytes[files.length - 1 - j + 1]=tempBytes;
    }
    dfs.concat(trgPath,files);
    ContentSummary cAfter=dfs.getContentSummary(trgPath.getParent());
    assertEquals(cBefore.getFileCount(),cAfter.getFileCount() + files.length);
    long totalLen=trgLen;
    long totalBlocks=trgBlocks;
    for (i=0; i < files.length; i++) {
      totalLen+=lens[i];
      totalBlocks+=lblocks[i].locatedBlockCount();
    }
    System.out.println("total len=" + totalLen + "; totalBlocks="+ totalBlocks);
    fStatus=nn.getFileInfo(trg);
    trgLen=fStatus.getLen();
    stm=dfs.open(trgPath);
    byte[] byteFileConcat=new byte[(int)trgLen];
    stm.readFully(0,byteFileConcat);
    stm.close();
    trgBlocks=nn.getBlockLocations(trg,0,trgLen).locatedBlockCount();
    assertEquals(trgBlocks,totalBlocks);
    assertEquals(trgLen,totalLen);
    for (    Path p : files) {
      fStatus=nn.getFileInfo(p.toUri().getPath());
      assertNull("File " + p + " still exists",fStatus);
      DFSTestUtil.createFile(dfs,p,fileLen,REPL_FACTOR,1);
    }
    checkFileContent(byteFileConcat,bytes);
    Path smallFile=new Path("/sfile");
    int sFileLen=10;
    DFSTestUtil.createFile(dfs,smallFile,sFileLen,REPL_FACTOR,1);
    dfs.concat(trgPath,new Path[]{smallFile});
    fStatus=nn.getFileInfo(trg);
    trgLen=fStatus.getLen();
    trgBlocks=nn.getBlockLocations(trg,0,trgLen).locatedBlockCount();
    assertEquals(trgBlocks,totalBlocks + 1);
    assertEquals(trgLen,totalLen + sFileLen);
  }
  /** 
 * Test that the concat operation is properly persisted in the edit log, and properly replayed on restart.
 */
  @Test public void testConcatInEditLog() throws Exception {
    final Path TEST_DIR=new Path("/testConcatInEditLog");
    final long FILE_LEN=blockSize;
    Path[] srcFiles=new Path[3];
    for (int i=0; i < srcFiles.length; i++) {
      Path path=new Path(TEST_DIR,"src-" + i);
      DFSTestUtil.createFile(dfs,path,FILE_LEN,REPL_FACTOR,1);
      srcFiles[i]=path;
    }
    Path targetFile=new Path(TEST_DIR,"target");
    DFSTestUtil.createFile(dfs,targetFile,FILE_LEN,REPL_FACTOR,1);
    dfs.concat(targetFile,srcFiles);
    assertTrue(dfs.exists(targetFile));
    FileStatus origStatus=dfs.getFileStatus(targetFile);
    cluster.restartNameNode(true);
    assertTrue(dfs.exists(targetFile));
    assertFalse(dfs.exists(srcFiles[0]));
    FileStatus statusAfterRestart=dfs.getFileStatus(targetFile);
    assertEquals(origStatus.getModificationTime(),statusAfterRestart.getModificationTime());
  }
  private void checkFileContent(  byte[] concat,  byte[][] bytes){
    int idx=0;
    boolean mismatch=false;
    for (    byte[] bb : bytes) {
      for (      byte b : bb) {
        if (b != concat[idx++]) {
          mismatch=true;
          break;
        }
      }
      if (mismatch)       break;
    }
    assertFalse("File content of concatenated file is different",mismatch);
  }
  @Test public void testConcatNotCompleteBlock() throws IOException {
    long trgFileLen=blockSize * 3;
    long srcFileLen=blockSize * 3 + 20;
    String name1="/trg", name2="/src";
    Path filePath1=new Path(name1);
    DFSTestUtil.createFile(dfs,filePath1,trgFileLen,REPL_FACTOR,1);
    HdfsFileStatus fStatus=nn.getFileInfo(name1);
    long fileLen=fStatus.getLen();
    assertEquals(fileLen,trgFileLen);
    FSDataInputStream stm=dfs.open(filePath1);
    byte[] byteFile1=new byte[(int)trgFileLen];
    stm.readFully(0,byteFile1);
    stm.close();
    LocatedBlocks lb1=nn.getBlockLocations(name1,0,trgFileLen);
    Path filePath2=new Path(name2);
    DFSTestUtil.createFile(dfs,filePath2,srcFileLen,REPL_FACTOR,1);
    fStatus=nn.getFileInfo(name2);
    fileLen=fStatus.getLen();
    assertEquals(srcFileLen,fileLen);
    stm=dfs.open(filePath2);
    byte[] byteFile2=new byte[(int)srcFileLen];
    stm.readFully(0,byteFile2);
    stm.close();
    LocatedBlocks lb2=nn.getBlockLocations(name2,0,srcFileLen);
    System.out.println("trg len=" + trgFileLen + "; src len="+ srcFileLen);
    dfs.concat(filePath1,new Path[]{filePath2});
    long totalLen=trgFileLen + srcFileLen;
    fStatus=nn.getFileInfo(name1);
    fileLen=fStatus.getLen();
    stm=dfs.open(filePath1);
    byte[] byteFileConcat=new byte[(int)fileLen];
    stm.readFully(0,byteFileConcat);
    stm.close();
    LocatedBlocks lbConcat=nn.getBlockLocations(name1,0,fileLen);
    assertEquals(lbConcat.locatedBlockCount(),lb1.locatedBlockCount() + lb2.locatedBlockCount());
    System.out.println("file1 len=" + fileLen + "; total len="+ totalLen);
    assertEquals(fileLen,totalLen);
    fStatus=nn.getFileInfo(name2);
    assertNull("File " + name2 + "still exists",fStatus);
    checkFileContent(byteFileConcat,new byte[][]{byteFile1,byteFile2});
  }
  /** 
 * test illegal args cases
 */
  @Test public void testIllegalArg() throws IOException {
    long fileLen=blockSize * 3;
    Path parentDir=new Path("/parentTrg");
    assertTrue(dfs.mkdirs(parentDir));
    Path trg=new Path(parentDir,"trg");
    DFSTestUtil.createFile(dfs,trg,fileLen,REPL_FACTOR,1);
{
      Path dir1=new Path("/dir1");
      assertTrue(dfs.mkdirs(dir1));
      Path src=new Path(dir1,"src");
      DFSTestUtil.createFile(dfs,src,fileLen,REPL_FACTOR,1);
      try {
        dfs.concat(trg,new Path[]{src});
        fail("didn't fail for src and trg in different directories");
      }
 catch (      Exception e) {
      }
    }
    try {
      dfs.concat(trg,new Path[]{new Path("test1/a")});
      fail("didn't fail with invalid arguments");
    }
 catch (    Exception e) {
    }
    try {
      dfs.concat(trg,new Path[]{});
      fail("didn't fail with invalid arguments");
    }
 catch (    Exception e) {
    }
{
      final Path src1=new Path(parentDir,"src1");
      DFSTestUtil.createFile(dfs,src1,fileLen,REPL_FACTOR,0L);
      final Path src2=new Path(parentDir,"src2");
      DFSTestUtil.createFile(dfs,src2,1024,fileLen,dfs.getDefaultBlockSize(trg) * 2,REPL_FACTOR,0L);
      try {
        dfs.concat(trg,new Path[]{src1,src2});
        fail("didn't fail for src with greater preferred block size");
      }
 catch (      Exception e) {
        GenericTestUtils.assertExceptionContains("preferred block size",e);
      }
    }
  }
  /** 
 * make sure we update the quota correctly after concat
 */
  @Test public void testConcatWithQuotaDecrease() throws IOException {
    final short srcRepl=3;
    final int srcNum=10;
    final Path foo=new Path("/foo");
    final Path[] srcs=new Path[srcNum];
    final Path target=new Path(foo,"target");
    DFSTestUtil.createFile(dfs,target,blockSize,REPL_FACTOR,0L);
    dfs.setQuota(foo,Long.MAX_VALUE - 1,Long.MAX_VALUE - 1);
    for (int i=0; i < srcNum; i++) {
      srcs[i]=new Path(foo,"src" + i);
      DFSTestUtil.createFile(dfs,srcs[i],blockSize * 2,srcRepl,0L);
    }
    ContentSummary summary=dfs.getContentSummary(foo);
    Assert.assertEquals(11,summary.getFileCount());
    Assert.assertEquals(blockSize * REPL_FACTOR + blockSize * 2 * srcRepl* srcNum,summary.getSpaceConsumed());
    dfs.concat(target,srcs);
    summary=dfs.getContentSummary(foo);
    Assert.assertEquals(1,summary.getFileCount());
    Assert.assertEquals(blockSize * REPL_FACTOR + blockSize * 2 * REPL_FACTOR* srcNum,summary.getSpaceConsumed());
  }
  @Test public void testConcatWithQuotaIncrease() throws IOException {
    final short repl=3;
    final int srcNum=10;
    final Path foo=new Path("/foo");
    final Path bar=new Path(foo,"bar");
    final Path[] srcs=new Path[srcNum];
    final Path target=new Path(bar,"target");
    DFSTestUtil.createFile(dfs,target,blockSize,repl,0L);
    final long dsQuota=blockSize * repl + blockSize * srcNum * REPL_FACTOR;
    dfs.setQuota(foo,Long.MAX_VALUE - 1,dsQuota);
    for (int i=0; i < srcNum; i++) {
      srcs[i]=new Path(bar,"src" + i);
      DFSTestUtil.createFile(dfs,srcs[i],blockSize,REPL_FACTOR,0L);
    }
    ContentSummary summary=dfs.getContentSummary(bar);
    Assert.assertEquals(11,summary.getFileCount());
    Assert.assertEquals(dsQuota,summary.getSpaceConsumed());
    try {
      dfs.concat(target,srcs);
      fail("QuotaExceededException expected");
    }
 catch (    RemoteException e) {
      Assert.assertTrue(e.unwrapRemoteException() instanceof QuotaExceededException);
    }
    dfs.setQuota(foo,Long.MAX_VALUE - 1,Long.MAX_VALUE - 1);
    dfs.concat(target,srcs);
    summary=dfs.getContentSummary(bar);
    Assert.assertEquals(1,summary.getFileCount());
    Assert.assertEquals(blockSize * repl * (srcNum + 1),summary.getSpaceConsumed());
  }
  @Test public void testConcatRelativeTargetPath() throws IOException {
    Path dir=new Path("/dir");
    Path trg=new Path("trg");
    Path src=new Path(dir,"src");
    dfs.setWorkingDirectory(dir);
    DFSTestUtil.createFile(dfs,trg,blockSize,REPL_FACTOR,1);
    DFSTestUtil.createFile(dfs,src,blockSize,REPL_FACTOR,1);
    dfs.concat(trg,new Path[]{src});
    assertEquals(blockSize * 2,dfs.getFileStatus(trg).getLen());
    assertFalse(dfs.exists(src));
  }
  @Test(timeout=30000) public void testConcatReservedRelativePaths() throws IOException {
    String testPathDir="/.reserved/raw/ezone";
    Path dir=new Path(testPathDir);
    dfs.mkdirs(dir);
    Path trg=new Path(testPathDir,"trg");
    Path src=new Path(testPathDir,"src");
    DFSTestUtil.createFile(dfs,trg,blockSize,REPL_FACTOR,1);
    DFSTestUtil.createFile(dfs,src,blockSize,REPL_FACTOR,1);
    try {
      dfs.concat(trg,new Path[]{src});
      Assert.fail("Must throw Exception!");
    }
 catch (    IOException e) {
      String errMsg="Concat operation doesn't support " + FSDirectory.DOT_RESERVED_STRING + " relative path : "+ trg;
      GenericTestUtils.assertExceptionContains(errMsg,e);
    }
  }
}
