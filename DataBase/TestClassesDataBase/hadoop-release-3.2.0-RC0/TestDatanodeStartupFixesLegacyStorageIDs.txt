/** 
 * The test verifies that legacy storage IDs in older DataNode images are replaced with UUID-based storage IDs. The startup may or may not involve a Datanode Layout upgrade. Each test case uses the following resource files. 1. testCaseName.tgz - NN and DN directories corresponding to a specific layout version. 2. testCaseName.txt - Text file listing the checksum of each file in the cluster and overall checksum. See TestUpgradeFromImage for the file format. If any test case is renamed then the corresponding resource files must also be renamed.
 */
public class TestDatanodeStartupFixesLegacyStorageIDs {
  /** 
 * Perform a upgrade using the test image corresponding to testCaseName.
 * @param testCaseName
 * @param expectedStorageId if null, then the upgrade generates a newunique storage ID.
 * @throws IOException
 */
  private static void runLayoutUpgradeTest(  final String testCaseName,  final String expectedStorageId) throws IOException {
    TestDFSUpgradeFromImage upgrade=new TestDFSUpgradeFromImage();
    upgrade.unpackStorage(testCaseName + ".tgz",testCaseName + ".txt");
    Configuration conf=new Configuration(TestDFSUpgradeFromImage.upgradeConf);
    initStorageDirs(conf,testCaseName);
    upgradeAndVerify(upgrade,conf,new ClusterVerifier(){
      @Override public void verifyClusterPostUpgrade(      MiniDFSCluster cluster) throws IOException {
        final String bpid=cluster.getNamesystem().getBlockPoolId();
        StorageReport[] reports=cluster.getDataNodes().get(0).getFSDataset().getStorageReports(bpid);
        assertThat(reports.length,is(1));
        final String storageID=reports[0].getStorage().getStorageID();
        assertTrue(DatanodeStorage.isValidStorageId(storageID));
        if (expectedStorageId != null) {
          assertThat(storageID,is(expectedStorageId));
        }
      }
    }
);
  }
  private static void initStorageDirs(  final Configuration conf,  final String testName){
    conf.set(DFSConfigKeys.DFS_DATANODE_DATA_DIR_KEY,GenericTestUtils.getTempPath(testName + File.separator + "dfs"+ File.separator+ "data"));
    conf.set(DFSConfigKeys.DFS_NAMENODE_NAME_DIR_KEY,GenericTestUtils.getTempPath(testName + File.separator + "dfs"+ File.separator+ "name"));
  }
  private static void upgradeAndVerify(  final TestDFSUpgradeFromImage upgrade,  final Configuration conf,  final ClusterVerifier verifier) throws IOException {
    upgrade.upgradeAndVerify(new MiniDFSCluster.Builder(conf).numDataNodes(1).manageDataDfsDirs(false).manageNameDfsDirs(false),verifier);
  }
  /** 
 * Upgrade from 2.2 (no storage IDs per volume) correctly generates GUID-based storage IDs. Test case for HDFS-7575.
 */
  @Test(timeout=300000) public void testUpgradeFrom22FixesStorageIDs() throws IOException {
    runLayoutUpgradeTest(GenericTestUtils.getMethodName(),null);
  }
  /** 
 * Startup from a 2.6-layout that has legacy storage IDs correctly generates new storage IDs. Test case for HDFS-7575.
 */
  @Test(timeout=300000) public void testUpgradeFrom22via26FixesStorageIDs() throws IOException {
    runLayoutUpgradeTest(GenericTestUtils.getMethodName(),null);
  }
  /** 
 * Startup from a 2.6-layout that already has unique storage IDs does not regenerate the storage IDs. Test case for HDFS-7575.
 */
  @Test(timeout=300000) public void testUpgradeFrom26PreservesStorageIDs() throws IOException {
    runLayoutUpgradeTest(GenericTestUtils.getMethodName(),"DS-a0e39cfa-930f-4abd-813c-e22b59223774");
  }
}
