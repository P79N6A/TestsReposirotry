public final class BloomTokenFilterTest extends MahoutTestCase {
  private static final CharsetEncoder encoder=Charsets.UTF_8.newEncoder();
  private static final String input="The best of times the worst of times";
  private static final String[] allTokens={"The","best","of","times","the","worst","of","times"};
  private static final String[] expectedNonKeepTokens={"best","times","the","worst","times"};
  private static final String[] expectedKeepTokens={"The","of","of"};
  private static final String[] filterTokens={"The","of"};
  private static final String[] notFilterTokens={"best","worst","the","times"};
  private static final String[] shingleKeepTokens={"The best","best of times","the worst","worst of times","of times"};
  private static final String[] expectedShingleTokens={"The best","best of times","of times","the worst","worst of times","of times"};
  /** 
 * test standalone filter without tokenfilter wrapping 
 */
  @Test public void testFilter() throws IOException {
    Filter filter=getFilter(filterTokens);
    Key k=new Key();
    for (    String s : filterTokens) {
      setKey(k,s);
      assertTrue("Key for string " + s + " should be filter member",filter.membershipTest(k));
    }
    for (    String s : notFilterTokens) {
      setKey(k,s);
      assertFalse("Key for string " + s + " should not be filter member",filter.membershipTest(k));
    }
  }
  /** 
 * normal case, unfiltered analyzer 
 */
  @Test public void testAnalyzer() throws IOException {
    Reader reader=new StringReader(input);
    Analyzer analyzer=new WhitespaceAnalyzer();
    TokenStream ts=analyzer.tokenStream(null,reader);
    ts.reset();
    validateTokens(allTokens,ts);
    ts.end();
    ts.close();
  }
  /** 
 * filtered analyzer 
 */
  @Test public void testNonKeepdAnalyzer() throws IOException {
    Reader reader=new StringReader(input);
    Analyzer analyzer=new WhitespaceAnalyzer();
    TokenStream ts=analyzer.tokenStream(null,reader);
    ts.reset();
    TokenStream f=new BloomTokenFilter(getFilter(filterTokens),false,ts);
    validateTokens(expectedNonKeepTokens,f);
    ts.end();
    ts.close();
  }
  /** 
 * keep analyzer 
 */
  @Test public void testKeepAnalyzer() throws IOException {
    Reader reader=new StringReader(input);
    Analyzer analyzer=new WhitespaceAnalyzer();
    TokenStream ts=analyzer.tokenStream(null,reader);
    ts.reset();
    TokenStream f=new BloomTokenFilter(getFilter(filterTokens),true,ts);
    validateTokens(expectedKeepTokens,f);
    ts.end();
    ts.close();
  }
  /** 
 * shingles, keep those matching whitelist 
 */
  @Test public void testShingleFilteredAnalyzer() throws IOException {
    Reader reader=new StringReader(input);
    Analyzer analyzer=new WhitespaceAnalyzer();
    TokenStream ts=analyzer.tokenStream(null,reader);
    ts.reset();
    ShingleFilter sf=new ShingleFilter(ts,3);
    TokenStream f=new BloomTokenFilter(getFilter(shingleKeepTokens),true,sf);
    validateTokens(expectedShingleTokens,f);
    ts.end();
    ts.close();
  }
  private static void setKey(  Key k,  String s) throws IOException {
    ByteBuffer buffer=encoder.encode(CharBuffer.wrap(s.toCharArray()));
    k.set(buffer.array(),1.0);
  }
  private static void validateTokens(  String[] expected,  TokenStream ts) throws IOException {
    int pos=0;
    while (ts.incrementToken()) {
      assertTrue("Analyzer produced too many tokens",pos <= expected.length);
      CharTermAttribute termAttr=ts.getAttribute(CharTermAttribute.class);
      assertEquals("Unexpected term",expected[pos++],termAttr.toString());
    }
    assertEquals("Analyzer produced too few terms",expected.length,pos);
  }
  private static Filter getFilter(  String[] tokens) throws IOException {
    Filter filter=new BloomFilter(100,50,Hash.JENKINS_HASH);
    Key k=new Key();
    for (    String s : tokens) {
      setKey(k,s);
      filter.add(k);
    }
    return filter;
  }
}
