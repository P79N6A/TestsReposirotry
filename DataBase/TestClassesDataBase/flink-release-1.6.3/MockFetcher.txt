private static class MockFetcher<T> extends AbstractFetcher<T,Object> {
  private final OneShotLatch runLatch=new OneShotLatch();
  private final OneShotLatch stopLatch=new OneShotLatch();
  private final ArrayDeque<HashMap<KafkaTopicPartition,Long>> stateSnapshotsToReturn=new ArrayDeque<>();
  private Map<KafkaTopicPartition,Long> lastCommittedOffsets;
  private int commitCount=0;
  @SafeVarargs private MockFetcher(  HashMap<KafkaTopicPartition,Long>... stateSnapshotsToReturn) throws Exception {
    super(new TestSourceContext<>(),new HashMap<>(),null,null,new TestProcessingTimeService(),0,MockFetcher.class.getClassLoader(),new UnregisteredMetricsGroup(),false);
    this.stateSnapshotsToReturn.addAll(Arrays.asList(stateSnapshotsToReturn));
  }
  @Override protected void doCommitInternalOffsetsToKafka(  Map<KafkaTopicPartition,Long> offsets,  @Nonnull KafkaCommitCallback commitCallback) throws Exception {
    this.lastCommittedOffsets=offsets;
    this.commitCount++;
    commitCallback.onSuccess();
  }
  @Override public void runFetchLoop() throws Exception {
    runLatch.trigger();
    stopLatch.await();
  }
  @Override public HashMap<KafkaTopicPartition,Long> snapshotCurrentState(){
    checkState(!stateSnapshotsToReturn.isEmpty());
    return stateSnapshotsToReturn.poll();
  }
  @Override protected Object createKafkaPartitionHandle(  KafkaTopicPartition partition){
    throw new UnsupportedOperationException();
  }
  @Override public void cancel(){
    stopLatch.trigger();
  }
  private void waitUntilRun() throws InterruptedException {
    runLatch.await();
  }
  private Map<KafkaTopicPartition,Long> getAndClearLastCommittedOffsets(){
    Map<KafkaTopicPartition,Long> offsets=this.lastCommittedOffsets;
    this.lastCommittedOffsets=null;
    return offsets;
  }
  private int getCommitCount(){
    return commitCount;
  }
}
