/** 
 * Test WordCount with Hadoop input and output "mapred" (legacy) formats.
 */
public class WordCountMapredITCase extends JavaProgramTestBase {
  protected String textPath;
  protected String resultPath;
  @Before public void checkOperatingSystem(){
    Assume.assumeTrue("This test can't run successfully on Windows.",!OperatingSystem.isWindows());
  }
  @Override protected void preSubmit() throws Exception {
    textPath=createTempFile("text.txt",WordCountData.TEXT);
    resultPath=getTempDirPath("result");
  }
  @Override protected void postSubmit() throws Exception {
    compareResultsByLinesInMemory(WordCountData.COUNTS,resultPath,new String[]{".","_"});
  }
  @Override protected void testProgram() throws Exception {
    internalRun(true);
    postSubmit();
    resultPath=getTempDirPath("result2");
    internalRun(false);
    postSubmit();
  }
  private void internalRun(  boolean isTestDeprecatedAPI) throws Exception {
    final ExecutionEnvironment env=ExecutionEnvironment.getExecutionEnvironment();
    DataSet<Tuple2<LongWritable,Text>> input;
    if (isTestDeprecatedAPI) {
      input=env.createInput(HadoopInputs.readHadoopFile(new TextInputFormat(),LongWritable.class,Text.class,textPath));
    }
 else {
      input=env.createInput(readHadoopFile(new TextInputFormat(),LongWritable.class,Text.class,textPath));
    }
    DataSet<String> text=input.map(new MapFunction<Tuple2<LongWritable,Text>,String>(){
      @Override public String map(      Tuple2<LongWritable,Text> value) throws Exception {
        return value.f1.toString();
      }
    }
);
    DataSet<Tuple2<String,Integer>> counts=text.flatMap(new Tokenizer()).groupBy(0).sum(1);
    DataSet<Tuple2<Text,LongWritable>> words=counts.map(new MapFunction<Tuple2<String,Integer>,Tuple2<Text,LongWritable>>(){
      @Override public Tuple2<Text,LongWritable> map(      Tuple2<String,Integer> value) throws Exception {
        return new Tuple2<Text,LongWritable>(new Text(value.f0),new LongWritable(value.f1));
      }
    }
);
    HadoopOutputFormat<Text,LongWritable> hadoopOutputFormat=new HadoopOutputFormat<Text,LongWritable>(new TextOutputFormat<Text,LongWritable>(),new JobConf());
    hadoopOutputFormat.getJobConf().set("mapred.textoutputformat.separator"," ");
    TextOutputFormat.setOutputPath(hadoopOutputFormat.getJobConf(),new Path(resultPath));
    words.output(hadoopOutputFormat);
    env.execute("Hadoop Compat WordCount");
  }
static final class Tokenizer implements FlatMapFunction<String,Tuple2<String,Integer>> {
    @Override public void flatMap(    String value,    Collector<Tuple2<String,Integer>> out){
      String[] tokens=value.toLowerCase().split("\\W+");
      for (      String token : tokens) {
        if (token.length() > 0) {
          out.collect(new Tuple2<>(token,1));
        }
      }
    }
  }
}
