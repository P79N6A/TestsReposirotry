/** 
 * Suite of tests for  {@link ElasticsearchSinkBase}.
 */
public class ElasticsearchSinkBaseTest {
  /** 
 * Verifies that the collection given to the sink is not modified.
 */
  @Test public void testCollectionArgumentNotModified(){
    Map<String,String> userConfig=new HashMap<>();
    userConfig.put(ElasticsearchSinkBase.CONFIG_KEY_BULK_FLUSH_BACKOFF_DELAY,"1");
    userConfig.put(ElasticsearchSinkBase.CONFIG_KEY_BULK_FLUSH_BACKOFF_ENABLE,"true");
    userConfig.put(ElasticsearchSinkBase.CONFIG_KEY_BULK_FLUSH_BACKOFF_RETRIES,"1");
    userConfig.put(ElasticsearchSinkBase.CONFIG_KEY_BULK_FLUSH_BACKOFF_TYPE,"CONSTANT");
    userConfig.put(ElasticsearchSinkBase.CONFIG_KEY_BULK_FLUSH_INTERVAL_MS,"1");
    userConfig.put(ElasticsearchSinkBase.CONFIG_KEY_BULK_FLUSH_MAX_ACTIONS,"1");
    userConfig.put(ElasticsearchSinkBase.CONFIG_KEY_BULK_FLUSH_MAX_SIZE_MB,"1");
    new DummyElasticsearchSink<>(Collections.unmodifiableMap(userConfig),new SimpleSinkFunction<String>(),new NoOpFailureHandler());
  }
  /** 
 * Tests that any item failure in the listener callbacks is rethrown on an immediately following invoke call. 
 */
  @Test public void testItemFailureRethrownOnInvoke() throws Throwable {
    final DummyElasticsearchSink<String> sink=new DummyElasticsearchSink<>(new HashMap<String,String>(),new SimpleSinkFunction<String>(),new NoOpFailureHandler());
    final OneInputStreamOperatorTestHarness<String,Object> testHarness=new OneInputStreamOperatorTestHarness<>(new StreamSink<>(sink));
    testHarness.open();
    sink.setMockItemFailuresListForNextBulkItemResponses(Collections.singletonList(new Exception("artificial failure for record")));
    testHarness.processElement(new StreamRecord<>("msg"));
    verify(sink.getMockBulkProcessor(),times(1)).add(any(IndexRequest.class));
    sink.manualBulkRequestWithAllPendingRequests();
    try {
      testHarness.processElement(new StreamRecord<>("next msg"));
    }
 catch (    Exception e) {
      Assert.assertTrue(e.getCause().getMessage().contains("artificial failure for record"));
      return;
    }
    Assert.fail();
  }
  /** 
 * Tests that any item failure in the listener callbacks is rethrown on an immediately following checkpoint. 
 */
  @Test public void testItemFailureRethrownOnCheckpoint() throws Throwable {
    final DummyElasticsearchSink<String> sink=new DummyElasticsearchSink<>(new HashMap<String,String>(),new SimpleSinkFunction<String>(),new NoOpFailureHandler());
    final OneInputStreamOperatorTestHarness<String,Object> testHarness=new OneInputStreamOperatorTestHarness<>(new StreamSink<>(sink));
    testHarness.open();
    sink.setMockItemFailuresListForNextBulkItemResponses(Collections.singletonList(new Exception("artificial failure for record")));
    testHarness.processElement(new StreamRecord<>("msg"));
    verify(sink.getMockBulkProcessor(),times(1)).add(any(IndexRequest.class));
    sink.manualBulkRequestWithAllPendingRequests();
    try {
      testHarness.snapshot(1L,1000L);
    }
 catch (    Exception e) {
      Assert.assertTrue(e.getCause().getCause().getMessage().contains("artificial failure for record"));
      return;
    }
    Assert.fail();
  }
  /** 
 * Tests that any item failure in the listener callbacks due to flushing on an immediately following checkpoint is rethrown; we set a timeout because the test will not finish if the logic is broken.
 */
  @Test(timeout=5000) public void testItemFailureRethrownOnCheckpointAfterFlush() throws Throwable {
    final DummyElasticsearchSink<String> sink=new DummyElasticsearchSink<>(new HashMap<String,String>(),new SimpleSinkFunction<String>(),new NoOpFailureHandler());
    final OneInputStreamOperatorTestHarness<String,Object> testHarness=new OneInputStreamOperatorTestHarness<>(new StreamSink<>(sink));
    testHarness.open();
    List<Exception> mockResponsesList=new ArrayList<>(2);
    mockResponsesList.add(null);
    mockResponsesList.add(new Exception("artificial failure for record"));
    sink.setMockItemFailuresListForNextBulkItemResponses(mockResponsesList);
    testHarness.processElement(new StreamRecord<>("msg-1"));
    verify(sink.getMockBulkProcessor(),times(1)).add(any(IndexRequest.class));
    sink.manualBulkRequestWithAllPendingRequests();
    testHarness.processElement(new StreamRecord<>("msg-2"));
    testHarness.processElement(new StreamRecord<>("msg-3"));
    verify(sink.getMockBulkProcessor(),times(3)).add(any(IndexRequest.class));
    CheckedThread snapshotThread=new CheckedThread(){
      @Override public void go() throws Exception {
        testHarness.snapshot(1L,1000L);
      }
    }
;
    snapshotThread.start();
    while (snapshotThread.getState() != Thread.State.WAITING) {
      Thread.sleep(10);
    }
    sink.continueFlush();
    try {
      snapshotThread.sync();
    }
 catch (    Exception e) {
      Assert.assertTrue(e.getCause().getCause().getMessage().contains("artificial failure for record"));
      return;
    }
    Assert.fail();
  }
  /** 
 * Tests that any bulk failure in the listener callbacks is rethrown on an immediately following invoke call. 
 */
  @Test public void testBulkFailureRethrownOnInvoke() throws Throwable {
    final DummyElasticsearchSink<String> sink=new DummyElasticsearchSink<>(new HashMap<String,String>(),new SimpleSinkFunction<String>(),new NoOpFailureHandler());
    final OneInputStreamOperatorTestHarness<String,Object> testHarness=new OneInputStreamOperatorTestHarness<>(new StreamSink<>(sink));
    testHarness.open();
    sink.setFailNextBulkRequestCompletely(new Exception("artificial failure for bulk request"));
    testHarness.processElement(new StreamRecord<>("msg"));
    verify(sink.getMockBulkProcessor(),times(1)).add(any(IndexRequest.class));
    sink.manualBulkRequestWithAllPendingRequests();
    try {
      testHarness.processElement(new StreamRecord<>("next msg"));
    }
 catch (    Exception e) {
      Assert.assertTrue(e.getCause().getMessage().contains("artificial failure for bulk request"));
      return;
    }
    Assert.fail();
  }
  /** 
 * Tests that any bulk failure in the listener callbacks is rethrown on an immediately following checkpoint. 
 */
  @Test public void testBulkFailureRethrownOnCheckpoint() throws Throwable {
    final DummyElasticsearchSink<String> sink=new DummyElasticsearchSink<>(new HashMap<String,String>(),new SimpleSinkFunction<String>(),new NoOpFailureHandler());
    final OneInputStreamOperatorTestHarness<String,Object> testHarness=new OneInputStreamOperatorTestHarness<>(new StreamSink<>(sink));
    testHarness.open();
    sink.setFailNextBulkRequestCompletely(new Exception("artificial failure for bulk request"));
    testHarness.processElement(new StreamRecord<>("msg"));
    verify(sink.getMockBulkProcessor(),times(1)).add(any(IndexRequest.class));
    sink.manualBulkRequestWithAllPendingRequests();
    try {
      testHarness.snapshot(1L,1000L);
    }
 catch (    Exception e) {
      Assert.assertTrue(e.getCause().getCause().getMessage().contains("artificial failure for bulk request"));
      return;
    }
    Assert.fail();
  }
  /** 
 * Tests that any bulk failure in the listener callbacks due to flushing on an immediately following checkpoint is rethrown; we set a timeout because the test will not finish if the logic is broken.
 */
  @Test(timeout=5000) public void testBulkFailureRethrownOnOnCheckpointAfterFlush() throws Throwable {
    final DummyElasticsearchSink<String> sink=new DummyElasticsearchSink<>(new HashMap<String,String>(),new SimpleSinkFunction<String>(),new NoOpFailureHandler());
    final OneInputStreamOperatorTestHarness<String,Object> testHarness=new OneInputStreamOperatorTestHarness<>(new StreamSink<>(sink));
    testHarness.open();
    sink.setMockItemFailuresListForNextBulkItemResponses(Collections.singletonList((Exception)null));
    testHarness.processElement(new StreamRecord<>("msg-1"));
    verify(sink.getMockBulkProcessor(),times(1)).add(any(IndexRequest.class));
    sink.manualBulkRequestWithAllPendingRequests();
    testHarness.processElement(new StreamRecord<>("msg-2"));
    testHarness.processElement(new StreamRecord<>("msg-3"));
    verify(sink.getMockBulkProcessor(),times(3)).add(any(IndexRequest.class));
    CheckedThread snapshotThread=new CheckedThread(){
      @Override public void go() throws Exception {
        testHarness.snapshot(1L,1000L);
      }
    }
;
    snapshotThread.start();
    while (snapshotThread.getState() != Thread.State.WAITING) {
      Thread.sleep(10);
    }
    sink.setFailNextBulkRequestCompletely(new Exception("artificial failure for bulk request"));
    sink.continueFlush();
    try {
      snapshotThread.sync();
    }
 catch (    Exception e) {
      Assert.assertTrue(e.getCause().getCause().getMessage().contains("artificial failure for bulk request"));
      return;
    }
    Assert.fail();
  }
  /** 
 * Tests that the sink correctly waits for pending requests (including re-added requests) on checkpoints; we set a timeout because the test will not finish if the logic is broken.
 */
  @Test(timeout=5000) public void testAtLeastOnceSink() throws Throwable {
    final DummyElasticsearchSink<String> sink=new DummyElasticsearchSink<>(new HashMap<String,String>(),new SimpleSinkFunction<String>(),new DummyRetryFailureHandler());
    final OneInputStreamOperatorTestHarness<String,Object> testHarness=new OneInputStreamOperatorTestHarness<>(new StreamSink<>(sink));
    testHarness.open();
    sink.setMockItemFailuresListForNextBulkItemResponses(Collections.singletonList(new Exception("artificial failure for record")));
    testHarness.processElement(new StreamRecord<>("msg"));
    verify(sink.getMockBulkProcessor(),times(1)).add(any(IndexRequest.class));
    CheckedThread snapshotThread=new CheckedThread(){
      @Override public void go() throws Exception {
        testHarness.snapshot(1L,1000L);
      }
    }
;
    snapshotThread.start();
    while (snapshotThread.getState() != Thread.State.WAITING) {
      Thread.sleep(10);
    }
    sink.continueFlush();
    while (snapshotThread.getState() != Thread.State.WAITING) {
      Thread.sleep(10);
    }
    Assert.assertEquals(1,sink.getNumPendingRequests());
    sink.setMockItemFailuresListForNextBulkItemResponses(Collections.singletonList((Exception)null));
    sink.continueFlush();
    snapshotThread.sync();
    testHarness.close();
  }
  /** 
 * This test is meant to assure that testAtLeastOnceSink is valid by testing that if flushing is disabled, the snapshot method does indeed finishes without waiting for pending requests; we set a timeout because the test will not finish if the logic is broken.
 */
  @Test(timeout=5000) public void testDoesNotWaitForPendingRequestsIfFlushingDisabled() throws Exception {
    final DummyElasticsearchSink<String> sink=new DummyElasticsearchSink<>(new HashMap<String,String>(),new SimpleSinkFunction<String>(),new DummyRetryFailureHandler());
    sink.disableFlushOnCheckpoint();
    final OneInputStreamOperatorTestHarness<String,Object> testHarness=new OneInputStreamOperatorTestHarness<>(new StreamSink<>(sink));
    testHarness.open();
    sink.setMockItemFailuresListForNextBulkItemResponses(Collections.singletonList(new Exception("artificial failure for record")));
    testHarness.processElement(new StreamRecord<>("msg-1"));
    verify(sink.getMockBulkProcessor(),times(1)).add(any(IndexRequest.class));
    testHarness.snapshot(1L,1000L);
    testHarness.close();
  }
private static class DummyElasticsearchSink<T> extends ElasticsearchSinkBase<T,Client> {
    private static final long serialVersionUID=5051907841570096991L;
    private transient BulkProcessor mockBulkProcessor;
    private transient BulkRequest nextBulkRequest=new BulkRequest();
    private transient MultiShotLatch flushLatch=new MultiShotLatch();
    private List<? extends Throwable> mockItemFailuresList;
    private Throwable nextBulkFailure;
    public DummyElasticsearchSink(    Map<String,String> userConfig,    ElasticsearchSinkFunction<T> sinkFunction,    ActionRequestFailureHandler failureHandler){
      super(new DummyElasticsearchApiCallBridge(),userConfig,sinkFunction,failureHandler);
    }
    /** 
 * This method is used to mimic a scheduled bulk request; we need to do this manually because we are mocking the BulkProcessor.
 */
    public void manualBulkRequestWithAllPendingRequests(){
      flushLatch.trigger();
      mockBulkProcessor.flush();
    }
    /** 
 * On non-manual flushes, i.e. when flush is called in the snapshot method implementation, usages need to explicitly call this to allow the flush to continue. This is useful to make sure that specific requests get added to the next bulk request for flushing.
 */
    public void continueFlush(){
      flushLatch.trigger();
    }
    /** 
 * Set the list of mock failures to use for the next bulk of item responses. A  {@code null}means that the response is successful, failed otherwise. <p>The list is used with corresponding order to the requests in the bulk, i.e. the first request uses the response at index 0, the second requests uses the response at index 1, etc.
 */
    public void setMockItemFailuresListForNextBulkItemResponses(    List<? extends Throwable> mockItemFailuresList){
      this.mockItemFailuresList=mockItemFailuresList;
    }
    /** 
 * Let the next bulk request fail completely with the provided throwable. If this is set, the failures list provided with setMockItemFailuresListForNextBulkItemResponses is not respected.
 */
    public void setFailNextBulkRequestCompletely(    Throwable failure){
      this.nextBulkFailure=failure;
    }
    public BulkProcessor getMockBulkProcessor(){
      return mockBulkProcessor;
    }
    /** 
 * Override the bulk processor build process to provide a mock implementation, but reuse the listener implementation in our mock to test that the listener logic works correctly with request flushing logic.
 */
    @Override protected BulkProcessor buildBulkProcessor(    final BulkProcessor.Listener listener){
      this.mockBulkProcessor=mock(BulkProcessor.class);
      when(mockBulkProcessor.add(any(IndexRequest.class))).thenAnswer(new Answer<Object>(){
        @Override public Object answer(        InvocationOnMock invocationOnMock) throws Throwable {
          nextBulkRequest.add(invocationOnMock.getArgumentAt(0,IndexRequest.class));
          return null;
        }
      }
);
      doAnswer(new Answer(){
        @Override public Object answer(        InvocationOnMock invocationOnMock) throws Throwable {
          while (nextBulkRequest.numberOfActions() > 0) {
            flushLatch.await();
            BulkRequest currentBulkRequest=nextBulkRequest;
            nextBulkRequest=new BulkRequest();
            listener.beforeBulk(123L,currentBulkRequest);
            if (nextBulkFailure == null) {
              BulkItemResponse[] mockResponses=new BulkItemResponse[currentBulkRequest.requests().size()];
              for (int i=0; i < currentBulkRequest.requests().size(); i++) {
                Throwable mockItemFailure=mockItemFailuresList.get(i);
                if (mockItemFailure == null) {
                  mockResponses[i]=new BulkItemResponse(i,"opType",mock(ActionResponse.class));
                }
 else {
                  mockResponses[i]=new BulkItemResponse(i,"opType",new BulkItemResponse.Failure("index","type","id",mockItemFailure));
                }
              }
              listener.afterBulk(123L,currentBulkRequest,new BulkResponse(mockResponses,1000L));
            }
 else {
              listener.afterBulk(123L,currentBulkRequest,nextBulkFailure);
            }
          }
          return null;
        }
      }
).when(mockBulkProcessor).flush();
      return mockBulkProcessor;
    }
  }
private static class DummyElasticsearchApiCallBridge implements ElasticsearchApiCallBridge<Client> {
    private static final long serialVersionUID=-4272760730959041699L;
    @Override public Client createClient(    Map<String,String> clientConfig){
      return mock(Client.class);
    }
    @Override public BulkProcessor.Builder createBulkProcessorBuilder(    Client client,    BulkProcessor.Listener listener){
      return null;
    }
    @Nullable @Override public Throwable extractFailureCauseFromBulkItemResponse(    BulkItemResponse bulkItemResponse){
      if (bulkItemResponse.isFailed()) {
        return new Exception(bulkItemResponse.getFailure().getMessage());
      }
 else {
        return null;
      }
    }
    @Override public void configureBulkProcessorBackoff(    BulkProcessor.Builder builder,    @Nullable ElasticsearchSinkBase.BulkFlushBackoffPolicy flushBackoffPolicy){
    }
  }
private static class SimpleSinkFunction<String> implements ElasticsearchSinkFunction<String> {
    private static final long serialVersionUID=-176739293659135148L;
    @Override public void process(    String element,    RuntimeContext ctx,    RequestIndexer indexer){
      Map<java.lang.String,Object> json=new HashMap<>();
      json.put("data",element);
      indexer.add(Requests.indexRequest().index("index").type("type").id("id").source(json));
    }
  }
private static class DummyRetryFailureHandler implements ActionRequestFailureHandler {
    private static final long serialVersionUID=5400023700099200745L;
    @Override public void onFailure(    ActionRequest action,    Throwable failure,    int restStatusCode,    RequestIndexer indexer) throws Throwable {
      indexer.add(action);
    }
  }
}
