/** 
 * Small test to check that the  {@link org.apache.flink.runtime.blob.BlobServer} cleanup is executedafter job termination.
 */
public class JobManagerCleanupITCase extends TestLogger {
  @Rule public TemporaryFolder tmpFolder=new TemporaryFolder();
  private static ActorSystem system;
  @BeforeClass public static void setup(){
    system=AkkaUtils.createLocalActorSystem(new Configuration());
  }
  @AfterClass public static void teardown(){
    JavaTestKit.shutdownActorSystem(system);
  }
  /** 
 * Specifies which test case to run in  {@link #testBlobServerCleanup(TestCase)}.
 */
  private enum TestCase {  JOB_FINISHES_SUCESSFULLY,   JOB_IS_CANCELLED,   JOB_FAILS,   JOB_SUBMISSION_FAILS}
  /** 
 * Test cleanup for a job that finishes ordinarily.
 */
  @Test public void testBlobServerCleanupFinishedJob() throws IOException {
    testBlobServerCleanup(TestCase.JOB_FINISHES_SUCESSFULLY);
  }
  /** 
 * Test cleanup for a job which is cancelled after submission.
 */
  @Test public void testBlobServerCleanupCancelledJob() throws IOException {
    testBlobServerCleanup(TestCase.JOB_IS_CANCELLED);
  }
  /** 
 * Test cleanup for a job that fails (first a task fails, then the job recovers, then the whole job fails due to a limited restart policy).
 */
  @Test public void testBlobServerCleanupFailedJob() throws IOException {
    testBlobServerCleanup(TestCase.JOB_FAILS);
  }
  /** 
 * Test cleanup for a job that fails job submission (emulated by an additional BLOB not being present).
 */
  @Test public void testBlobServerCleanupFailedSubmission() throws IOException {
    testBlobServerCleanup(TestCase.JOB_SUBMISSION_FAILS);
  }
  private void testBlobServerCleanup(  final TestCase testCase) throws IOException {
    final int num_tasks=2;
    final File blobBaseDir=tmpFolder.newFolder();
    new JavaTestKit(system){
{
        new Within(duration("30 seconds")){
          @Override protected void run(){
            TestingCluster cluster=null;
            File tempBlob=null;
            try {
              Configuration config=new Configuration();
              config.setInteger(TaskManagerOptions.NUM_TASK_SLOTS,2);
              config.setInteger(ConfigConstants.LOCAL_NUMBER_TASK_MANAGER,1);
              config.setString(AkkaOptions.ASK_TIMEOUT,DEFAULT_AKKA_ASK_TIMEOUT());
              config.setString(BlobServerOptions.STORAGE_DIRECTORY,blobBaseDir.getAbsolutePath());
              config.setString(ConfigConstants.RESTART_STRATEGY,"fixeddelay");
              config.setInteger(ConfigConstants.RESTART_STRATEGY_FIXED_DELAY_ATTEMPTS,1);
              config.setString(ConfigConstants.RESTART_STRATEGY_FIXED_DELAY_DELAY,"1 s");
              config.setLong(BlobServerOptions.CLEANUP_INTERVAL,1L);
              cluster=new TestingCluster(config);
              cluster.start();
              final ActorGateway jobManagerGateway=cluster.getLeaderGateway(TestingUtils.TESTING_DURATION());
              final ActorGateway testActorGateway=new AkkaActorGateway(getTestActor(),HighAvailabilityServices.DEFAULT_LEADER_ID);
              JobVertex source=new JobVertex("Source");
              if (testCase == TestCase.JOB_FAILS || testCase == TestCase.JOB_IS_CANCELLED) {
                source.setInvokableClass(FailingBlockingInvokable.class);
              }
 else {
                source.setInvokableClass(NoOpInvokable.class);
              }
              source.setParallelism(num_tasks);
              JobGraph jobGraph=new JobGraph("BlobCleanupTest",source);
              final JobID jid=jobGraph.getJobID();
              Future<Object> future=jobManagerGateway.ask(JobManagerMessages.getRequestBlobManagerPort(),remaining());
              int blobPort=(Integer)Await.result(future,remaining());
              tempBlob=File.createTempFile("Required",".jar");
              List<PermanentBlobKey> keys=BlobClient.uploadFiles(new InetSocketAddress("localhost",blobPort),config,jid,Collections.singletonList(new Path(tempBlob.getAbsolutePath())));
              assertEquals(1,keys.size());
              jobGraph.addUserJarBlobKey(keys.get(0));
              if (testCase == TestCase.JOB_SUBMISSION_FAILS) {
                jobGraph.addUserJarBlobKey(new PermanentBlobKey());
              }
              jobManagerGateway.tell(new JobManagerMessages.SubmitJob(jobGraph,testCase == TestCase.JOB_IS_CANCELLED ? ListeningBehaviour.DETACHED : ListeningBehaviour.EXECUTION_RESULT),testActorGateway);
              if (testCase == TestCase.JOB_SUBMISSION_FAILS) {
                expectMsgClass(JobManagerMessages.JobResultFailure.class);
              }
 else {
                expectMsgEquals(new JobManagerMessages.JobSubmitSuccess(jid));
                if (testCase == TestCase.JOB_FAILS) {
                  FailingBlockingInvokable.unblock();
                  expectMsgClass(JobManagerMessages.JobResultFailure.class);
                }
 else                 if (testCase == TestCase.JOB_IS_CANCELLED) {
                  jobManagerGateway.tell(new JobManagerMessages.CancelJob(jid),testActorGateway);
                  expectMsgEquals(new JobManagerMessages.CancellationSuccess(jid,null));
                }
 else {
                  expectMsgClass(JobManagerMessages.JobResultSuccess.class);
                }
              }
              File[] blobDirs=blobBaseDir.listFiles(new FilenameFilter(){
                @Override public boolean accept(                File dir,                String name){
                  return name.startsWith("blobStore-");
                }
              }
);
              assertNotNull(blobDirs);
              for (              File blobDir : blobDirs) {
                waitForEmptyBlobDir(blobDir,remaining());
              }
            }
 catch (            Exception e) {
              e.printStackTrace();
              fail(e.getMessage());
            }
 finally {
              if (cluster != null) {
                cluster.stop();
              }
              if (tempBlob != null) {
                assertTrue(tempBlob.delete());
              }
            }
          }
        }
;
      }
    }
;
    assertArrayEquals(new File[]{},blobBaseDir.listFiles());
  }
  /** 
 * Waits until the given  {@link org.apache.flink.runtime.blob.BlobService} storage directorydoes not contain any job-related folders any more.
 * @param blobDir directory of a  {@link org.apache.flink.runtime.blob.BlobServer} or {@link org.apache.flink.runtime.blob.BlobCacheService}
 * @param remaining remaining time for this test
 * @see org.apache.flink.runtime.blob.BlobUtils
 */
  private static void waitForEmptyBlobDir(  File blobDir,  FiniteDuration remaining) throws InterruptedException {
    long deadline=System.currentTimeMillis() + remaining.toMillis();
    String[] blobDirContents;
    do {
      blobDirContents=blobDir.list(new FilenameFilter(){
        @Override public boolean accept(        File dir,        String name){
          return name.startsWith("job_");
        }
      }
);
      if (blobDirContents == null || blobDirContents.length == 0) {
        return;
      }
      Thread.sleep(100);
    }
 while (System.currentTimeMillis() < deadline);
    fail("Timeout while waiting for " + blobDir.getAbsolutePath() + " to become empty. Current contents: "+ Arrays.toString(blobDirContents));
  }
}
