/** 
 * Abstract class to verify that it is possible to migrate a savepoint across upgraded Flink versions and that the topology can be modified from that point on. <p>The verification is done in 2 Steps: Step 1: Migrate the job to the newer version by submitting the same job used for the old version savepoint, and create a new savepoint. Step 2: Modify the job topology, and restore from the savepoint created in step 1.
 */
public abstract class AbstractOperatorRestoreTestBase extends TestLogger {
  private static final int NUM_TMS=1;
  private static final int NUM_SLOTS_PER_TM=4;
  private static final Duration TEST_TIMEOUT=Duration.ofSeconds(10000L);
  @Rule public final TemporaryFolder tmpFolder=new TemporaryFolder();
  @ClassRule public static final MiniClusterResource MINI_CLUSTER_RESOURCE=new MiniClusterResource(new MiniClusterResourceConfiguration.Builder().setNumberTaskManagers(NUM_TMS).setNumberSlotsPerTaskManager(NUM_SLOTS_PER_TM).build());
  private final boolean allowNonRestoredState;
  protected AbstractOperatorRestoreTestBase(){
    this(true);
  }
  protected AbstractOperatorRestoreTestBase(  boolean allowNonRestoredState){
    this.allowNonRestoredState=allowNonRestoredState;
  }
  @BeforeClass public static void beforeClass(){
    SavepointSerializers.setFailWhenLegacyStateDetected(false);
  }
  @Test public void testMigrationAndRestore() throws Throwable {
    ClassLoader classLoader=this.getClass().getClassLoader();
    ClusterClient<?> clusterClient=MINI_CLUSTER_RESOURCE.getClusterClient();
    clusterClient.setDetached(true);
    final Deadline deadline=Deadline.now().plus(TEST_TIMEOUT);
    String savepointPath=migrateJob(classLoader,clusterClient,deadline);
    restoreJob(classLoader,clusterClient,deadline,savepointPath);
  }
  private String migrateJob(  ClassLoader classLoader,  ClusterClient<?> clusterClient,  Deadline deadline) throws Throwable {
    URL savepointResource=AbstractOperatorRestoreTestBase.class.getClassLoader().getResource("operatorstate/" + getMigrationSavepointName());
    if (savepointResource == null) {
      throw new IllegalArgumentException("Savepoint file does not exist.");
    }
    JobGraph jobToMigrate=createJobGraph(ExecutionMode.MIGRATE);
    jobToMigrate.setSavepointRestoreSettings(SavepointRestoreSettings.forPath(savepointResource.getFile()));
    assertNotNull(jobToMigrate.getJobID());
    clusterClient.submitJob(jobToMigrate,classLoader);
    CompletableFuture<JobStatus> jobRunningFuture=FutureUtils.retrySuccesfulWithDelay(() -> clusterClient.getJobStatus(jobToMigrate.getJobID()),Time.milliseconds(50),deadline,(jobStatus) -> jobStatus == JobStatus.RUNNING,TestingUtils.defaultScheduledExecutor());
    assertEquals(JobStatus.RUNNING,jobRunningFuture.get(deadline.timeLeft().toMillis(),TimeUnit.MILLISECONDS));
    File targetDirectory=tmpFolder.newFolder();
    String savepointPath=null;
    while (deadline.hasTimeLeft() && savepointPath == null) {
      try {
        savepointPath=clusterClient.cancelWithSavepoint(jobToMigrate.getJobID(),targetDirectory.getAbsolutePath());
      }
 catch (      Exception e) {
        String exceptionString=ExceptionUtils.stringifyException(e);
        if (!(exceptionString.matches("(.*\n)*.*savepoint for the job .* failed(.*\n)*") || exceptionString.matches("(.*\n)*.*was not running(.*\n)*") || exceptionString.matches("(.*\n)*.*Not all required tasks are currently running(.*\n)*")|| exceptionString.matches("(.*\n)*.*Checkpoint was declined \\(tasks not ready\\)(.*\n)*"))) {
          throw e;
        }
      }
    }
    assertNotNull("Could not take savepoint.",savepointPath);
    CompletableFuture<JobStatus> jobCanceledFuture=FutureUtils.retrySuccesfulWithDelay(() -> clusterClient.getJobStatus(jobToMigrate.getJobID()),Time.milliseconds(50),deadline,(jobStatus) -> jobStatus == JobStatus.CANCELED,TestingUtils.defaultScheduledExecutor());
    assertEquals(JobStatus.CANCELED,jobCanceledFuture.get(deadline.timeLeft().toMillis(),TimeUnit.MILLISECONDS));
    return savepointPath;
  }
  private void restoreJob(  ClassLoader classLoader,  ClusterClient<?> clusterClient,  Deadline deadline,  String savepointPath) throws Exception {
    JobGraph jobToRestore=createJobGraph(ExecutionMode.RESTORE);
    jobToRestore.setSavepointRestoreSettings(SavepointRestoreSettings.forPath(savepointPath,allowNonRestoredState));
    assertNotNull("Job doesn't have a JobID.",jobToRestore.getJobID());
    clusterClient.submitJob(jobToRestore,classLoader);
    CompletableFuture<JobStatus> jobStatusFuture=FutureUtils.retrySuccesfulWithDelay(() -> clusterClient.getJobStatus(jobToRestore.getJobID()),Time.milliseconds(50),deadline,(jobStatus) -> jobStatus == JobStatus.FINISHED,TestingUtils.defaultScheduledExecutor());
    assertEquals(JobStatus.FINISHED,jobStatusFuture.get(deadline.timeLeft().toMillis(),TimeUnit.MILLISECONDS));
  }
  private JobGraph createJobGraph(  ExecutionMode mode){
    StreamExecutionEnvironment env=StreamExecutionEnvironment.getExecutionEnvironment();
    env.enableCheckpointing(500,CheckpointingMode.EXACTLY_ONCE);
    env.setRestartStrategy(RestartStrategies.noRestart());
    env.setStateBackend((StateBackend)new MemoryStateBackend());
switch (mode) {
case MIGRATE:
      createMigrationJob(env);
    break;
case RESTORE:
  createRestoredJob(env);
break;
}
return StreamingJobGraphGenerator.createJobGraph(env.getStreamGraph());
}
/** 
 * Recreates the job used to create the new version savepoint.
 * @param env StreamExecutionEnvironment to use
 */
protected abstract void createMigrationJob(StreamExecutionEnvironment env);
/** 
 * Creates a modified version of the job used to create the new version savepoint.
 * @param env StreamExecutionEnvironment to use
 */
protected abstract void createRestoredJob(StreamExecutionEnvironment env);
/** 
 * Returns the name of the savepoint directory to use, relative to "resources/operatorstate".
 * @return savepoint directory to use
 */
protected abstract String getMigrationSavepointName();
}
