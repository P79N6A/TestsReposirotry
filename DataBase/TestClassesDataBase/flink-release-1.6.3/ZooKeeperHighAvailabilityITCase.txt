/** 
 * Integration tests for  {@link org.apache.flink.runtime.checkpoint.ZooKeeperCompletedCheckpointStore}.
 */
public class ZooKeeperHighAvailabilityITCase extends TestLogger {
  private static final Duration TEST_TIMEOUT=Duration.ofSeconds(10000L);
  private static final int NUM_JMS=1;
  private static final int NUM_TMS=1;
  private static final int NUM_SLOTS_PER_TM=1;
  @ClassRule public static final TemporaryFolder TEMPORARY_FOLDER=new TemporaryFolder();
  private static File haStorageDir;
  private static TestingServer zkServer;
  private static MiniClusterResource miniClusterResource;
  private static OneShotLatch waitForCheckpointLatch=new OneShotLatch();
  private static OneShotLatch failInCheckpointLatch=new OneShotLatch();
  @BeforeClass public static void setup() throws Exception {
    zkServer=new TestingServer();
    Configuration config=new Configuration();
    config.setInteger(ConfigConstants.LOCAL_NUMBER_JOB_MANAGER,NUM_JMS);
    config.setInteger(ConfigConstants.LOCAL_NUMBER_TASK_MANAGER,NUM_TMS);
    config.setInteger(TaskManagerOptions.NUM_TASK_SLOTS,NUM_SLOTS_PER_TM);
    haStorageDir=TEMPORARY_FOLDER.newFolder();
    config.setString(HighAvailabilityOptions.HA_STORAGE_PATH,haStorageDir.toString());
    config.setString(HighAvailabilityOptions.HA_CLUSTER_ID,UUID.randomUUID().toString());
    config.setString(HighAvailabilityOptions.HA_ZOOKEEPER_QUORUM,zkServer.getConnectString());
    config.setString(HighAvailabilityOptions.HA_MODE,"zookeeper");
    config.setString(ConfigConstants.METRICS_REPORTER_PREFIX + "restarts." + ConfigConstants.METRICS_REPORTER_CLASS_SUFFIX,RestartReporter.class.getName());
    miniClusterResource=new MiniClusterResource(new MiniClusterResourceConfiguration.Builder().setConfiguration(config).setNumberTaskManagers(NUM_TMS).setNumberSlotsPerTaskManager(NUM_SLOTS_PER_TM).build());
    miniClusterResource.before();
  }
  @AfterClass public static void tearDown() throws Exception {
    miniClusterResource.after();
    zkServer.stop();
    zkServer.close();
  }
  /** 
 * Verify that we don't start a job from scratch if we cannot restore any of the CompletedCheckpoints. <p>Synchronization for the different steps and things we want to observe happens via latches in the test method and the methods of  {@link CheckpointBlockingFunction}. <p>The test follows these steps: <ol> <li>Start job and block on a latch until we have done some checkpoints <li>Block in the special function <li>Move away the contents of the ZooKeeper HA directory to make restoring from checkpoints impossible <li>Unblock the special function, which now induces a failure <li>Make sure that the job does not recover successfully <li>Move back the HA directory <li>Make sure that the job recovers, we use a latch to ensure that the operator restored successfully </ol>
 */
  @Test(timeout=120_000L) public void testRestoreBehaviourWithFaultyStateHandles() throws Exception {
    CheckpointBlockingFunction.allowedInitializeCallsWithoutRestore.set(1);
    CheckpointBlockingFunction.successfulRestores.set(0);
    CheckpointBlockingFunction.illegalRestores.set(0);
    CheckpointBlockingFunction.afterMessWithZooKeeper.set(false);
    CheckpointBlockingFunction.failedAlready.set(false);
    waitForCheckpointLatch=new OneShotLatch();
    failInCheckpointLatch=new OneShotLatch();
    ClusterClient<?> clusterClient=miniClusterResource.getClusterClient();
    final Deadline deadline=Deadline.now().plus(TEST_TIMEOUT);
    StreamExecutionEnvironment env=StreamExecutionEnvironment.getExecutionEnvironment();
    env.setParallelism(1);
    env.setRestartStrategy(RestartStrategies.fixedDelayRestart(Integer.MAX_VALUE,0));
    env.enableCheckpointing(10);
    File checkpointLocation=TEMPORARY_FOLDER.newFolder();
    env.setStateBackend((StateBackend)new FsStateBackend(checkpointLocation.toURI()));
    DataStreamSource<String> source=env.addSource(new UnboundedSource());
    source.keyBy((str) -> str).map(new CheckpointBlockingFunction());
    JobGraph jobGraph=env.getStreamGraph().getJobGraph();
    JobID jobID=Preconditions.checkNotNull(jobGraph.getJobID());
    clusterClient.setDetached(true);
    clusterClient.submitJob(jobGraph,ZooKeeperHighAvailabilityITCase.class.getClassLoader());
    waitForCheckpointLatch.await();
    log.debug("Messing with HA directory");
    File movedCheckpointLocation=TEMPORARY_FOLDER.newFolder();
    AtomicInteger numCheckpoints=new AtomicInteger();
    Files.walkFileTree(haStorageDir.toPath(),new SimpleFileVisitor<Path>(){
      @Override public FileVisitResult visitFile(      Path file,      BasicFileAttributes attrs){
        if (file.getFileName().toString().startsWith("completedCheckpoint")) {
          log.debug("Moving original checkpoint file {}.",file);
          try {
            Files.move(file,movedCheckpointLocation.toPath().resolve(file.getFileName()));
            numCheckpoints.incrementAndGet();
          }
 catch (          IOException ioe) {
            log.debug("Exception while moving HA files.",ioe);
          }
        }
        return FileVisitResult.CONTINUE;
      }
    }
);
    assertTrue(numCheckpoints.get() > 0);
    log.debug("Resuming job");
    failInCheckpointLatch.trigger();
    assertNotNull("fullRestarts metric could not be accessed.",RestartReporter.numRestarts);
    while (RestartReporter.numRestarts.getValue() < 5 && deadline.hasTimeLeft()) {
      Thread.sleep(50);
    }
    assertThat(RestartReporter.numRestarts.getValue(),is(greaterThan(4L)));
    CheckpointBlockingFunction.afterMessWithZooKeeper.set(true);
    log.debug("Restored zookeeper");
    Files.walkFileTree(movedCheckpointLocation.toPath(),new SimpleFileVisitor<Path>(){
      @Override public FileVisitResult visitFile(      Path file,      BasicFileAttributes attrs) throws IOException {
        Files.move(file,haStorageDir.toPath().resolve(file.getFileName()));
        return FileVisitResult.CONTINUE;
      }
    }
);
    CompletableFuture<JobStatus> jobStatusFuture=FutureUtils.retrySuccesfulWithDelay(() -> clusterClient.getJobStatus(jobID),Time.milliseconds(50),deadline,(jobStatus) -> jobStatus == JobStatus.FINISHED,TestingUtils.defaultScheduledExecutor());
    assertEquals(JobStatus.FINISHED,jobStatusFuture.get());
    assertThat("We saw illegal restores.",CheckpointBlockingFunction.illegalRestores.get(),is(0));
  }
private static class UnboundedSource implements SourceFunction<String> {
    private volatile boolean running=true;
    @Override public void run(    SourceContext<String> ctx) throws Exception {
      while (running && !CheckpointBlockingFunction.afterMessWithZooKeeper.get()) {
        ctx.collect("hello");
        Thread.sleep(50);
      }
    }
    @Override public void cancel(){
      running=false;
    }
  }
private static class CheckpointBlockingFunction extends RichMapFunction<String,String> implements CheckpointedFunction {
    static AtomicInteger allowedInitializeCallsWithoutRestore=new AtomicInteger(1);
    static AtomicInteger illegalRestores=new AtomicInteger(0);
    static AtomicInteger successfulRestores=new AtomicInteger(0);
    static AtomicBoolean afterMessWithZooKeeper=new AtomicBoolean(false);
    static AtomicBoolean failedAlready=new AtomicBoolean(false);
    private final ValueStateDescriptor<String> stateDescriptor=new ValueStateDescriptor<>("state",StringSerializer.INSTANCE);
    @Override public String map(    String value) throws Exception {
      getRuntimeContext().getState(stateDescriptor).update("42");
      return value;
    }
    @Override public void snapshotState(    FunctionSnapshotContext context) throws Exception {
      if (context.getCheckpointId() > 5) {
        waitForCheckpointLatch.trigger();
        failInCheckpointLatch.await();
        if (!failedAlready.getAndSet(true)) {
          throw new RuntimeException("Failing on purpose.");
        }
      }
    }
    @Override public void initializeState(    FunctionInitializationContext context){
      if (!context.isRestored()) {
        int updatedValue=allowedInitializeCallsWithoutRestore.decrementAndGet();
        if (updatedValue < 0) {
          illegalRestores.getAndIncrement();
          throw new RuntimeException("We are not allowed any more restores.");
        }
      }
 else {
        if (!afterMessWithZooKeeper.get()) {
          illegalRestores.getAndIncrement();
        }
 else         if (successfulRestores.getAndIncrement() > 0) {
          illegalRestores.getAndIncrement();
        }
      }
    }
  }
  /** 
 * Reporter that exposes the  {@link NumberOfFullRestartsGauge} metric.
 */
public static class RestartReporter implements MetricReporter {
    static volatile NumberOfFullRestartsGauge numRestarts=null;
    @Override public void open(    MetricConfig metricConfig){
    }
    @Override public void close(){
    }
    @Override public void notifyOfAddedMetric(    Metric metric,    String s,    MetricGroup metricGroup){
      if (metric instanceof NumberOfFullRestartsGauge) {
        numRestarts=(NumberOfFullRestartsGauge)metric;
      }
    }
    @Override public void notifyOfRemovedMetric(    Metric metric,    String s,    MetricGroup metricGroup){
    }
  }
}
