/** 
 * Integration tests for custom  {@link DataDistribution}.
 */
@SuppressWarnings("serial") public class CustomDistributionITCase extends TestLogger {
  @ClassRule public static final MiniClusterResource MINI_CLUSTER_RESOURCE=new MiniClusterResource(new MiniClusterResourceConfiguration.Builder().setNumberTaskManagers(1).setNumberSlotsPerTaskManager(8).build());
  /** 
 * Test the record partitioned rightly with one field according to the customized data distribution.
 */
  @Test public void testPartitionWithDistribution1() throws Exception {
    final TestDataDist1 dist=new TestDataDist1();
    final ExecutionEnvironment env=ExecutionEnvironment.getExecutionEnvironment();
    env.setParallelism(dist.getParallelism());
    DataSet<Tuple3<Integer,Long,String>> input=CollectionDataSets.get3TupleDataSet(env);
    DataSet<Boolean> result=DataSetUtils.partitionByRange(input,dist,0).mapPartition(new RichMapPartitionFunction<Tuple3<Integer,Long,String>,Boolean>(){
      @Override public void mapPartition(      Iterable<Tuple3<Integer,Long,String>> values,      Collector<Boolean> out) throws Exception {
        int pIdx=getRuntimeContext().getIndexOfThisSubtask();
        for (        Tuple3<Integer,Long,String> s : values) {
          boolean correctlyPartitioned=true;
          if (pIdx == 0) {
            Integer[] upper=dist.boundaries[0];
            if (s.f0.compareTo(upper[0]) > 0) {
              correctlyPartitioned=false;
            }
          }
 else           if (pIdx > 0 && pIdx < dist.getParallelism() - 1) {
            Integer[] lower=dist.boundaries[pIdx - 1];
            Integer[] upper=dist.boundaries[pIdx];
            if (s.f0.compareTo(upper[0]) > 0 || (s.f0.compareTo(lower[0]) <= 0)) {
              correctlyPartitioned=false;
            }
          }
 else {
            Integer[] lower=dist.boundaries[pIdx - 1];
            if ((s.f0.compareTo(lower[0]) <= 0)) {
              correctlyPartitioned=false;
            }
          }
          if (!correctlyPartitioned) {
            fail("Record was not correctly partitioned: " + s.toString());
          }
        }
      }
    }
);
    result.output(new DiscardingOutputFormat<Boolean>());
    env.execute();
  }
  /** 
 * Test the record partitioned rightly with two fields according to the customized data distribution.
 */
  @Test public void testRangeWithDistribution2() throws Exception {
    final TestDataDist2 dist=new TestDataDist2();
    final ExecutionEnvironment env=ExecutionEnvironment.getExecutionEnvironment();
    env.setParallelism(dist.getParallelism());
    DataSet<Tuple3<Integer,Integer,String>> input=env.fromElements(new Tuple3<>(1,5,"Hi"),new Tuple3<>(1,6,"Hi"),new Tuple3<>(1,7,"Hi"),new Tuple3<>(1,11,"Hello"),new Tuple3<>(2,3,"World"),new Tuple3<>(2,4,"World"),new Tuple3<>(2,5,"World"),new Tuple3<>(2,13,"Hello World"),new Tuple3<>(3,8,"Say"),new Tuple3<>(4,0,"Why"),new Tuple3<>(4,2,"Java"),new Tuple3<>(4,11,"Say Hello"),new Tuple3<>(5,1,"Hi Java!"),new Tuple3<>(5,2,"Hi Java?"),new Tuple3<>(5,3,"Hi Java again"));
    DataSet<Boolean> result=DataSetUtils.partitionByRange(input,dist,0,1).mapPartition(new RichMapPartitionFunction<Tuple3<Integer,Integer,String>,Boolean>(){
      @Override public void mapPartition(      Iterable<Tuple3<Integer,Integer,String>> values,      Collector<Boolean> out) throws Exception {
        int pIdx=getRuntimeContext().getIndexOfThisSubtask();
        boolean correctlyPartitioned=true;
        for (        Tuple3<Integer,Integer,String> s : values) {
          if (pIdx == 0) {
            Integer[] upper=dist.boundaries[0];
            if (s.f0.compareTo(upper[0]) > 0 || (s.f0.compareTo(upper[0]) == 0 && s.f1.compareTo(upper[1]) > 0)) {
              correctlyPartitioned=false;
            }
          }
 else           if (pIdx > 0 && pIdx < dist.getParallelism() - 1) {
            Integer[] lower=dist.boundaries[pIdx - 1];
            Integer[] upper=dist.boundaries[pIdx];
            if (s.f0.compareTo(upper[0]) > 0 || (s.f0.compareTo(upper[0]) == 0 && s.f1.compareTo(upper[1]) > 0) || (s.f0.compareTo(lower[0]) < 0) || (s.f0.compareTo(lower[0]) == 0 && s.f1.compareTo(lower[1]) <= 0)) {
              correctlyPartitioned=false;
            }
          }
 else {
            Integer[] lower=dist.boundaries[pIdx - 1];
            if ((s.f0.compareTo(lower[0]) < 0) || (s.f0.compareTo(lower[0]) == 0 && s.f1.compareTo(lower[1]) <= 0)) {
              correctlyPartitioned=false;
            }
          }
          if (!correctlyPartitioned) {
            fail("Record was not correctly partitioned: " + s.toString());
          }
        }
      }
    }
);
    result.output(new DiscardingOutputFormat<Boolean>());
    env.execute();
  }
  @Test public void testPartitionKeyLessDistribution() throws Exception {
    final TestDataDist2 dist=new TestDataDist2();
    final ExecutionEnvironment env=ExecutionEnvironment.getExecutionEnvironment();
    env.setParallelism(dist.getParallelism());
    DataSet<Tuple3<Integer,Long,String>> input=CollectionDataSets.get3TupleDataSet(env);
    DataSet<Boolean> result=DataSetUtils.partitionByRange(input,dist,0).mapPartition(new RichMapPartitionFunction<Tuple3<Integer,Long,String>,Boolean>(){
      @Override public void mapPartition(      Iterable<Tuple3<Integer,Long,String>> values,      Collector<Boolean> out) throws Exception {
        int pIdx=getRuntimeContext().getIndexOfThisSubtask();
        for (        Tuple3<Integer,Long,String> s : values) {
          boolean correctlyPartitioned=true;
          if (pIdx == 0) {
            Integer[] upper=dist.boundaries[0];
            if (s.f0.compareTo(upper[0]) > 0) {
              correctlyPartitioned=false;
            }
          }
 else           if (pIdx > 0 && pIdx < dist.getParallelism() - 1) {
            Integer[] lower=dist.boundaries[pIdx - 1];
            Integer[] upper=dist.boundaries[pIdx];
            if (s.f0.compareTo(upper[0]) > 0 || (s.f0.compareTo(lower[0]) <= 0)) {
              correctlyPartitioned=false;
            }
          }
 else {
            Integer[] lower=dist.boundaries[pIdx - 1];
            if ((s.f0.compareTo(lower[0]) <= 0)) {
              correctlyPartitioned=false;
            }
          }
          if (!correctlyPartitioned) {
            fail("Record was not correctly partitioned: " + s.toString());
          }
        }
      }
    }
);
    result.output(new DiscardingOutputFormat<Boolean>());
    env.execute();
  }
  @Test(expected=IllegalArgumentException.class) public void testPartitionMoreThanDistribution() throws Exception {
    final TestDataDist2 dist=new TestDataDist2();
    ExecutionEnvironment env=ExecutionEnvironment.getExecutionEnvironment();
    DataSet<Tuple3<Integer,Long,String>> input=CollectionDataSets.get3TupleDataSet(env);
    DataSetUtils.partitionByRange(input,dist,0,1,2);
  }
  /** 
 * The class is used to do the tests of range partition with one key.
 */
public static class TestDataDist1 implements DataDistribution {
    public Integer[][] boundaries=new Integer[][]{new Integer[]{4},new Integer[]{9},new Integer[]{13},new Integer[]{18}};
    public TestDataDist1(){
    }
    public int getParallelism(){
      return boundaries.length;
    }
    @Override public Object[] getBucketBoundary(    int bucketNum,    int totalNumBuckets){
      return boundaries[bucketNum];
    }
    @Override public int getNumberOfFields(){
      return 1;
    }
    @Override public TypeInformation[] getKeyTypes(){
      return new TypeInformation[]{BasicTypeInfo.INT_TYPE_INFO};
    }
    @Override public void write(    DataOutputView out) throws IOException {
    }
    @Override public void read(    DataInputView in) throws IOException {
    }
  }
  /** 
 * The class is used to do the tests of range partition with two keys.
 */
public static class TestDataDist2 implements DataDistribution {
    public Integer[][] boundaries=new Integer[][]{new Integer[]{1,6},new Integer[]{2,4},new Integer[]{3,9},new Integer[]{4,1},new Integer[]{5,2}};
    public TestDataDist2(){
    }
    public int getParallelism(){
      return boundaries.length;
    }
    @Override public Object[] getBucketBoundary(    int bucketNum,    int totalNumBuckets){
      return boundaries[bucketNum];
    }
    @Override public int getNumberOfFields(){
      return 2;
    }
    @Override public TypeInformation[] getKeyTypes(){
      return new TypeInformation[]{BasicTypeInfo.INT_TYPE_INFO,BasicTypeInfo.INT_TYPE_INFO};
    }
    @Override public void write(    DataOutputView out) throws IOException {
    }
    @Override public void read(    DataInputView in) throws IOException {
    }
  }
}
