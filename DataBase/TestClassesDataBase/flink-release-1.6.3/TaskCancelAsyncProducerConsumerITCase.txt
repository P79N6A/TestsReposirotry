public class TaskCancelAsyncProducerConsumerITCase extends TestLogger {
  private static volatile Exception ASYNC_PRODUCER_EXCEPTION;
  private static volatile Exception ASYNC_CONSUMER_EXCEPTION;
  private static volatile Thread ASYNC_PRODUCER_THREAD;
  private static volatile Thread ASYNC_CONSUMER_THREAD;
  /** 
 * Tests that a task waiting on an async producer/consumer that is stuck in a blocking buffer request can be properly cancelled. <p>This is currently required for the Flink Kafka sources, which spawn a separate Thread consuming from Kafka and producing the intermediate streams in the spawned Thread instead of the main task Thread.
 */
  @Test public void testCancelAsyncProducerAndConsumer() throws Exception {
    Deadline deadline=Deadline.now().plus(Duration.ofMinutes(2));
    Configuration config=new Configuration();
    config.setInteger(RestOptions.PORT,0);
    config.setString(TaskManagerOptions.MEMORY_SEGMENT_SIZE,"4096");
    config.setInteger(TaskManagerOptions.NETWORK_NUM_BUFFERS,9);
    MiniClusterConfiguration miniClusterConfiguration=new MiniClusterConfiguration.Builder().setConfiguration(config).setNumTaskManagers(1).setNumSlotsPerTaskManager(1).build();
    try (MiniCluster flink=new MiniCluster(miniClusterConfiguration)){
      flink.start();
      JobVertex producer=new JobVertex("AsyncProducer");
      producer.setParallelism(1);
      producer.setInvokableClass(AsyncProducer.class);
      JobVertex consumer=new JobVertex("AsyncConsumer");
      consumer.setParallelism(1);
      consumer.setInvokableClass(AsyncConsumer.class);
      consumer.connectNewDataSetAsInput(producer,DistributionPattern.POINTWISE,ResultPartitionType.PIPELINED);
      SlotSharingGroup slot=new SlotSharingGroup(producer.getID(),consumer.getID());
      producer.setSlotSharingGroup(slot);
      consumer.setSlotSharingGroup(slot);
      JobGraph jobGraph=new JobGraph(producer,consumer);
      flink.runDetached(jobGraph);
      FutureUtils.retrySuccesfulWithDelay(() -> flink.getJobStatus(jobGraph.getJobID()),Time.milliseconds(10),deadline,status -> status == JobStatus.RUNNING,TestingUtils.defaultScheduledExecutor()).get(deadline.timeLeft().toMillis(),TimeUnit.MILLISECONDS);
      boolean producerBlocked=false;
      for (int i=0; i < 50; i++) {
        Thread thread=ASYNC_PRODUCER_THREAD;
        if (thread != null && thread.isAlive()) {
          StackTraceElement[] stackTrace=thread.getStackTrace();
          producerBlocked=isInBlockingBufferRequest(stackTrace);
        }
        if (producerBlocked) {
          break;
        }
 else {
          Thread.sleep(500L);
        }
      }
      assertTrue("Producer thread is not blocked: " + Arrays.toString(ASYNC_PRODUCER_THREAD.getStackTrace()),producerBlocked);
      boolean consumerWaiting=false;
      for (int i=0; i < 50; i++) {
        Thread thread=ASYNC_CONSUMER_THREAD;
        if (thread != null && thread.isAlive()) {
          consumerWaiting=thread.getState() == Thread.State.WAITING;
        }
        if (consumerWaiting) {
          break;
        }
 else {
          Thread.sleep(500L);
        }
      }
      assertTrue("Consumer thread is not blocked.",consumerWaiting);
      flink.cancelJob(jobGraph.getJobID()).get(deadline.timeLeft().toMillis(),TimeUnit.MILLISECONDS);
      FutureUtils.retrySuccesfulWithDelay(() -> flink.getJobStatus(jobGraph.getJobID()),Time.milliseconds(10),deadline,status -> status == JobStatus.CANCELED,TestingUtils.defaultScheduledExecutor()).get(deadline.timeLeft().toMillis(),TimeUnit.MILLISECONDS);
      assertNotNull(ASYNC_PRODUCER_EXCEPTION);
      assertEquals(IllegalStateException.class,ASYNC_PRODUCER_EXCEPTION.getClass());
      assertNotNull(ASYNC_CONSUMER_EXCEPTION);
      assertEquals(IllegalStateException.class,ASYNC_CONSUMER_EXCEPTION.getClass());
    }
   }
  /** 
 * Invokable emitting records in a separate Thread (not the main Task thread).
 */
public static class AsyncProducer extends AbstractInvokable {
    public AsyncProducer(    Environment environment){
      super(environment);
    }
    @Override public void invoke() throws Exception {
      Thread producer=new ProducerThread(getEnvironment().getWriter(0));
      ASYNC_PRODUCER_THREAD=producer;
      producer.start();
      while (producer.isAlive()) {
        try {
          producer.join();
        }
 catch (        InterruptedException ignored) {
        }
      }
    }
    /** 
 * The Thread emitting the records.
 */
private static class ProducerThread extends Thread {
      private final RecordWriter<LongValue> recordWriter;
      public ProducerThread(      ResultPartitionWriter partitionWriter){
        this.recordWriter=new RecordWriter<>(partitionWriter);
      }
      @Override public void run(){
        LongValue current=new LongValue(0);
        try {
          while (true) {
            current.setValue(current.getValue() + 1);
            recordWriter.emit(current);
            recordWriter.flushAll();
          }
        }
 catch (        Exception e) {
          ASYNC_PRODUCER_EXCEPTION=e;
        }
      }
    }
  }
  /** 
 * Invokable consuming buffers in a separate Thread (not the main Task thread).
 */
public static class AsyncConsumer extends AbstractInvokable {
    public AsyncConsumer(    Environment environment){
      super(environment);
    }
    @Override public void invoke() throws Exception {
      Thread consumer=new ConsumerThread(getEnvironment().getInputGate(0));
      ASYNC_CONSUMER_THREAD=consumer;
      consumer.start();
      while (consumer.isAlive()) {
        try {
          consumer.join();
        }
 catch (        InterruptedException ignored) {
        }
      }
    }
    /** 
 * The Thread consuming buffers.
 */
private static class ConsumerThread extends Thread {
      private final InputGate inputGate;
      public ConsumerThread(      InputGate inputGate){
        this.inputGate=inputGate;
      }
      @Override public void run(){
        try {
          while (true) {
            inputGate.getNextBufferOrEvent();
          }
        }
 catch (        Exception e) {
          ASYNC_CONSUMER_EXCEPTION=e;
        }
      }
    }
  }
}
