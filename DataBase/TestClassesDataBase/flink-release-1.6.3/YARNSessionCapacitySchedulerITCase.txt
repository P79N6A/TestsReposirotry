/** 
 * This test starts a MiniYARNCluster with a CapacityScheduler. Is has, by default a queue called "default". The configuration here adds another queue: "qa-team".
 */
public class YARNSessionCapacitySchedulerITCase extends YarnTestBase {
  private static final Logger LOG=LoggerFactory.getLogger(YARNSessionCapacitySchedulerITCase.class);
  @BeforeClass public static void setup(){
    YARN_CONFIGURATION.setClass(YarnConfiguration.RM_SCHEDULER,CapacityScheduler.class,ResourceScheduler.class);
    YARN_CONFIGURATION.set("yarn.scheduler.capacity.root.queues","default,qa-team");
    YARN_CONFIGURATION.setInt("yarn.scheduler.capacity.root.default.capacity",40);
    YARN_CONFIGURATION.setInt("yarn.scheduler.capacity.root.qa-team.capacity",60);
    YARN_CONFIGURATION.set(YarnTestBase.TEST_CLUSTER_NAME_KEY,"flink-yarn-tests-capacityscheduler");
    startYARNWithConfig(YARN_CONFIGURATION);
  }
  /** 
 * Test regular operation, including command line parameter parsing.
 */
  @Test public void testClientStartup() throws IOException {
    assumeTrue("The new mode does not start TMs upfront.",!isNewMode);
    LOG.info("Starting testClientStartup()");
    runWithArgs(new String[]{"-j",flinkUberjar.getAbsolutePath(),"-t",flinkLibFolder.getAbsolutePath(),"-n","1","-jm","768m","-tm","1024m","-qu","qa-team"},"Number of connected TaskManagers changed to 1. Slots available: 1",null,RunTypes.YARN_SESSION,0);
    LOG.info("Finished testClientStartup()");
  }
  /** 
 * Test per-job yarn cluster <p>This also tests the prefixed CliFrontend options for the YARN case We also test if the requested parallelism of 2 is passed through. The parallelism is requested at the YARN client (-ys).
 */
  @Test public void perJobYarnCluster() throws IOException {
    LOG.info("Starting perJobYarnCluster()");
    addTestAppender(JobClient.class,Level.INFO);
    File exampleJarLocation=getTestJarPath("BatchWordCount.jar");
    runWithArgs(new String[]{"run","-m","yarn-cluster","-yj",flinkUberjar.getAbsolutePath(),"-yt",flinkLibFolder.getAbsolutePath(),"-yn","1","-ys","2","-yjm","768m","-ytm","1024m",exampleJarLocation.getAbsolutePath()},"Program execution finished",new String[]{"DataSink \\(.*\\) \\(1/1\\) switched to FINISHED"},RunTypes.CLI_FRONTEND,0,true);
    LOG.info("Finished perJobYarnCluster()");
  }
  /** 
 * Test per-job yarn cluster and memory calculations for off-heap use (see FLINK-7400) with the same job as  {@link #perJobYarnCluster()}. <p>This ensures that with (any) pre-allocated off-heap memory by us, there is some off-heap memory remaining for Flink's libraries. Creating task managers will thus fail if no off-heap memory remains.
 */
  @Test public void perJobYarnClusterOffHeap() throws IOException {
    LOG.info("Starting perJobYarnCluster()");
    addTestAppender(JobClient.class,Level.INFO);
    File exampleJarLocation=getTestJarPath("BatchWordCount.jar");
    final long taskManagerMemoryMB=1024;
    final long networkBuffersMB=TaskManagerServices.calculateNetworkBufferMemory((taskManagerMemoryMB - ResourceManagerOptions.CONTAINERIZED_HEAP_CUTOFF_MIN.defaultValue()) << 20,new Configuration()) >> 20;
    final long offHeapMemory=taskManagerMemoryMB - ResourceManagerOptions.CONTAINERIZED_HEAP_CUTOFF_MIN.defaultValue() - networkBuffersMB- 100;
    runWithArgs(new String[]{"run","-m","yarn-cluster","-yj",flinkUberjar.getAbsolutePath(),"-yt",flinkLibFolder.getAbsolutePath(),"-yn","1","-ys","2","-yjm","768m","-ytm",taskManagerMemoryMB + "m","-yD","taskmanager.memory.off-heap=true","-yD","taskmanager.memory.size=" + offHeapMemory + "m","-yD","taskmanager.memory.preallocate=true",exampleJarLocation.getAbsolutePath()},"Program execution finished",new String[]{"DataSink \\(.*\\) \\(1/1\\) switched to FINISHED"},RunTypes.CLI_FRONTEND,0,true);
    LOG.info("Finished perJobYarnCluster()");
  }
  /** 
 * Test TaskManager failure and also if the vcores are set correctly (see issue FLINK-2213).
 */
  @Test(timeout=100000) public void testTaskManagerFailure() throws Exception {
    assumeTrue("The new mode does not start TMs upfront.",!isNewMode);
    LOG.info("Starting testTaskManagerFailure()");
    Runner runner=startWithArgs(new String[]{"-j",flinkUberjar.getAbsolutePath(),"-t",flinkLibFolder.getAbsolutePath(),"-n","1","-jm","768m","-tm","1024m","-s","3","-nm","customName","-Dfancy-configuration-value=veryFancy","-Dyarn.maximum-failed-containers=3","-D" + YarnConfigOptions.VCORES.key() + "=2"},"Number of connected TaskManagers changed to 1. Slots available: 3",RunTypes.YARN_SESSION);
    Assert.assertEquals(2,getRunningContainers());
    final YarnClient yc=YarnClient.createYarnClient();
    yc.init(YARN_CONFIGURATION);
    yc.start();
    List<ApplicationReport> apps=yc.getApplications(EnumSet.of(YarnApplicationState.RUNNING));
    Assert.assertEquals(1,apps.size());
    ApplicationReport app=apps.get(0);
    Assert.assertEquals("customName",app.getName());
    String url=app.getTrackingUrl();
    if (!url.endsWith("/")) {
      url+="/";
    }
    if (!url.startsWith("http://")) {
      url="http://" + url;
    }
    LOG.info("Got application URL from YARN {}",url);
    String response=TestBaseUtils.getFromHTTP(url + "taskmanagers/");
    JsonNode parsedTMs=new ObjectMapper().readTree(response);
    ArrayNode taskManagers=(ArrayNode)parsedTMs.get("taskmanagers");
    Assert.assertNotNull(taskManagers);
    Assert.assertEquals(1,taskManagers.size());
    Assert.assertEquals(3,taskManagers.get(0).get("slotsNumber").asInt());
    String jsonConfig=TestBaseUtils.getFromHTTP(url + "jobmanager/config");
    Map<String,String> parsedConfig=WebMonitorUtils.fromKeyValueJsonArray(jsonConfig);
    Assert.assertEquals("veryFancy",parsedConfig.get("fancy-configuration-value"));
    Assert.assertEquals("3",parsedConfig.get("yarn.maximum-failed-containers"));
    Assert.assertEquals("2",parsedConfig.get(YarnConfigOptions.VCORES.key()));
    String oC=outContent.toString();
    Pattern p=Pattern.compile("Flink JobManager is now running on ([a-zA-Z0-9.-]+):([0-9]+)");
    Matcher matches=p.matcher(oC);
    String hostname=null;
    String port=null;
    while (matches.find()) {
      hostname=matches.group(1).toLowerCase();
      port=matches.group(2);
    }
    LOG.info("Extracted hostname:port: {} {}",hostname,port);
    Assert.assertEquals("unable to find hostname in " + jsonConfig,hostname,parsedConfig.get(JobManagerOptions.ADDRESS.key()));
    Assert.assertEquals("unable to find port in " + jsonConfig,port,parsedConfig.get(JobManagerOptions.PORT.key()));
    String logs=TestBaseUtils.getFromHTTP(url + "jobmanager/log");
    Assert.assertTrue(logs.contains("Starting YARN ApplicationMaster"));
    Assert.assertTrue(logs.contains("Starting JobManager"));
    Assert.assertTrue(logs.contains("Starting JobManager Web Frontend"));
    ContainerId taskManagerContainer=null;
    NodeManager nodeManager=null;
    UserGroupInformation remoteUgi=null;
    NMTokenIdentifier nmIdent=null;
    try {
      remoteUgi=UserGroupInformation.getCurrentUser();
    }
 catch (    IOException e) {
      LOG.warn("Unable to get curr user",e);
      Assert.fail();
    }
    for (int nmId=0; nmId < NUM_NODEMANAGERS; nmId++) {
      NodeManager nm=yarnCluster.getNodeManager(nmId);
      ConcurrentMap<ContainerId,Container> containers=nm.getNMContext().getContainers();
      for (      Map.Entry<ContainerId,Container> entry : containers.entrySet()) {
        String command=StringUtils.join(entry.getValue().getLaunchContext().getCommands()," ");
        if (command.contains(YarnTaskManager.class.getSimpleName())) {
          taskManagerContainer=entry.getKey();
          nodeManager=nm;
          nmIdent=new NMTokenIdentifier(taskManagerContainer.getApplicationAttemptId(),null,"",0);
          remoteUgi.addTokenIdentifier(nmIdent);
        }
      }
      sleep(500);
    }
    Assert.assertNotNull("Unable to find container with TaskManager",taskManagerContainer);
    Assert.assertNotNull("Illegal state",nodeManager);
    yc.stop();
    List<ContainerId> toStop=new LinkedList<ContainerId>();
    toStop.add(taskManagerContainer);
    StopContainersRequest scr=StopContainersRequest.newInstance(toStop);
    try {
      nodeManager.getNMContext().getContainerManager().stopContainers(scr);
    }
 catch (    Throwable e) {
      LOG.warn("Error stopping container",e);
      Assert.fail("Error stopping container: " + e.getMessage());
    }
    boolean ok=false;
    do {
      LOG.debug("Waiting for correct order of events. Output: {}",errContent.toString());
      String o=errContent.toString();
      int killedOff=o.indexOf("Container killed by the ApplicationMaster");
      if (killedOff != -1) {
        o=o.substring(killedOff);
        ok=o.indexOf("Launching TaskManager") > 0;
      }
      sleep(1000);
    }
 while (!ok);
    runner.sendStop();
    try {
      runner.join();
    }
 catch (    InterruptedException e) {
      LOG.warn("Interrupted while stopping runner",e);
    }
    LOG.warn("stopped");
    System.setOut(ORIGINAL_STDOUT);
    System.setErr(ORIGINAL_STDERR);
    oC=outContent.toString();
    String eC=errContent.toString();
    LOG.info("Sending stdout content through logger: \n\n{}\n\n",oC);
    LOG.info("Sending stderr content through logger: \n\n{}\n\n",eC);
    Assert.assertTrue("Expect to see failed container",eC.contains("New messages from the YARN cluster"));
    Assert.assertTrue("Expect to see failed container",eC.contains("Container killed by the ApplicationMaster"));
    Assert.assertTrue("Expect to see new container started",eC.contains("Launching TaskManager") && eC.contains("on host"));
    remoteUgi.getTokenIdentifiers().remove(nmIdent);
    LOG.info("Finished testTaskManagerFailure()");
  }
  /** 
 * Test deployment to non-existing queue & ensure that the system logs a WARN message for the user. (Users had unexpected behavior of Flink on YARN because they mistyped the target queue. With an error message, we can help users identifying the issue)
 */
  @Test public void testNonexistingQueueWARNmessage() throws IOException {
    LOG.info("Starting testNonexistingQueueWARNmessage()");
    addTestAppender(AbstractYarnClusterDescriptor.class,Level.WARN);
    try {
      runWithArgs(new String[]{"-j",flinkUberjar.getAbsolutePath(),"-t",flinkLibFolder.getAbsolutePath(),"-n","1","-jm","768m","-tm","1024m","-qu","doesntExist"},"to unknown queue: doesntExist",null,RunTypes.YARN_SESSION,1);
    }
 catch (    Exception e) {
      assertTrue(ExceptionUtils.findThrowableWithMessage(e,"to unknown queue: doesntExist").isPresent());
    }
    checkForLogString("The specified queue 'doesntExist' does not exist. Available queues");
    LOG.info("Finished testNonexistingQueueWARNmessage()");
  }
  /** 
 * Test per-job yarn cluster with the parallelism set at the CliFrontend instead of the YARN client.
 */
  @Test public void perJobYarnClusterWithParallelism() throws IOException {
    LOG.info("Starting perJobYarnClusterWithParallelism()");
    addTestAppender(JobClient.class,Level.INFO);
    File exampleJarLocation=getTestJarPath("BatchWordCount.jar");
    runWithArgs(new String[]{"run","-p","2","-m","yarn-cluster","-yj",flinkUberjar.getAbsolutePath(),"-yt",flinkLibFolder.getAbsolutePath(),"-yn","1","-ys","2","-yjm","768m","-ytm","1024m",exampleJarLocation.getAbsolutePath()},"Program execution finished",new String[]{"DataSink \\(.*\\) \\(1/1\\) switched to FINISHED"},RunTypes.CLI_FRONTEND,0,true);
    LOG.info("Finished perJobYarnClusterWithParallelism()");
  }
  /** 
 * Test a fire-and-forget job submission to a YARN cluster.
 */
  @Test(timeout=60000) public void testDetachedPerJobYarnCluster() throws Exception {
    LOG.info("Starting testDetachedPerJobYarnCluster()");
    File exampleJarLocation=getTestJarPath("BatchWordCount.jar");
    testDetachedPerJobYarnClusterInternal(exampleJarLocation.getAbsolutePath());
    LOG.info("Finished testDetachedPerJobYarnCluster()");
  }
  /** 
 * Test a fire-and-forget job submission to a YARN cluster.
 */
  @Test(timeout=60000) public void testDetachedPerJobYarnClusterWithStreamingJob() throws Exception {
    LOG.info("Starting testDetachedPerJobYarnClusterWithStreamingJob()");
    File exampleJarLocation=getTestJarPath("StreamingWordCount.jar");
    testDetachedPerJobYarnClusterInternal(exampleJarLocation.getAbsolutePath());
    LOG.info("Finished testDetachedPerJobYarnClusterWithStreamingJob()");
  }
  private void testDetachedPerJobYarnClusterInternal(  String job) throws Exception {
    YarnClient yc=YarnClient.createYarnClient();
    yc.init(YARN_CONFIGURATION);
    yc.start();
    File tmpOutFolder=null;
    try {
      tmpOutFolder=tmp.newFolder();
    }
 catch (    IOException e) {
      throw new RuntimeException(e);
    }
    File tmpInFile;
    try {
      tmpInFile=tmp.newFile();
      FileUtils.writeStringToFile(tmpInFile,WordCountData.TEXT);
    }
 catch (    IOException e) {
      throw new RuntimeException(e);
    }
    Runner runner=startWithArgs(new String[]{"run","-m","yarn-cluster","-yj",flinkUberjar.getAbsolutePath(),"-yt",flinkLibFolder.getAbsolutePath(),"-yn","1","-yjm","768m","-yD","yarn.heap-cutoff-ratio=0.7","-yD","yarn.tags=test-tag","-ytm","1024m","-ys","2","-p","2","--detached",job,"--input",tmpInFile.getAbsoluteFile().toString(),"--output",tmpOutFolder.getAbsoluteFile().toString()},"Job has been submitted with JobID",RunTypes.CLI_FRONTEND);
    Assert.assertTrue("There should be at most 2 containers running",getRunningContainers() <= 2);
    for (int attempt=0; runner.isAlive() && attempt < 5; attempt++) {
      try {
        Thread.sleep(500);
      }
 catch (      InterruptedException e) {
      }
    }
    Assert.assertFalse("The runner should detach.",runner.isAlive());
    LOG.info("CLI Frontend has returned, so the job is running");
    try {
      List<ApplicationReport> apps=yc.getApplications(EnumSet.of(YarnApplicationState.RUNNING));
      ApplicationId tmpAppId;
      if (apps.size() == 1) {
        tmpAppId=apps.get(0).getApplicationId();
        LOG.info("waiting for the job with appId {} to finish",tmpAppId);
        while (yc.getApplications(EnumSet.of(YarnApplicationState.RUNNING)).size() > 0) {
          sleep(500);
        }
      }
 else {
        apps=yc.getApplications();
        Collections.sort(apps,new Comparator<ApplicationReport>(){
          @Override public int compare(          ApplicationReport o1,          ApplicationReport o2){
            return o1.getApplicationId().compareTo(o2.getApplicationId()) * -1;
          }
        }
);
        tmpAppId=apps.get(0).getApplicationId();
        LOG.info("Selected {} as the last appId from {}",tmpAppId,Arrays.toString(apps.toArray()));
      }
      final ApplicationId id=tmpAppId;
      File[] listOfOutputFiles=tmpOutFolder.listFiles();
      Assert.assertNotNull("Taskmanager output not found",listOfOutputFiles);
      LOG.info("The job has finished. TaskManager output files found in {}",tmpOutFolder);
      String content="";
      for (      File f : listOfOutputFiles) {
        if (f.isFile()) {
          content+=FileUtils.readFileToString(f) + "\n";
        }
      }
      Assert.assertTrue("Expected string 'da 5' or '(all,2)' not found in string '" + content + "'",content.contains("da 5") || content.contains("(da,5)") || content.contains("(all,2)"));
      Assert.assertTrue("Expected string 'der 29' or '(mind,1)' not found in string'" + content + "'",content.contains("der 29") || content.contains("(der,29)") || content.contains("(mind,1)"));
      File jobmanagerLog=YarnTestBase.findFile("..",new FilenameFilter(){
        @Override public boolean accept(        File dir,        String name){
          return name.contains("jobmanager.log") && dir.getAbsolutePath().contains(id.toString());
        }
      }
);
      Assert.assertNotNull("Unable to locate JobManager log",jobmanagerLog);
      content=FileUtils.readFileToString(jobmanagerLog);
      String expected="Starting TaskManagers";
      Assert.assertTrue("Expected string '" + expected + "' not found in JobManager log: '"+ jobmanagerLog+ "'",content.contains(expected));
      expected=" (2/2) (attempt #0) to ";
      Assert.assertTrue("Expected string '" + expected + "' not found in JobManager log."+ "This string checks that the job has been started with a parallelism of 2. Log contents: '"+ jobmanagerLog+ "'",content.contains(expected));
      LOG.info("Checking again that app has finished");
      ApplicationReport rep;
      do {
        sleep(500);
        rep=yc.getApplicationReport(id);
        LOG.info("Got report {}",rep);
      }
 while (rep.getYarnApplicationState() == YarnApplicationState.RUNNING);
      verifyApplicationTags(rep);
    }
  finally {
      String confDirPath=System.getenv("FLINK_CONF_DIR");
      File configDirectory=new File(confDirPath);
      LOG.info("testDetachedPerJobYarnClusterInternal: Using configuration directory " + configDirectory.getAbsolutePath());
      LOG.info("testDetachedPerJobYarnClusterInternal: Trying to load configuration file");
      Configuration configuration=GlobalConfiguration.loadConfiguration(configDirectory.getAbsolutePath());
      try {
        File yarnPropertiesFile=FlinkYarnSessionCli.getYarnPropertiesLocation(configuration.getValue(YarnConfigOptions.PROPERTIES_FILE_LOCATION));
        if (yarnPropertiesFile.exists()) {
          LOG.info("testDetachedPerJobYarnClusterInternal: Cleaning up temporary Yarn address reference: {}",yarnPropertiesFile.getAbsolutePath());
          yarnPropertiesFile.delete();
        }
      }
 catch (      Exception e) {
        LOG.warn("testDetachedPerJobYarnClusterInternal: Exception while deleting the JobManager address file",e);
      }
      try {
        LOG.info("testDetachedPerJobYarnClusterInternal: Closing the yarn client");
        yc.stop();
      }
 catch (      Exception e) {
        LOG.warn("testDetachedPerJobYarnClusterInternal: Exception while close the yarn client",e);
      }
    }
  }
  /** 
 * Ensures that the YARN application tags were set properly. <p>Since YARN application tags were only added in Hadoop 2.4, but Flink still supports Hadoop 2.3, reflection is required to invoke the methods. If the method does not exist, this test passes.
 */
  private void verifyApplicationTags(  final ApplicationReport report) throws InvocationTargetException, IllegalAccessException {
    final Method applicationTagsMethod;
    Class<ApplicationReport> clazz=ApplicationReport.class;
    try {
      applicationTagsMethod=clazz.getMethod("getApplicationTags");
    }
 catch (    NoSuchMethodException e) {
      return;
    }
    @SuppressWarnings("unchecked") Set<String> applicationTags=(Set<String>)applicationTagsMethod.invoke(report);
    Assert.assertEquals(Collections.singleton("test-tag"),applicationTags);
  }
  @After public void checkForProhibitedLogContents(){
    ensureNoProhibitedStringInLogFiles(PROHIBITED_STRINGS,WHITELISTED_STRINGS);
  }
}
