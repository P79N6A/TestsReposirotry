/** 
 * Test for consuming a pipelined result only partially.
 */
public class PartialConsumePipelinedResultTest extends TestLogger {
  private static final int NUMBER_OF_TMS=1;
  private static final int NUMBER_OF_SLOTS_PER_TM=1;
  private static final int PARALLELISM=NUMBER_OF_TMS * NUMBER_OF_SLOTS_PER_TM;
  private static final int NUMBER_OF_NETWORK_BUFFERS=128;
  private static MiniCluster flink;
  @BeforeClass public static void setUp() throws Exception {
    final Configuration config=new Configuration();
    config.setInteger(RestOptions.PORT,0);
    config.setString(AkkaOptions.ASK_TIMEOUT,TestingUtils.DEFAULT_AKKA_ASK_TIMEOUT());
    config.setInteger(TaskManagerOptions.NETWORK_NUM_BUFFERS,NUMBER_OF_NETWORK_BUFFERS);
    final MiniClusterConfiguration miniClusterConfiguration=new MiniClusterConfiguration.Builder().setConfiguration(config).setNumTaskManagers(NUMBER_OF_TMS).setNumSlotsPerTaskManager(NUMBER_OF_SLOTS_PER_TM).build();
    flink=new MiniCluster(miniClusterConfiguration);
    flink.start();
  }
  @AfterClass public static void tearDown() throws Exception {
    if (flink != null) {
      flink.close();
    }
  }
  /** 
 * Tests a fix for FLINK-1930. <p>When consuming a pipelined result only partially, is is possible that local channels release the buffer pool, which is associated with the result partition, too early. If the producer is still producing data when this happens, it runs into an IllegalStateException, because of the destroyed buffer pool.
 * @see <a href="https://issues.apache.org/jira/browse/FLINK-1930">FLINK-1930</a>
 */
  @Test public void testPartialConsumePipelinedResultReceiver() throws Exception {
    final JobVertex sender=new JobVertex("Sender");
    sender.setInvokableClass(SlowBufferSender.class);
    sender.setParallelism(PARALLELISM);
    final JobVertex receiver=new JobVertex("Receiver");
    receiver.setInvokableClass(SingleBufferReceiver.class);
    receiver.setParallelism(PARALLELISM);
    receiver.connectNewDataSetAsInput(sender,DistributionPattern.POINTWISE,ResultPartitionType.PIPELINED);
    final JobGraph jobGraph=new JobGraph("Partial Consume of Pipelined Result",sender,receiver);
    final SlotSharingGroup slotSharingGroup=new SlotSharingGroup(sender.getID(),receiver.getID());
    sender.setSlotSharingGroup(slotSharingGroup);
    receiver.setSlotSharingGroup(slotSharingGroup);
    flink.executeJobBlocking(jobGraph);
  }
  /** 
 * Sends a fixed number of buffers and sleeps in-between sends.
 */
public static class SlowBufferSender extends AbstractInvokable {
    public SlowBufferSender(    Environment environment){
      super(environment);
    }
    @Override public void invoke() throws Exception {
      final ResultPartitionWriter writer=getEnvironment().getWriter(0);
      for (int i=0; i < 8; i++) {
        final BufferBuilder bufferBuilder=writer.getBufferProvider().requestBufferBuilderBlocking();
        writer.addBufferConsumer(bufferBuilder.createBufferConsumer(),0);
        Thread.sleep(50);
        bufferBuilder.finish();
      }
    }
  }
  /** 
 * Reads a single buffer and recycles it.
 */
public static class SingleBufferReceiver extends AbstractInvokable {
    public SingleBufferReceiver(    Environment environment){
      super(environment);
    }
    @Override public void invoke() throws Exception {
      InputGate gate=getEnvironment().getInputGate(0);
      Buffer buffer=gate.getNextBufferOrEvent().orElseThrow(IllegalStateException::new).getBuffer();
      if (buffer != null) {
        buffer.recycleBuffer();
      }
    }
  }
}
