@Category({VerySlowRegionServerTests.class,LargeTests.class}) public class TestLogRolling extends AbstractTestLogRolling {
  @ClassRule public static final HBaseClassTestRule CLASS_RULE=HBaseClassTestRule.forClass(TestLogRolling.class);
  private static final Logger LOG=LoggerFactory.getLogger(TestLogRolling.class);
  @BeforeClass public static void setUpBeforeClass() throws Exception {
    System.setProperty("hbase.tests.use.shortcircuit.reads","false");
    Configuration conf=TEST_UTIL.getConfiguration();
    conf.setInt("dfs.namenode.heartbeat.recheck-interval",5000);
    conf.setInt("dfs.heartbeat.interval",1);
    conf.setInt("dfs.client.block.write.retries",30);
    conf.setInt("hbase.regionserver.hlog.tolerable.lowreplication",2);
    conf.setInt("hbase.regionserver.hlog.lowreplication.rolllimit",3);
    conf.set(WALFactory.WAL_PROVIDER,"filesystem");
    AbstractTestLogRolling.setUpBeforeClass();
  }
  void batchWriteAndWait(  Table table,  final FSHLog log,  int start,  boolean expect,  int timeout) throws IOException {
    for (int i=0; i < 10; i++) {
      Put put=new Put(Bytes.toBytes("row" + String.format("%1$04d",(start + i))));
      put.addColumn(HConstants.CATALOG_FAMILY,null,value);
      table.put(put);
    }
    Put tmpPut=new Put(Bytes.toBytes("tmprow"));
    tmpPut.addColumn(HConstants.CATALOG_FAMILY,null,value);
    long startTime=System.currentTimeMillis();
    long remaining=timeout;
    while (remaining > 0) {
      if (log.isLowReplicationRollEnabled() == expect) {
        break;
      }
 else {
        table.put(tmpPut);
        try {
          Thread.sleep(200);
        }
 catch (        InterruptedException e) {
        }
        remaining=timeout - (System.currentTimeMillis() - startTime);
      }
    }
  }
  /** 
 * Tests that logs are rolled upon detecting datanode death Requires an HDFS jar with HDFS-826 & syncFs() support (HDFS-200)
 */
  @Test public void testLogRollOnDatanodeDeath() throws Exception {
    TEST_UTIL.ensureSomeRegionServersAvailable(2);
    assertTrue("This test requires WAL file replication set to 2.",fs.getDefaultReplication(TEST_UTIL.getDataTestDirOnTestFS()) == 2);
    LOG.info("Replication=" + fs.getDefaultReplication(TEST_UTIL.getDataTestDirOnTestFS()));
    this.server=cluster.getRegionServer(0);
    TableDescriptor desc=TableDescriptorBuilder.newBuilder(TableName.valueOf(getName())).setColumnFamily(ColumnFamilyDescriptorBuilder.of(HConstants.CATALOG_FAMILY)).build();
    admin.createTable(desc);
    Table table=TEST_UTIL.getConnection().getTable(desc.getTableName());
    server=TEST_UTIL.getRSForFirstRegionInTable(desc.getTableName());
    RegionInfo region=server.getRegions(desc.getTableName()).get(0).getRegionInfo();
    final FSHLog log=(FSHLog)server.getWAL(region);
    final AtomicBoolean lowReplicationHookCalled=new AtomicBoolean(false);
    log.registerWALActionsListener(new WALActionsListener(){
      @Override public void logRollRequested(      boolean lowReplication){
        if (lowReplication) {
          lowReplicationHookCalled.lazySet(true);
        }
      }
    }
);
    List<DataNode> existingNodes=dfsCluster.getDataNodes();
    int numDataNodes=3;
    dfsCluster.startDataNodes(TEST_UTIL.getConfiguration(),numDataNodes,true,null,null);
    List<DataNode> allNodes=dfsCluster.getDataNodes();
    for (int i=allNodes.size() - 1; i >= 0; i--) {
      if (existingNodes.contains(allNodes.get(i))) {
        dfsCluster.stopDataNode(i);
      }
    }
    assertTrue("DataNodes " + dfsCluster.getDataNodes().size() + " default replication "+ fs.getDefaultReplication(TEST_UTIL.getDataTestDirOnTestFS()),dfsCluster.getDataNodes().size() >= fs.getDefaultReplication(TEST_UTIL.getDataTestDirOnTestFS()) + 1);
    writeData(table,2);
    long curTime=System.currentTimeMillis();
    LOG.info("log.getCurrentFileName(): " + log.getCurrentFileName());
    long oldFilenum=AbstractFSWALProvider.extractFileNumFromWAL(log);
    assertTrue("Log should have a timestamp older than now",curTime > oldFilenum && oldFilenum != -1);
    assertTrue("The log shouldn't have rolled yet",oldFilenum == AbstractFSWALProvider.extractFileNumFromWAL(log));
    final DatanodeInfo[] pipeline=log.getPipeline();
    assertTrue(pipeline.length == fs.getDefaultReplication(TEST_UTIL.getDataTestDirOnTestFS()));
    assertTrue(dfsCluster.stopDataNode(pipeline[0].getName()) != null);
    writeData(table,2);
    long newFilenum=AbstractFSWALProvider.extractFileNumFromWAL(log);
    assertTrue("Missing datanode should've triggered a log roll",newFilenum > oldFilenum && newFilenum > curTime);
    assertTrue("The log rolling hook should have been called with the low replication flag",lowReplicationHookCalled.get());
    writeData(table,3);
    assertTrue("The log should not roll again.",AbstractFSWALProvider.extractFileNumFromWAL(log) == newFilenum);
    assertTrue(dfsCluster.stopDataNode(pipeline[1].getName()) != null);
    batchWriteAndWait(table,log,3,false,14000);
    int replication=log.getLogReplication();
    assertTrue("LowReplication Roller should've been disabled, current replication=" + replication,!log.isLowReplicationRollEnabled());
    dfsCluster.startDataNodes(TEST_UTIL.getConfiguration(),1,true,null,null);
    log.rollWriter(true);
    batchWriteAndWait(table,log,13,true,10000);
    replication=log.getLogReplication();
    assertTrue("New log file should have the default replication instead of " + replication,replication == fs.getDefaultReplication(TEST_UTIL.getDataTestDirOnTestFS()));
    assertTrue("LowReplication Roller should've been enabled",log.isLowReplicationRollEnabled());
  }
  /** 
 * Test that WAL is rolled when all data nodes in the pipeline have been restarted.
 * @throws Exception
 */
  @Test public void testLogRollOnPipelineRestart() throws Exception {
    LOG.info("Starting testLogRollOnPipelineRestart");
    assertTrue("This test requires WAL file replication.",fs.getDefaultReplication(TEST_UTIL.getDataTestDirOnTestFS()) > 1);
    LOG.info("Replication=" + fs.getDefaultReplication(TEST_UTIL.getDataTestDirOnTestFS()));
    Table t=TEST_UTIL.getConnection().getTable(TableName.META_TABLE_NAME);
    try {
      this.server=cluster.getRegionServer(0);
      TableDescriptor desc=TableDescriptorBuilder.newBuilder(TableName.valueOf(getName())).setColumnFamily(ColumnFamilyDescriptorBuilder.of(HConstants.CATALOG_FAMILY)).build();
      admin.createTable(desc);
      Table table=TEST_UTIL.getConnection().getTable(desc.getTableName());
      server=TEST_UTIL.getRSForFirstRegionInTable(desc.getTableName());
      RegionInfo region=server.getRegions(desc.getTableName()).get(0).getRegionInfo();
      final WAL log=server.getWAL(region);
      final List<Path> paths=new ArrayList<>(1);
      final List<Integer> preLogRolledCalled=new ArrayList<>();
      paths.add(AbstractFSWALProvider.getCurrentFileName(log));
      log.registerWALActionsListener(new WALActionsListener(){
        @Override public void preLogRoll(        Path oldFile,        Path newFile){
          LOG.debug("preLogRoll: oldFile=" + oldFile + " newFile="+ newFile);
          preLogRolledCalled.add(new Integer(1));
        }
        @Override public void postLogRoll(        Path oldFile,        Path newFile){
          paths.add(newFile);
        }
      }
);
      writeData(table,1002);
      long curTime=System.currentTimeMillis();
      LOG.info("log.getCurrentFileName()): " + AbstractFSWALProvider.getCurrentFileName(log));
      long oldFilenum=AbstractFSWALProvider.extractFileNumFromWAL(log);
      assertTrue("Log should have a timestamp older than now",curTime > oldFilenum && oldFilenum != -1);
      assertTrue("The log shouldn't have rolled yet",oldFilenum == AbstractFSWALProvider.extractFileNumFromWAL(log));
      dfsCluster.restartDataNodes();
      Thread.sleep(1000);
      dfsCluster.waitActive();
      LOG.info("Data Nodes restarted");
      validateData(table,1002);
      writeData(table,1003);
      long newFilenum=AbstractFSWALProvider.extractFileNumFromWAL(log);
      assertTrue("Missing datanode should've triggered a log roll",newFilenum > oldFilenum && newFilenum > curTime);
      validateData(table,1003);
      writeData(table,1004);
      dfsCluster.restartDataNodes();
      Thread.sleep(1000);
      dfsCluster.waitActive();
      LOG.info("Data Nodes restarted");
      validateData(table,1004);
      writeData(table,1005);
      log.rollWriter(true);
      assertTrue("preLogRolledCalled has size of " + preLogRolledCalled.size(),preLogRolledCalled.size() >= 1);
      Set<String> loggedRows=new HashSet<>();
      FSUtils fsUtils=FSUtils.getInstance(fs,TEST_UTIL.getConfiguration());
      for (      Path p : paths) {
        LOG.debug("recovering lease for " + p);
        fsUtils.recoverFileLease(((HFileSystem)fs).getBackingFs(),p,TEST_UTIL.getConfiguration(),null);
        LOG.debug("Reading WAL " + FSUtils.getPath(p));
        WAL.Reader reader=null;
        try {
          reader=WALFactory.createReader(fs,p,TEST_UTIL.getConfiguration());
          WAL.Entry entry;
          while ((entry=reader.next()) != null) {
            LOG.debug("#" + entry.getKey().getSequenceId() + ": "+ entry.getEdit().getCells());
            for (            Cell cell : entry.getEdit().getCells()) {
              loggedRows.add(Bytes.toStringBinary(cell.getRowArray(),cell.getRowOffset(),cell.getRowLength()));
            }
          }
        }
 catch (        EOFException e) {
          LOG.debug("EOF reading file " + FSUtils.getPath(p));
        }
 finally {
          if (reader != null)           reader.close();
        }
      }
      assertTrue(loggedRows.contains("row1002"));
      assertTrue(loggedRows.contains("row1003"));
      assertTrue(loggedRows.contains("row1004"));
      assertTrue(loggedRows.contains("row1005"));
      for (      HRegion r : server.getOnlineRegionsLocalContext()) {
        try {
          r.flush(true);
        }
 catch (        Exception e) {
          LOG.info(e.toString(),e);
        }
      }
      ResultScanner scanner=table.getScanner(new Scan());
      try {
        for (int i=2; i <= 5; i++) {
          Result r=scanner.next();
          assertNotNull(r);
          assertFalse(r.isEmpty());
          assertEquals("row100" + i,Bytes.toString(r.getRow()));
        }
      }
  finally {
        scanner.close();
      }
      for (      JVMClusterUtil.RegionServerThread rsThread : TEST_UTIL.getHBaseCluster().getRegionServerThreads()) {
        assertFalse(rsThread.getRegionServer().isAborted());
      }
    }
  finally {
      if (t != null)       t.close();
    }
  }
}
