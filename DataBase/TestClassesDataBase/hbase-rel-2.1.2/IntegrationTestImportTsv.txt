/** 
 * Validate ImportTsv + LoadIncrementalHFiles on a distributed cluster.
 */
@Category(IntegrationTests.class) public class IntegrationTestImportTsv extends Configured implements Tool {
  private static final String NAME=IntegrationTestImportTsv.class.getSimpleName();
  private static final Logger LOG=LoggerFactory.getLogger(IntegrationTestImportTsv.class);
  protected static final String simple_tsv="row1\t1\tc1\tc2\n" + "row2\t1\tc1\tc2\n" + "row3\t1\tc1\tc2\n"+ "row4\t1\tc1\tc2\n"+ "row5\t1\tc1\tc2\n"+ "row6\t1\tc1\tc2\n"+ "row7\t1\tc1\tc2\n"+ "row8\t1\tc1\tc2\n"+ "row9\t1\tc1\tc2\n"+ "row10\t1\tc1\tc2\n";
  @Rule public TestName name=new TestName();
  protected static final Set<KeyValue> simple_expected=new TreeSet<KeyValue>(CellComparator.getInstance()){
    private static final long serialVersionUID=1L;
{
      byte[] family=Bytes.toBytes("d");
      for (      String line : simple_tsv.split("\n")) {
        String[] row=line.split("\t");
        byte[] key=Bytes.toBytes(row[0]);
        long ts=Long.parseLong(row[1]);
        byte[][] fields={Bytes.toBytes(row[2]),Bytes.toBytes(row[3])};
        add(new KeyValue(key,family,fields[0],ts,Type.Put,fields[0]));
        add(new KeyValue(key,family,fields[1],ts,Type.Put,fields[1]));
      }
    }
  }
;
  protected static IntegrationTestingUtility util=null;
  public Configuration getConf(){
    return util.getConfiguration();
  }
  public void setConf(  Configuration conf){
    LOG.debug("Ignoring setConf call.");
  }
  @BeforeClass public static void provisionCluster() throws Exception {
    if (null == util) {
      util=new IntegrationTestingUtility();
    }
    util.initializeCluster(1);
    if (!util.isDistributedCluster()) {
      util.startMiniMapReduceCluster();
    }
  }
  @AfterClass public static void releaseCluster() throws Exception {
    util.restoreCluster();
    if (!util.isDistributedCluster()) {
      util.shutdownMiniMapReduceCluster();
    }
    util=null;
  }
  /** 
 * Verify the data described by <code>simple_tsv</code> matches <code>simple_expected</code>.
 */
  protected void doLoadIncrementalHFiles(  Path hfiles,  TableName tableName) throws Exception {
    String[] args={hfiles.toString(),tableName.getNameAsString()};
    LOG.info(format("Running LoadIncrememntalHFiles with args: %s",Arrays.asList(args)));
    assertEquals("Loading HFiles failed.",0,ToolRunner.run(new LoadIncrementalHFiles(new Configuration(getConf())),args));
    Table table=null;
    Scan scan=new Scan(){
{
        setCacheBlocks(false);
        setCaching(1000);
      }
    }
;
    try {
      table=util.getConnection().getTable(tableName);
      Iterator<Result> resultsIt=table.getScanner(scan).iterator();
      Iterator<KeyValue> expectedIt=simple_expected.iterator();
      while (resultsIt.hasNext() && expectedIt.hasNext()) {
        Result r=resultsIt.next();
        for (        Cell actual : r.rawCells()) {
          assertTrue("Ran out of expected values prematurely!",expectedIt.hasNext());
          KeyValue expected=expectedIt.next();
          assertEquals("Scan produced surprising result",0,CellComparator.getInstance().compare(expected,actual));
        }
      }
      assertFalse("Did not consume all expected values.",expectedIt.hasNext());
      assertFalse("Did not consume all scan results.",resultsIt.hasNext());
    }
  finally {
      if (null != table)       table.close();
    }
  }
  /** 
 * Confirm the absence of the  {@link TotalOrderPartitioner} partitions file.
 */
  protected static void validateDeletedPartitionsFile(  Configuration conf) throws IOException {
    if (!conf.getBoolean(IntegrationTestingUtility.IS_DISTRIBUTED_CLUSTER,false))     return;
    FileSystem fs=FileSystem.get(conf);
    Path partitionsFile=new Path(TotalOrderPartitioner.getPartitionFile(conf));
    assertFalse("Failed to clean up partitions file.",fs.exists(partitionsFile));
  }
  @Test public void testGenerateAndLoad() throws Exception {
    generateAndLoad(TableName.valueOf(name.getMethodName()));
  }
  void generateAndLoad(  final TableName table) throws Exception {
    LOG.info("Running test testGenerateAndLoad.");
    String cf="d";
    Path hfiles=new Path(util.getDataTestDirOnTestFS(table.getNameAsString()),"hfiles");
    Map<String,String> args=new HashMap<>();
    args.put(ImportTsv.BULK_OUTPUT_CONF_KEY,hfiles.toString());
    args.put(ImportTsv.COLUMNS_CONF_KEY,format("HBASE_ROW_KEY,HBASE_TS_KEY,%s:c1,%s:c2",cf,cf));
    args.put(TestImportTsv.DELETE_AFTER_LOAD_CONF,"false");
    util.createTable(table,new String[]{cf});
    Tool t=TestImportTsv.doMROnTableTest(util,table,cf,simple_tsv,args);
    doLoadIncrementalHFiles(hfiles,table);
    validateDeletedPartitionsFile(t.getConf());
    util.deleteTable(table);
    util.cleanupDataTestDirOnTestFS(table.getNameAsString());
    LOG.info("testGenerateAndLoad completed successfully.");
  }
  public int run(  String[] args) throws Exception {
    if (args.length != 0) {
      System.err.println(format("%s [genericOptions]",NAME));
      System.err.println("  Runs ImportTsv integration tests against a distributed cluster.");
      System.err.println();
      ToolRunner.printGenericCommandUsage(System.err);
      return 1;
    }
    provisionCluster();
    TableName tableName=TableName.valueOf("IntegrationTestImportTsv");
    if (util.getAdmin().tableExists(tableName)) {
      util.deleteTable(tableName);
    }
    generateAndLoad(tableName);
    releaseCluster();
    return 0;
  }
  public static void main(  String[] args) throws Exception {
    Configuration conf=HBaseConfiguration.create();
    IntegrationTestingUtility.setUseDistributedCluster(conf);
    util=new IntegrationTestingUtility(conf);
    int status=ToolRunner.run(conf,new IntegrationTestImportTsv(),args);
    System.exit(status);
  }
}
