/** 
 * A Map Reduce job that verifies that the linked lists generated by {@link Generator} do not have any holes.
 */
static class Verify extends Configured implements Tool {
  private static final Logger LOG=LoggerFactory.getLogger(Verify.class);
  protected static final BytesWritable DEF=new BytesWritable(new byte[]{0});
  protected static final BytesWritable DEF_LOST_FAMILIES=new BytesWritable(new byte[]{1});
  protected Job job;
public static class VerifyMapper extends TableMapper<BytesWritable,BytesWritable> {
    private BytesWritable row=new BytesWritable();
    private BytesWritable ref=new BytesWritable();
    private boolean multipleUnevenColumnFamilies;
    @Override protected void setup(    Mapper<ImmutableBytesWritable,Result,BytesWritable,BytesWritable>.Context context) throws IOException, InterruptedException {
      this.multipleUnevenColumnFamilies=isMultiUnevenColumnFamilies(context.getConfiguration());
    }
    @Override protected void map(    ImmutableBytesWritable key,    Result value,    Context context) throws IOException, InterruptedException {
      byte[] rowKey=key.get();
      row.set(rowKey,0,rowKey.length);
      if (multipleUnevenColumnFamilies && (!value.containsColumn(BIG_FAMILY_NAME,BIG_FAMILY_NAME) || !value.containsColumn(TINY_FAMILY_NAME,TINY_FAMILY_NAME))) {
        context.write(row,DEF_LOST_FAMILIES);
      }
 else {
        context.write(row,DEF);
      }
      byte[] prev=value.getValue(FAMILY_NAME,COLUMN_PREV);
      if (prev != null && prev.length > 0) {
        ref.set(prev,0,prev.length);
        context.write(ref,row);
      }
 else {
        LOG.warn(String.format("Prev is not set for: %s",Bytes.toStringBinary(rowKey)));
      }
    }
  }
  /** 
 * Don't change the order of these enums. Their ordinals are used as type flag when we emit problems found from the reducer.
 */
  public static enum Counts {  UNREFERENCED,   UNDEFINED,   REFERENCED,   CORRUPT,   EXTRAREFERENCES,   EXTRA_UNDEF_REFERENCES,   LOST_FAMILIES}
  /** 
 * Per reducer, we output problem rows as byte arrasy so can be used as input for subsequent investigative mapreduce jobs. Each emitted value is prefaced by a one byte flag saying what sort of emission it is. Flag is the Count enum ordinal as a short.
 */
public static class VerifyReducer extends Reducer<BytesWritable,BytesWritable,BytesWritable,BytesWritable> {
    private ArrayList<byte[]> refs=new ArrayList<>();
    private final BytesWritable UNREF=new BytesWritable(addPrefixFlag(Counts.UNREFERENCED.ordinal(),new byte[]{}));
    private final BytesWritable LOSTFAM=new BytesWritable(addPrefixFlag(Counts.LOST_FAMILIES.ordinal(),new byte[]{}));
    private AtomicInteger rows=new AtomicInteger(0);
    private Connection connection;
    @Override protected void setup(    Reducer<BytesWritable,BytesWritable,BytesWritable,BytesWritable>.Context context) throws IOException, InterruptedException {
      super.setup(context);
      this.connection=ConnectionFactory.createConnection(context.getConfiguration());
    }
    @Override protected void cleanup(    Reducer<BytesWritable,BytesWritable,BytesWritable,BytesWritable>.Context context) throws IOException, InterruptedException {
      if (this.connection != null) {
        this.connection.close();
      }
      super.cleanup(context);
    }
    /** 
 * @param ordinal
 * @param r
 * @return Return new byte array that has <code>ordinal</code> as prefix on front taking upBytes.SIZEOF_SHORT bytes followed by <code>r</code>
 */
    public static byte[] addPrefixFlag(    final int ordinal,    final byte[] r){
      byte[] prefix=Bytes.toBytes((short)ordinal);
      if (prefix.length != Bytes.SIZEOF_SHORT) {
        throw new RuntimeException("Unexpected size: " + prefix.length);
      }
      byte[] result=new byte[prefix.length + r.length];
      System.arraycopy(prefix,0,result,0,prefix.length);
      System.arraycopy(r,0,result,prefix.length,r.length);
      return result;
    }
    /** 
 * @param bs
 * @return Type from the Counts enum of this row. Reads prefix added by{@link #addPrefixFlag(int,byte[])}
 */
    public static Counts whichType(    final byte[] bs){
      int ordinal=Bytes.toShort(bs,0,Bytes.SIZEOF_SHORT);
      return Counts.values()[ordinal];
    }
    /** 
 * @param bw
 * @return Row bytes minus the type flag.
 */
    public static byte[] getRowOnly(    BytesWritable bw){
      byte[] bytes=new byte[bw.getLength() - Bytes.SIZEOF_SHORT];
      System.arraycopy(bw.getBytes(),Bytes.SIZEOF_SHORT,bytes,0,bytes.length);
      return bytes;
    }
    @Override public void reduce(    BytesWritable key,    Iterable<BytesWritable> values,    Context context) throws IOException, InterruptedException {
      int defCount=0;
      boolean lostFamilies=false;
      refs.clear();
      for (      BytesWritable type : values) {
        if (type.getLength() == DEF.getLength()) {
          defCount++;
          if (type.getBytes()[0] == 1) {
            lostFamilies=true;
          }
        }
 else {
          byte[] bytes=new byte[type.getLength()];
          System.arraycopy(type.getBytes(),0,bytes,0,type.getLength());
          refs.add(bytes);
        }
      }
      StringBuilder refsSb=null;
      String keyString=Bytes.toStringBinary(key.getBytes(),0,key.getLength());
      if (defCount == 0 || refs.size() != 1) {
        refsSb=dumpExtraInfoOnRefs(key,context,refs);
        LOG.error("LinkedListError: key=" + keyString + ", reference(s)="+ (refsSb != null ? refsSb.toString() : ""));
      }
      if (lostFamilies) {
        LOG.error("LinkedListError: key=" + keyString + ", lost big or tiny families");
        context.getCounter(Counts.LOST_FAMILIES).increment(1);
        context.write(key,LOSTFAM);
      }
      if (defCount == 0 && refs.size() > 0) {
        for (int i=0; i < refs.size(); i++) {
          byte[] bs=refs.get(i);
          int ordinal;
          if (i <= 0) {
            ordinal=Counts.UNDEFINED.ordinal();
            context.write(key,new BytesWritable(addPrefixFlag(ordinal,bs)));
            context.getCounter(Counts.UNDEFINED).increment(1);
          }
 else {
            ordinal=Counts.EXTRA_UNDEF_REFERENCES.ordinal();
            context.write(key,new BytesWritable(addPrefixFlag(ordinal,bs)));
          }
        }
        if (rows.addAndGet(1) < MISSING_ROWS_TO_LOG) {
          context.getCounter("undef",keyString).increment(1);
        }
      }
 else       if (defCount > 0 && refs.isEmpty()) {
        context.write(key,UNREF);
        context.getCounter(Counts.UNREFERENCED).increment(1);
        if (rows.addAndGet(1) < MISSING_ROWS_TO_LOG) {
          context.getCounter("unref",keyString).increment(1);
        }
      }
 else {
        if (refs.size() > 1) {
          for (int i=1; i < refs.size(); i++) {
            context.write(key,new BytesWritable(addPrefixFlag(Counts.EXTRAREFERENCES.ordinal(),refs.get(i))));
          }
          context.getCounter(Counts.EXTRAREFERENCES).increment(refs.size() - 1);
        }
        context.getCounter(Counts.REFERENCED).increment(1);
      }
    }
    /** 
 * Dump out extra info around references if there are any. Helps debugging.
 * @return StringBuilder filled with references if any.
 * @throws IOException
 */
    private StringBuilder dumpExtraInfoOnRefs(    final BytesWritable key,    final Context context,    final List<byte[]> refs) throws IOException {
      StringBuilder refsSb=null;
      if (refs.isEmpty())       return refsSb;
      refsSb=new StringBuilder();
      String comma="";
      TableName tn=getTableName(context.getConfiguration());
      try (Table t=this.connection.getTable(tn)){
        for (        byte[] ref : refs) {
          Result r=t.get(new Get(ref));
          List<Cell> cells=r.listCells();
          String ts=(cells != null && !cells.isEmpty()) ? new java.util.Date(cells.get(0).getTimestamp()).toString() : "";
          byte[] b=r.getValue(FAMILY_NAME,COLUMN_CLIENT);
          String jobStr=(b != null && b.length > 0) ? Bytes.toString(b) : "";
          b=r.getValue(FAMILY_NAME,COLUMN_COUNT);
          long count=(b != null && b.length > 0) ? Bytes.toLong(b) : -1;
          b=r.getValue(FAMILY_NAME,COLUMN_PREV);
          String refRegionLocation="";
          String keyRegionLocation="";
          if (b != null && b.length > 0) {
            try (RegionLocator rl=this.connection.getRegionLocator(tn)){
              HRegionLocation hrl=rl.getRegionLocation(b);
              if (hrl != null)               refRegionLocation=hrl.toString();
              hrl=rl.getRegionLocation(key.getBytes());
              if (hrl != null)               keyRegionLocation=hrl.toString();
            }
           }
          LOG.error("Extras on ref without a def, ref=" + Bytes.toStringBinary(ref) + ", refPrevEqualsKey="+ (Bytes.compareTo(key.getBytes(),0,key.getLength(),b,0,b.length) == 0)+ ", key="+ Bytes.toStringBinary(key.getBytes(),0,key.getLength())+ ", ref row date="+ ts+ ", jobStr="+ jobStr+ ", ref row count="+ count+ ", ref row regionLocation="+ refRegionLocation+ ", key row regionLocation="+ keyRegionLocation);
          refsSb.append(comma);
          comma=",";
          refsSb.append(Bytes.toStringBinary(ref));
        }
      }
       return refsSb;
    }
  }
  @Override public int run(  String[] args) throws Exception {
    if (args.length != 2) {
      System.out.println("Usage : " + Verify.class.getSimpleName() + " <output dir> <num reducers>");
      return 0;
    }
    String outputDir=args[0];
    int numReducers=Integer.parseInt(args[1]);
    return run(outputDir,numReducers);
  }
  public int run(  String outputDir,  int numReducers) throws Exception {
    return run(new Path(outputDir),numReducers);
  }
  public int run(  Path outputDir,  int numReducers) throws Exception {
    LOG.info("Running Verify with outputDir=" + outputDir + ", numReducers="+ numReducers);
    job=Job.getInstance(getConf());
    job.setJobName("Link Verifier");
    job.setNumReduceTasks(numReducers);
    job.setJarByClass(getClass());
    setJobScannerConf(job);
    Scan scan=new Scan();
    scan.addColumn(FAMILY_NAME,COLUMN_PREV);
    scan.setCaching(10000);
    scan.setCacheBlocks(false);
    if (isMultiUnevenColumnFamilies(getConf())) {
      scan.addColumn(BIG_FAMILY_NAME,BIG_FAMILY_NAME);
      scan.addColumn(TINY_FAMILY_NAME,TINY_FAMILY_NAME);
    }
    TableMapReduceUtil.initTableMapperJob(getTableName(getConf()).getName(),scan,VerifyMapper.class,BytesWritable.class,BytesWritable.class,job);
    TableMapReduceUtil.addDependencyJarsForClasses(job.getConfiguration(),AbstractHBaseTool.class);
    job.getConfiguration().setBoolean("mapreduce.map.speculative",false);
    job.setReducerClass(VerifyReducer.class);
    job.setOutputFormatClass(SequenceFileAsBinaryOutputFormat.class);
    job.setOutputKeyClass(BytesWritable.class);
    job.setOutputValueClass(BytesWritable.class);
    TextOutputFormat.setOutputPath(job,outputDir);
    boolean success=job.waitForCompletion(true);
    if (success) {
      Counters counters=job.getCounters();
      if (null == counters) {
        LOG.warn("Counters were null, cannot verify Job completion." + " This is commonly a result of insufficient YARN configuration.");
        return 0;
      }
      if (verifyUnexpectedValues(counters)) {
        return 0;
      }
    }
    return 1;
  }
  public boolean verify(  long expectedReferenced) throws Exception {
    if (job == null) {
      throw new IllegalStateException("You should call run() first");
    }
    Counters counters=job.getCounters();
    if (counters == null) {
      LOG.info("Counters object was null, write verification cannot be performed." + " This is commonly a result of insufficient YARN configuration.");
      return false;
    }
    boolean success=verifyExpectedValues(expectedReferenced,counters);
    if (!verifyUnexpectedValues(counters)) {
      success=false;
    }
    if (!success) {
      handleFailure(counters);
    }
    return success;
  }
  /** 
 * Verify the values in the Counters against the expected number of entries written.
 * @param expectedReferenced Expected number of referenced entrires
 * @param counters The Job's Counters object
 * @return True if the values match what's expected, false otherwise
 */
  protected boolean verifyExpectedValues(  long expectedReferenced,  Counters counters){
    final Counter referenced=counters.findCounter(Counts.REFERENCED);
    final Counter unreferenced=counters.findCounter(Counts.UNREFERENCED);
    boolean success=true;
    if (expectedReferenced != referenced.getValue()) {
      LOG.error("Expected referenced count does not match with actual referenced count. " + "expected referenced=" + expectedReferenced + " ,actual="+ referenced.getValue());
      success=false;
    }
    if (unreferenced.getValue() > 0) {
      final Counter multiref=counters.findCounter(Counts.EXTRAREFERENCES);
      boolean couldBeMultiRef=(multiref.getValue() == unreferenced.getValue());
      LOG.error("Unreferenced nodes were not expected. Unreferenced count=" + unreferenced.getValue() + (couldBeMultiRef ? "; could be due to duplicate random numbers" : ""));
      success=false;
    }
    return success;
  }
  /** 
 * Verify that the Counters don't contain values which indicate an outright failure from the Reducers.
 * @param counters The Job's counters
 * @return True if the "bad" counter objects are 0, false otherwise
 */
  protected boolean verifyUnexpectedValues(  Counters counters){
    final Counter undefined=counters.findCounter(Counts.UNDEFINED);
    final Counter lostfamilies=counters.findCounter(Counts.LOST_FAMILIES);
    boolean success=true;
    if (undefined.getValue() > 0) {
      LOG.error("Found an undefined node. Undefined count=" + undefined.getValue());
      success=false;
    }
    if (lostfamilies.getValue() > 0) {
      LOG.error("Found nodes which lost big or tiny families, count=" + lostfamilies.getValue());
      success=false;
    }
    return success;
  }
  protected void handleFailure(  Counters counters) throws IOException {
    Configuration conf=job.getConfiguration();
    TableName tableName=getTableName(conf);
    try (Connection conn=ConnectionFactory.createConnection(conf)){
      try (RegionLocator rl=conn.getRegionLocator(tableName)){
        CounterGroup g=counters.getGroup("undef");
        Iterator<Counter> it=g.iterator();
        while (it.hasNext()) {
          String keyString=it.next().getName();
          byte[] key=Bytes.toBytes(keyString);
          HRegionLocation loc=rl.getRegionLocation(key,true);
          LOG.error("undefined row " + keyString + ", "+ loc);
        }
        g=counters.getGroup("unref");
        it=g.iterator();
        while (it.hasNext()) {
          String keyString=it.next().getName();
          byte[] key=Bytes.toBytes(keyString);
          HRegionLocation loc=rl.getRegionLocation(key,true);
          LOG.error("unreferred row " + keyString + ", "+ loc);
        }
      }
     }
   }
}
