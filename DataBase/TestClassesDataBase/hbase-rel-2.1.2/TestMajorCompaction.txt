/** 
 * Test major compactions
 */
@Category({RegionServerTests.class,MediumTests.class}) @RunWith(Parameterized.class) public class TestMajorCompaction {
  @ClassRule public static final HBaseClassTestRule CLASS_RULE=HBaseClassTestRule.forClass(TestMajorCompaction.class);
  @Parameterized.Parameters public static Object[] data(){
    return new Object[]{"NONE","BASIC","EAGER"};
  }
  @Rule public TestName name;
  private static final Logger LOG=LoggerFactory.getLogger(TestMajorCompaction.class.getName());
  private static final HBaseTestingUtility UTIL=HBaseTestingUtility.createLocalHTU();
  protected Configuration conf=UTIL.getConfiguration();
  private HRegion r=null;
  private HTableDescriptor htd=null;
  private static final byte[] COLUMN_FAMILY=fam1;
  private final byte[] STARTROW=Bytes.toBytes(START_KEY);
  private static final byte[] COLUMN_FAMILY_TEXT=COLUMN_FAMILY;
  private int compactionThreshold;
  private byte[] secondRowBytes, thirdRowBytes;
  private static final long MAX_FILES_TO_COMPACT=10;
  /** 
 * constructor 
 */
  public TestMajorCompaction(  String compType){
    super();
    name=new TestName();
    conf.setInt(HConstants.HREGION_MEMSTORE_FLUSH_SIZE,1024 * 1024);
    conf.setInt(HConstants.HREGION_MEMSTORE_BLOCK_MULTIPLIER,100);
    compactionThreshold=conf.getInt("hbase.hstore.compactionThreshold",3);
    conf.set(CompactingMemStore.COMPACTING_MEMSTORE_TYPE_KEY,String.valueOf(compType));
    secondRowBytes=START_KEY_BYTES.clone();
    secondRowBytes[START_KEY_BYTES.length - 1]++;
    thirdRowBytes=START_KEY_BYTES.clone();
    thirdRowBytes[START_KEY_BYTES.length - 1]=(byte)(thirdRowBytes[START_KEY_BYTES.length - 1] + 2);
  }
  @Before public void setUp() throws Exception {
    this.htd=UTIL.createTableDescriptor(name.getMethodName().replace('[','i').replace(']','i'));
    this.r=UTIL.createLocalHRegion(htd,null,null);
  }
  @After public void tearDown() throws Exception {
    WAL wal=((HRegion)r).getWAL();
    ((HRegion)r).close();
    wal.close();
  }
  /** 
 * Test that on a major compaction, if all cells are expired or deleted, then we'll end up with no product.  Make sure scanner over region returns right answer in this case - and that it just basically works.
 * @throws IOException exception encountered
 */
  @Test public void testMajorCompactingToNoOutput() throws IOException {
    testMajorCompactingWithDeletes(KeepDeletedCells.FALSE);
  }
  /** 
 * Test that on a major compaction,Deleted cells are retained if keep deleted cells is set to true
 * @throws IOException exception encountered
 */
  @Test public void testMajorCompactingWithKeepDeletedCells() throws IOException {
    testMajorCompactingWithDeletes(KeepDeletedCells.TRUE);
  }
  /** 
 * Run compaction and flushing memstore Assert deletes get cleaned up.
 * @throws Exception
 */
  @Test public void testMajorCompaction() throws Exception {
    majorCompaction();
  }
  @Test public void testDataBlockEncodingInCacheOnly() throws Exception {
    majorCompactionWithDataBlockEncoding(true);
  }
  @Test public void testDataBlockEncodingEverywhere() throws Exception {
    majorCompactionWithDataBlockEncoding(false);
  }
  public void majorCompactionWithDataBlockEncoding(  boolean inCacheOnly) throws Exception {
    Map<HStore,HFileDataBlockEncoder> replaceBlockCache=new HashMap<>();
    for (    HStore store : r.getStores()) {
      HFileDataBlockEncoder blockEncoder=store.getDataBlockEncoder();
      replaceBlockCache.put(store,blockEncoder);
      final DataBlockEncoding inCache=DataBlockEncoding.PREFIX;
      final DataBlockEncoding onDisk=inCacheOnly ? DataBlockEncoding.NONE : inCache;
      ((HStore)store).setDataBlockEncoderInTest(new HFileDataBlockEncoderImpl(onDisk));
    }
    majorCompaction();
    for (    Entry<HStore,HFileDataBlockEncoder> entry : replaceBlockCache.entrySet()) {
      ((HStore)entry.getKey()).setDataBlockEncoderInTest(entry.getValue());
    }
  }
  private void majorCompaction() throws Exception {
    createStoreFile(r);
    for (int i=0; i < compactionThreshold; i++) {
      createStoreFile(r);
    }
    HBaseTestCase.addContent(new RegionAsTable(r),Bytes.toString(COLUMN_FAMILY));
    Result result=r.get(new Get(STARTROW).addFamily(COLUMN_FAMILY_TEXT).readVersions(100));
    assertEquals(compactionThreshold,result.size());
    for (    HStore store : r.getStores()) {
      assertNull(store.getCompactionProgress());
    }
    r.flush(true);
    r.compact(true);
    int storeCount=0;
    for (    HStore store : r.getStores()) {
      CompactionProgress progress=store.getCompactionProgress();
      if (progress != null) {
        ++storeCount;
        assertTrue(progress.currentCompactedKVs > 0);
        assertTrue(progress.getTotalCompactingKVs() > 0);
      }
      assertTrue(storeCount > 0);
    }
    byte[] secondRowBytes=START_KEY_BYTES.clone();
    secondRowBytes[START_KEY_BYTES.length - 1]++;
    result=r.get(new Get(secondRowBytes).addFamily(COLUMN_FAMILY_TEXT).readVersions(100));
    LOG.debug("Row " + Bytes.toStringBinary(secondRowBytes) + " after "+ "initial compaction: "+ result);
    assertEquals("Invalid number of versions of row " + Bytes.toStringBinary(secondRowBytes) + ".",compactionThreshold,result.size());
    LOG.debug("Adding deletes to memstore and flushing");
    Delete delete=new Delete(secondRowBytes,System.currentTimeMillis());
    byte[][] famAndQf={COLUMN_FAMILY,null};
    delete.addFamily(famAndQf[0]);
    r.delete(delete);
    result=r.get(new Get(secondRowBytes).addFamily(COLUMN_FAMILY_TEXT).readVersions(100));
    assertTrue("Second row should have been deleted",result.isEmpty());
    r.flush(true);
    result=r.get(new Get(secondRowBytes).addFamily(COLUMN_FAMILY_TEXT).readVersions(100));
    assertTrue("Second row should have been deleted",result.isEmpty());
    createSmallerStoreFile(this.r);
    r.flush(true);
    result=r.get(new Get(secondRowBytes).addFamily(COLUMN_FAMILY_TEXT).readVersions(100));
    assertTrue("Second row should still be deleted",result.isEmpty());
    r.compact(true);
    assertEquals(1,r.getStore(COLUMN_FAMILY_TEXT).getStorefiles().size());
    result=r.get(new Get(secondRowBytes).addFamily(COLUMN_FAMILY_TEXT).readVersions(100));
    assertTrue("Second row should still be deleted",result.isEmpty());
    verifyCounts(3,0);
    final int ttl=1000;
    for (    HStore store : r.getStores()) {
      ScanInfo old=store.getScanInfo();
      ScanInfo si=old.customize(old.getMaxVersions(),ttl,old.getKeepDeletedCells());
      store.setScanInfo(si);
    }
    Thread.sleep(1000);
    r.compact(true);
    int count=count();
    assertEquals("Should not see anything after TTL has expired",0,count);
  }
  @Test public void testTimeBasedMajorCompaction() throws Exception {
    int delay=10 * 1000;
    float jitterPct=0.20f;
    conf.setLong(HConstants.MAJOR_COMPACTION_PERIOD,delay);
    conf.setFloat("hbase.hregion.majorcompaction.jitter",jitterPct);
    HStore s=((HStore)r.getStore(COLUMN_FAMILY));
    s.storeEngine.getCompactionPolicy().setConf(conf);
    try {
      createStoreFile(r);
      createStoreFile(r);
      r.compact(true);
      createStoreFile(r);
      r.compact(false);
      assertEquals(2,s.getStorefilesCount());
      RatioBasedCompactionPolicy c=(RatioBasedCompactionPolicy)s.storeEngine.getCompactionPolicy();
      Collection<HStoreFile> storeFiles=s.getStorefiles();
      long mcTime=c.getNextMajorCompactTime(storeFiles);
      for (int i=0; i < 10; ++i) {
        assertEquals(mcTime,c.getNextMajorCompactTime(storeFiles));
      }
      long jitter=Math.round(delay * jitterPct);
      assertTrue(delay - jitter <= mcTime && mcTime <= delay + jitter);
      Thread.sleep(mcTime);
      r.compact(false);
      assertEquals(1,s.getStorefilesCount());
    }
  finally {
      conf.setLong(HConstants.MAJOR_COMPACTION_PERIOD,1000 * 60 * 60* 24);
      conf.setFloat("hbase.hregion.majorcompaction.jitter",0.20F);
      createStoreFile(r);
      r.compact(true);
      assertEquals(1,s.getStorefilesCount());
    }
  }
  private void verifyCounts(  int countRow1,  int countRow2) throws Exception {
    int count1=0;
    int count2=0;
    for (    HStoreFile f : r.getStore(COLUMN_FAMILY_TEXT).getStorefiles()) {
      HFileScanner scanner=f.getReader().getScanner(false,false);
      scanner.seekTo();
      do {
        byte[] row=CellUtil.cloneRow(scanner.getCell());
        if (Bytes.equals(row,STARTROW)) {
          count1++;
        }
 else         if (Bytes.equals(row,secondRowBytes)) {
          count2++;
        }
      }
 while (scanner.next());
    }
    assertEquals(countRow1,count1);
    assertEquals(countRow2,count2);
  }
  private int count() throws IOException {
    int count=0;
    for (    HStoreFile f : r.getStore(COLUMN_FAMILY_TEXT).getStorefiles()) {
      HFileScanner scanner=f.getReader().getScanner(false,false);
      if (!scanner.seekTo()) {
        continue;
      }
      do {
        count++;
      }
 while (scanner.next());
    }
    return count;
  }
  private void createStoreFile(  final HRegion region) throws IOException {
    createStoreFile(region,Bytes.toString(COLUMN_FAMILY));
  }
  private void createStoreFile(  final HRegion region,  String family) throws IOException {
    Table loader=new RegionAsTable(region);
    HBaseTestCase.addContent(loader,family);
    region.flush(true);
  }
  private void createSmallerStoreFile(  final HRegion region) throws IOException {
    Table loader=new RegionAsTable(region);
    HBaseTestCase.addContent(loader,Bytes.toString(COLUMN_FAMILY),Bytes.toBytes("" + "bbb"),null);
    region.flush(true);
  }
  /** 
 * Test for HBASE-5920 - Test user requested major compactions always occurring
 */
  @Test public void testNonUserMajorCompactionRequest() throws Exception {
    HStore store=r.getStore(COLUMN_FAMILY);
    createStoreFile(r);
    for (int i=0; i < MAX_FILES_TO_COMPACT + 1; i++) {
      createStoreFile(r);
    }
    store.triggerMajorCompaction();
    CompactionRequestImpl request=store.requestCompaction().get().getRequest();
    assertNotNull("Expected to receive a compaction request",request);
    assertEquals("System-requested major compaction should not occur if there are too many store files",false,request.isMajor());
  }
  /** 
 * Test for HBASE-5920
 */
  @Test public void testUserMajorCompactionRequest() throws IOException {
    HStore store=r.getStore(COLUMN_FAMILY);
    createStoreFile(r);
    for (int i=0; i < MAX_FILES_TO_COMPACT + 1; i++) {
      createStoreFile(r);
    }
    store.triggerMajorCompaction();
    CompactionRequestImpl request=store.requestCompaction(PRIORITY_USER,CompactionLifeCycleTracker.DUMMY,null).get().getRequest();
    assertNotNull("Expected to receive a compaction request",request);
    assertEquals("User-requested major compaction should always occur, even if there are too many store files",true,request.isMajor());
  }
  /** 
 * Test that on a major compaction, if all cells are expired or deleted, then we'll end up with no product. Make sure scanner over region returns right answer in this case - and that it just basically works.
 * @throws IOException
 */
  @Test public void testMajorCompactingToNoOutputWithReverseScan() throws IOException {
    createStoreFile(r);
    for (int i=0; i < compactionThreshold; i++) {
      createStoreFile(r);
    }
    Scan scan=new Scan();
    scan.setReversed(true);
    InternalScanner s=r.getScanner(scan);
    do {
      List<Cell> results=new ArrayList<>();
      boolean result=s.next(results);
      assertTrue(!results.isEmpty());
      r.delete(new Delete(CellUtil.cloneRow(results.get(0))));
      if (!result) {
        break;
      }
    }
 while (true);
    s.close();
    r.flush(true);
    r.compact(true);
    scan=new Scan();
    scan.setReversed(true);
    s=r.getScanner(scan);
    int counter=0;
    do {
      List<Cell> results=new ArrayList<>();
      boolean result=s.next(results);
      if (!result) {
        break;
      }
      counter++;
    }
 while (true);
    s.close();
    assertEquals(0,counter);
  }
  private void testMajorCompactingWithDeletes(  KeepDeletedCells keepDeletedCells) throws IOException {
    createStoreFile(r);
    for (int i=0; i < compactionThreshold; i++) {
      createStoreFile(r);
    }
    InternalScanner s=r.getScanner(new Scan());
    int originalCount=0;
    do {
      List<Cell> results=new ArrayList<>();
      boolean result=s.next(results);
      r.delete(new Delete(CellUtil.cloneRow(results.get(0))));
      if (!result)       break;
      originalCount++;
    }
 while (true);
    s.close();
    r.flush(true);
    for (    HStore store : this.r.stores.values()) {
      ScanInfo old=store.getScanInfo();
      ScanInfo si=old.customize(old.getMaxVersions(),old.getTtl(),keepDeletedCells);
      store.setScanInfo(si);
    }
    r.compact(true);
    s=r.getScanner(new Scan().setRaw(true));
    int counter=0;
    do {
      List<Cell> results=new ArrayList<>();
      boolean result=s.next(results);
      if (!result)       break;
      counter++;
    }
 while (true);
    assertEquals(keepDeletedCells == KeepDeletedCells.TRUE ? originalCount : 0,counter);
  }
}
